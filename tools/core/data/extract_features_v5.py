#!/usr/bin/env python3
"""
SA-1B é€šç”¨å¤„ç†æµæ°´çº¿ V5 (Universal Edition - Ultimate Quality)

ç¯å¢ƒ: RTX 3090 + 100æ ¸ CPU

å˜æ›´æ—¥å¿—:
- [Quality] JPEG ä¿å­˜è´¨é‡æå‡è‡³ 100 (æœ€é«˜è´¨é‡)
- [Quality] å¼ºåˆ¶å…³é—­è‰²åº¦é‡‡æ · (subsampling=0)ï¼Œä¿æŒ 4:4:4 åŸè‰²é‡‡æ ·ï¼Œç¡®ä¿è®­ç»ƒæ•°æ®æ— æŸçº§ç”»è´¨
- [Fix] Resize é€»è¾‘ç»´æŒ PIL.Image.resize(..., Image.BILINEAR) ä»¥å¯¹é½è®­ç»ƒä»£ç 
- [New] æ–°å¢ä¸‰ç§è¿è¡Œæ¨¡å¼ï¼šfull / pack_only / resize_only
- [Opt] ä¿æŒå¤šè¿›ç¨‹å’Œå¼‚æ­¥ I/O æ¶æ„

åŠŸèƒ½æ¨¡å¼ (--mode):
1. full (é»˜è®¤): [åŸå›¾] -> PIL Resize/ç¼–ç (å†…å­˜) -> SAM2æç‰¹å¾(GPU) -> æ ¡éªŒ -> [Tar Shard]
2. pack_only: [ç°æœ‰NPZç›®å½•] + [ç°æœ‰JPGç›®å½•] -> æé€Ÿæ‰«æåŒ¹é… -> [Tar Shard]
3. resize_only: [åŸå›¾] -> PIL Resize -> [JPGç›®å½•]
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
import argparse
from tqdm import tqdm
import json
import cv2
from PIL import Image
from pycocotools import mask as mask_utils
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import concurrent.futures
import tarfile
import io
import time
import multiprocessing as mp
import gc

# æ·»åŠ é¡¹ç›®è·¯å¾„å’ŒSAM2è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sam2_path = project_root / "vfmkd" / "sam2"
if str(sam2_path) not in sys.path:
    sys.path.insert(0, str(sam2_path))

try:
    from vfmkd.teachers.sam2_teacher import SAM2Teacher
    from tools.core.bbox.test_bbox_strategies import compute_strategy_geometry_color
    SAM2_AVAILABLE = True
except ImportError:
    SAM2Teacher = None
    compute_strategy_geometry_color = None
    SAM2_AVAILABLE = False


# =========================================================================
# æ¨¡å— A: Resize Only Worker (å¤šè¿›ç¨‹ - PILç‰ˆ)
# =========================================================================

def _resize_worker(args):
    """å•ä¸€å›¾ç‰‡çš„ Resize ä»»åŠ¡ (ä½¿ç”¨ PILï¼Œä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´)"""
    src_path, dst_path, target_size = args
    try:
        if os.path.exists(dst_path):
            return 0  # Skipped
        
        # ä½¿ç”¨ PIL æ‰“å¼€å’Œå¤„ç†ï¼Œç¡®ä¿ä¸è®­ç»ƒä¸€è‡´
        image_pil = Image.open(src_path).convert('RGB')
        
        # ä»…å½“å°ºå¯¸ä¸åŒ¹é…æ—¶æ‰ Resize
        if image_pil.size != (target_size, target_size):
            # ä½¿ç”¨ BILINEAR æ’å€¼ï¼ˆä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼‰
            image_pil = image_pil.resize((target_size, target_size), Image.BILINEAR)
        
        # åˆ›å»ºç›®å½•
        os.makedirs(os.path.dirname(dst_path), exist_ok=True)
        
        # ä¿å­˜ä¸ºæœ€é«˜è´¨é‡ JPGï¼ˆè´¨é‡100 + å…³é—­è‰²åº¦é‡‡æ ·ï¼Œä¿æŒ4:4:4åŸè‰²é‡‡æ ·ï¼‰
        # subsampling=0: å…³é—­è‰²åº¦å­é‡‡æ ·ï¼Œç¡®ä¿æ— æŸçº§ç”»è´¨
        image_pil.save(dst_path, format='JPEG', quality=100, subsampling=0)
        
        return 1  # Success
    except Exception as e:
        print(f"âŒ Resize Error: {src_path} -> {e}")
        return -1  # Error


def run_resize_only(args):
    """æ¨¡å¼ï¼šä»… Resize å›¾ç‰‡"""
    print(f"\n{'='*60}")
    print("ğŸš€ å¯åŠ¨æ¨¡å¼: RESIZE ONLY (PIL High-Quality)")
    print(f"{'='*60}")
    
    src_dir = Path(args.data_dir)
    dst_dir = Path(args.output_dir)
    dst_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {src_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {dst_dir}")
    print(f"ğŸ“ ç›®æ ‡å°ºå¯¸: {args.target_size}x{args.target_size}")
    print("\næ­£åœ¨æ‰«æå›¾ç‰‡...")
    
    exts = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.JPG', '*.JPEG', '*.PNG', '*.BMP']
    files = []
    for ext in exts:
        files.extend(list(src_dir.rglob(ext)))
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(files)} å¼ å›¾ç‰‡ï¼Œå‡†å¤‡å¤„ç†...")
    
    tasks = []
    for p in files:
        rel_path = p.relative_to(src_dir)
        out_p = (dst_dir / rel_path).with_suffix('.jpg')
        tasks.append((str(p), str(out_p), args.target_size))
    
    success, skip, error = 0, 0, 0
    
    # å¤šè¿›ç¨‹å¤„ç†
    with mp.Pool(args.num_workers) as pool:
        for res in tqdm(pool.imap_unordered(_resize_worker, tasks), total=len(tasks), desc="Resizeè¿›åº¦"):
            if res == 1:
                success += 1
            elif res == 0:
                skip += 1
            else:
                error += 1
    
    print(f"\n{'='*60}")
    print("âœ… Resize å®Œæˆ!")
    print(f"   æˆåŠŸ: {success}")
    print(f"   è·³è¿‡: {skip} (å·²å­˜åœ¨)")
    print(f"   å¤±è´¥: {error}")
    print(f"{'='*60}\n")


# =========================================================================
# æ¨¡å— B: Pack Only Worker (æé€Ÿä¼˜åŒ–ç‰ˆ)
# =========================================================================

def _pack_worker(args):
    """æ‰“åŒ…å•ä¸ª Shard"""
    shard_idx, shard_data, output_dir, mode = args
    shard_name = os.path.join(output_dir, f"sa1b_shard_{shard_idx:05d}.tar")
    
    count = 0
    try:
        with tarfile.open(shard_name, mode, bufsize=4*1024*1024, format=tarfile.PAX_FORMAT) as tar:
            for npz_path, img_path, image_id in shard_data:
                # æ·»åŠ  NPZ æ–‡ä»¶
                tar.add(npz_path, arcname=os.path.basename(npz_path))
                # æ·»åŠ  JPG æ–‡ä»¶ï¼ˆè§„èŒƒåŒ–å‘½å: sa_xxxx.jpg æˆ–ä¿æŒåŸåï¼‰
                clean_id = image_id.replace("sa_", "") if image_id.startswith("sa_") else image_id
                jpg_arcname = f"sa_{clean_id}.jpg" if not os.path.basename(img_path).startswith("sa_") else os.path.basename(img_path)
                tar.add(img_path, arcname=jpg_arcname)
                count += 1
        return count, None
    except Exception as e:
        return 0, str(e)


def _fast_scan(folder, suffix):
    """os.scandir æé€Ÿæ‰«æ"""
    print(f"ğŸ“ æ­£åœ¨æ‰«æ {folder} ...")
    idx = {}
    lst = []
    gc.disable()
    try:
        with os.scandir(folder) as it:
            for entry in it:
                if entry.is_file() and entry.name.endswith(suffix):
                    if suffix == '.jpg':
                        stem = entry.name[:-4]
                        # è§„èŒƒåŒ–keyï¼šsa_xxxx æˆ– xxxx éƒ½æ˜ å°„åˆ°ç»Ÿä¸€æ ¼å¼
                        if stem.startswith('sa_'):
                            key = stem
                        else:
                            key = f"sa_{stem}"
                        idx[key] = entry.path
                    else:
                        # _features.npz len=13
                        key = entry.name[:-13]
                        lst.append(entry.path)
    finally:
        gc.enable()
    lst.sort()
    return idx, lst


def run_pack_only(args):
    """æ¨¡å¼ï¼šä»…æ‰“åŒ…å·²æœ‰æ–‡ä»¶"""
    print(f"\n{'='*60}")
    print("ğŸš€ å¯åŠ¨æ¨¡å¼: PACK ONLY (æé€Ÿç‰ˆ)")
    print(f"{'='*60}")
    
    npz_dir = args.data_dir
    jpg_dir = args.images_dir
    
    if not jpg_dir:
        print("âŒ é”™è¯¯: Packæ¨¡å¼éœ€è¦æŒ‡å®š --images-dir (JPGå›¾ç‰‡ç›®å½•)")
        return
    
    if not os.path.exists(npz_dir):
        print(f"âŒ é”™è¯¯: NPZç›®å½•ä¸å­˜åœ¨: {npz_dir}")
        return
    
    if not os.path.exists(jpg_dir):
        print(f"âŒ é”™è¯¯: JPGç›®å½•ä¸å­˜åœ¨: {jpg_dir}")
        return
    
    print(f"ğŸ“ NPZç›®å½•: {npz_dir}")
    print(f"ğŸ“ JPGç›®å½•: {jpg_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    
    # æé€Ÿæ‰«æ
    img_index, _ = _fast_scan(jpg_dir, '.jpg')
    _, npz_files = _fast_scan(npz_dir, '_features.npz')
    
    print(f"\nğŸ“Š æ‰«æå®Œæˆ: JPG {len(img_index)} ä¸ª, NPZ {len(npz_files)} ä¸ª")
    
    # åŒ¹é…
    pairs = []
    for npz in tqdm(npz_files, desc="åŒ¹é…ä¸­"):
        fname = os.path.basename(npz)
        key = fname[:-13]  # å»æ‰ '_features.npz'
        if key in img_index:
            pairs.append((npz, img_index[key], key))
    
    print(f"âœ… åŒ¹é…æˆåŠŸ: {len(pairs)} å¯¹")
    
    if len(pairs) == 0:
        print("âš ï¸  æ²¡æœ‰åŒ¹é…çš„æ–‡ä»¶å¯¹ï¼Œé€€å‡º")
        return
    
    os.makedirs(args.output_dir, exist_ok=True)
    shard_size = args.shard_size
    num_shards = (len(pairs) + shard_size - 1) // shard_size
    
    tasks = []
    mode = "w"
    for i in range(num_shards):
        sub = pairs[i*shard_size : (i+1)*shard_size]
        tasks.append((i, sub, args.output_dir, mode))
    
    workers = min(args.num_workers, num_shards)
    print(f"\nğŸš€ å¯åŠ¨ {workers} ä¸ªè¿›ç¨‹æ‰“åŒ…...")
    print(f"   å°†ç”Ÿæˆ {num_shards} ä¸ª Shard (æ¯ä¸ªçº¦ {shard_size} ä¸ªæ ·æœ¬)\n")
    
    success_count = 0
    error_count = 0
    
    with mp.Pool(workers) as pool:
        for count, err in tqdm(pool.imap_unordered(_pack_worker, tasks), total=len(tasks), desc="æ‰“åŒ…è¿›åº¦"):
            if err:
                print(f"âŒ Shard Error: {err}")
                error_count += 1
            else:
                success_count += count
    
    print(f"\n{'='*60}")
    print("âœ… æ‰“åŒ…å®Œæˆ!")
    print(f"   æˆåŠŸæ‰“åŒ…: {success_count} ä¸ªæ ·æœ¬")
    print(f"   å¤±è´¥: {error_count} ä¸ª Shard")
    print(f"{'='*60}\n")


# =========================================================================
# æ¨¡å— C: Full Pipeline (V4 å®Œæ•´é€»è¾‘ - PILç‰ˆ)
# =========================================================================

def verify_data_integrity(npz_dict, args):
    """æ ¡éªŒå…³é”®æ•°æ®æ˜¯å¦å­˜åœ¨"""
    missing = []
    
    # 1. éªŒè¯ Edge (edge_256x256 å¿…é¡»ä¿å­˜)
    if args.save_edge:
        if 'edge_256x256' not in npz_dict:
            missing.append('edge_256x256')
        if args.enable_s16 and 'edge_64x64' not in npz_dict:
            missing.append('edge_64x64')
        if args.enable_s32 and 'edge_32x32' not in npz_dict:
            missing.append('edge_32x32')
    
    # 2. éªŒè¯ Weights
    if args.save_weights:
        if args.enable_s4 and 'fg_map_256x256' not in npz_dict:
            missing.append('fg_map_256x256')
        if args.enable_s8 and 'fg_map_128x128' not in npz_dict:
            missing.append('fg_map_128x128')
        if args.enable_s16 and 'fg_map_64x64' not in npz_dict:
            missing.append('fg_map_64x64')
        if args.enable_s32 and 'fg_map_32x32' not in npz_dict:
            missing.append('fg_map_32x32')
    
    # 3. éªŒè¯ Features (æ ¹æ®å¯ç”¨çš„å±‚çº§)
    if args.save_feature:
        if args.enable_s4:
            has_s4 = any('S4' in k or 'P2' in k or '256' in k for k in npz_dict.keys())
            if not has_s4:
                missing.append('feature_S4')
        if args.enable_s8:
            has_s8 = any('S8' in k or 'P3' in k or '128' in k for k in npz_dict.keys())
            if not has_s8:
                missing.append('feature_S8')
        if args.enable_s16:
            has_s16 = any('S16' in k or 'P4' in k or '64' in k for k in npz_dict.keys())
            if not has_s16:
                missing.append('feature_S16')
        if args.enable_s32:
            has_s32 = any('S32' in k or 'P5' in k or '32' in k for k in npz_dict.keys())
            if not has_s32:
                missing.append('feature_S32')
    
    # 4. éªŒè¯ BBox (å¦‚æœå¼€å¯ä¸”æ ‡è®°ä¸ºæœ‰bbox)
    if args.save_bbox:
        if npz_dict.get('has_bbox', False):
            if 'bboxes' not in npz_dict:
                missing.append('bboxes')
    
    return (len(missing) == 0), missing


class CPUWorker_Full:
    """Fullæ¨¡å¼ä¸“ç”¨çš„ Worker (é›†æˆ PIL + æœ€é«˜ç”»è´¨ï¼Œä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´)"""
    
    def __init__(self, config):
        self.kernel_size = config.get('kernel_size', 3)
        self.kernel = np.ones((self.kernel_size, self.kernel_size), dtype=np.uint8)
        self.max_instances = config.get('max_instances', 1)
        self.enable_bbox_selection = config.get('enable_bbox_selection', True)
        self.target_size = 1024
        
        self.edge_sizes = [256, 64, 32]
        self.weight_sizes = [256, 128, 64, 32]
    
    def process(self, image_path, json_path):
        try:
            # 1. åŠ è½½å›¾åƒ (ä½¿ç”¨ PILï¼Œä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´)
            # è®­ç»ƒæ—¶ä½¿ç”¨: Image.open().convert('RGB').resize((1024, 1024))
            image_pil = Image.open(str(image_path)).convert('RGB')
            
            # 2. Resize (PIL BILINEARï¼Œä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´)
            if image_pil.size != (self.target_size, self.target_size):
                image_pil_resized = image_pil.resize((self.target_size, self.target_size), Image.BILINEAR)
            else:
                image_pil_resized = image_pil
            
            # 3. ç¼–ç ä¸º JPG Bytes (ç”¨äºä¿å­˜åˆ° Tar)
            # ä½¿ç”¨PILä¿å­˜ï¼Œè´¨é‡100 + å…³é—­è‰²åº¦é‡‡æ ·ï¼ˆä¿æŒ4:4:4åŸè‰²é‡‡æ ·ï¼Œç¡®ä¿æ— æŸçº§ç”»è´¨ï¼‰
            # subsampling=0: å…³é—­è‰²åº¦å­é‡‡æ ·ï¼Œé¿å…é¢œè‰²ä¿¡æ¯æŸå¤±
            jpg_io = io.BytesIO()
            image_pil_resized.save(jpg_io, format='JPEG', quality=100, subsampling=0)
            jpg_bytes = jpg_io.getvalue()
            
            # 4. è½¬æ¢æ•°æ®ä¾›è®¡ç®—ä½¿ç”¨
            # SAM2 Teacher å’Œ è¾¹ç¼˜è®¡ç®—éœ€è¦ Numpy æ•°ç»„
            # æ³¨æ„: PIL æ˜¯ RGBï¼ŒOpenCV éœ€è¦ BGR
            image_rgb_np = np.array(image_pil)
            image_bgr_np = cv2.cvtColor(image_rgb_np, cv2.COLOR_RGB2BGR)
            
            # 5. åŠ è½½ JSON
            with open(json_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
            
            # 6. è®¡ç®— Edge/Weights (ä½¿ç”¨ numpy)
            edge_maps, weight_maps = self._compute_edges_and_weights(json_data)
            
            result = {
                'success': True,
                'image_id': Path(image_path).stem,
                'original_shape': np.array(image_rgb_np.shape),
                'edge_maps': edge_maps,
                'weight_maps': weight_maps,
                'jpg_bytes': jpg_bytes,
            }
            
            # 7. é€‰æ¡†ç­–ç•¥ (ä¼ å…¥ BGR numpy)
            if self.enable_bbox_selection and compute_strategy_geometry_color:
                bbox_data = self._compute_bbox(json_data, image_bgr_np)
                result.update(bbox_data)
            else:
                result.update({
                    'has_bbox': False,
                    'bboxes': np.empty((0, 4), dtype=np.float32),
                    'num_bboxes': 0,
                    'geometry_color_flag': 0
                })
            
            # è¿”å› RGB numpy ç»™ SAM2 (SAM2 é€šå¸¸å¤„ç† RGB)
            return image_rgb_np, result
            
        except Exception as e:
            return None, {
                'success': False,
                'image_id': Path(image_path).stem,
                'error': str(e)
            }
    
    def _compute_edges_and_weights(self, json_data):
        """å®Œå…¨ä¿ç•™åŸæœ‰çš„æ ¸å¿ƒç®—æ³•é€»è¾‘ï¼šMethod Bè¾¹ç¼˜æå– + æƒé‡å›¾ç”Ÿæˆ"""
        image_info = json_data.get('image', {})
        height = int(image_info.get('height', image_info.get('h', 0)))
        width = int(image_info.get('width', image_info.get('w', 0)))
        annotations = json_data.get('annotations', [])
        
        # Method Bï¼šæ¯ä¸ªå®ä¾‹å•ç‹¬æå–è¾¹ç¼˜ååˆå¹¶
        combined_edge_map = np.zeros((height, width), dtype=np.uint8)
        union_mask = np.zeros((height, width), dtype=np.uint8)
        
        if len(annotations) > 0:
            for ann in annotations:
                rle = ann.get('segmentation')
                if rle is None:
                    continue
                
                mask = mask_utils.decode(rle)
                
                # åˆå¹¶æ©ç ï¼ˆç”¨äºæƒé‡å›¾ï¼‰
                union_mask = np.maximum(union_mask, mask)
                
                # å¯¹æ¯ä¸ªå®ä¾‹å•ç‹¬æå–è¾¹ç¼˜
                edge = cv2.morphologyEx(mask, cv2.MORPH_GRADIENT, self.kernel)
                edge = (edge > 0).astype(np.uint8)
                
                # ä½¿ç”¨bitwise_oræ›¿ä»£logical_orï¼ˆç›´æ¥åœ¨uint8ä¸Šæ“ä½œï¼‰
                combined_edge_map = np.bitwise_or(combined_edge_map, edge)
        
        # ç”Ÿæˆå¤šå°ºåº¦è¾¹ç¼˜å›¾
        edge_maps = {}
        edge_float = combined_edge_map.astype(np.float32)
        for size in self.edge_sizes:
            edge_small = cv2.resize(edge_float, (size, size), interpolation=cv2.INTER_AREA)
            edge_maps[size] = (edge_small > 0).astype(np.uint8)
        
        # ç”Ÿæˆå¤šå°ºåº¦æƒé‡å›¾ï¼ˆä½¿ç”¨Torch CPUè¿›è¡Œæ± åŒ–ï¼‰
        weight_maps = {}
        union_tensor = torch.from_numpy(union_mask.astype(np.float32)).unsqueeze(0).unsqueeze(0)
        
        for size in self.weight_sizes:
            fg_prob = F.adaptive_avg_pool2d(union_tensor, (size, size)).squeeze().numpy()
            
            # å‰æ™¯æƒé‡ï¼šareaå½’ä¸€åŒ–
            fg_binary = (fg_prob > 0.5).astype(np.float32)
            num_fg = np.clip(fg_binary.sum(), a_min=1, a_max=None)
            fg_map = fg_binary / num_fg
            
            # èƒŒæ™¯æƒé‡ï¼šå½’ä¸€åŒ–
            bg_map = 1.0 - fg_binary
            bg_sum = bg_map.sum()
            if bg_sum > 0:
                bg_map = bg_map / bg_sum
            
            weight_maps[size] = {
                'fg_map': fg_map.astype(np.float32),
                'bg_map': bg_map.astype(np.float32)
            }
        
        return edge_maps, weight_maps
    
    def _compute_bbox(self, json_data, image_bgr):
        """æ‰§è¡Œé€‰æ¡†ç­–ç•¥ï¼Œå®Œå…¨ä¿ç•™åŸæœ‰é€»è¾‘"""
        try:
            H, W = image_bgr.shape[:2]
            
            # æ„é€ ç¬¦åˆæ¥å£çš„æ•°æ®ç»“æ„
            data = {
                'image': {
                    'height': H,
                    'width': W,
                    'h': H,
                    'w': W,
                }
            }
            annotations = json_data.get('annotations', [])
            
            # æ³¨æ„ï¼šcompute_strategy_geometry_color å†…éƒ¨ä¼šè½¬æ¢BGRåˆ°RGB
            selected_components = compute_strategy_geometry_color(
                data=data,
                annotations=annotations,
                image_rgb=image_bgr,  # ä¼ å…¥BGRï¼Œå‡½æ•°å†…éƒ¨ä¼šè½¬æ¢
                clip_data=None,
                max_instances=self.max_instances,
                max_display=0,
                debug_trace=None,
            )
            
            if selected_components and len(selected_components) > 0:
                bboxes = []
                masks = []
                for comp in selected_components:
                    bboxes.append(comp['box'])
                    masks.append(comp['mask'])
                
                return {
                    'has_bbox': True,
                    'bboxes': np.array(bboxes, dtype=np.float32),
                    'num_bboxes': len(bboxes),
                    'masks': masks,
                    'geometry_color_flag': 1
                }
            else:
                return {
                    'has_bbox': False,
                    'bboxes': np.empty((0, 4), dtype=np.float32),
                    'num_bboxes': 0,
                    'masks': [],
                    'geometry_color_flag': 1
                }
        except Exception as e:
            return {
                'has_bbox': False,
                'bboxes': np.empty((0, 4), dtype=np.float32),
                'num_bboxes': 0,
                'masks': [],
                'geometry_color_flag': 0
            }


class SA1BDataset_Full(Dataset):
    """Fullæ¨¡å¼çš„Dataset"""
    
    def __init__(self, data_dir, output_dir, worker_config, max_images=None):
        self.data_dir = Path(data_dir)
        self.output_dir = Path(output_dir)
        self.worker = CPUWorker_Full(worker_config)
        
        # æ‰«ææ–‡ä»¶
        print("ğŸ“ æ­£åœ¨æ‰«ææ•°æ®é›†...")
        all_images = list(self.data_dir.glob("*.jpg"))
        if max_images:
            all_images = all_images[:max_images]
        
        # å»é‡é€»è¾‘ï¼ˆæ£€æŸ¥å·²æœ‰Shardï¼‰
        self.task_list = []
        existing_shards = set()
        for tar_file in self.output_dir.glob("sa1b_shard_*.tar"):
            existing_shards.add(tar_file.stem)
        
        for img_path in all_images:
            json_path = self.data_dir / f"{img_path.stem}.json"
            if json_path.exists():
                self.task_list.append((img_path, json_path))
        
        print(f"ğŸ“Š ä»»åŠ¡ç»Ÿè®¡: æ€»è®¡ {len(all_images)} | æœ‰æ•ˆä»»åŠ¡ {len(self.task_list)}")
        if existing_shards:
            print(f"âš ï¸  æ£€æµ‹åˆ°å·²æœ‰ Shard æ–‡ä»¶ {len(existing_shards)} ä¸ªï¼Œè¯·ç¡®è®¤ä¸ä¼šè¦†ç›–")
    
    def __len__(self):
        return len(self.task_list)
    
    def __getitem__(self, idx):
        image_path, json_path = self.task_list[idx]
        return self.worker.process(image_path, json_path)


def collate_fn_full(batch):
    """è‡ªå®šä¹‰ batch å¤„ç†ï¼Œè¿‡æ»¤å¤±è´¥çš„æ ·æœ¬"""
    images = []
    results = []
    for img, res in batch:
        if img is not None and res.get('success', False):
            images.append(img)
            results.append(res)
    
    if not images:
        return None, None
    
    return images, results


def assemble_save_dict(cpu_data, gpu_features, args, teacher_model_type):
    """ç»„è£…ä¿å­˜å­—å…¸ï¼Œå®Œå…¨éµå¾ª V4 çš„ä¿å­˜é€»è¾‘è§„åˆ™"""
    save_dict = {}
    
    # 1. ç‰¹å¾ (Features) - ä»…å½“ Master å¼€å…³å¼€å¯æ—¶
    if args.save_feature and gpu_features:
        feat_configs = [
            (args.enable_s4, 'P2', 256, 'S4'),
            (args.enable_s8, 'P3', 128, 'S8'),
            (args.enable_s16, 'P4', 64, 'S16'),
            (args.enable_s32, 'P5', 32, 'S32'),
        ]
        
        for enabled, key_prefix, size, scale_name in feat_configs:
            if not enabled:
                continue
            
            found_key = None
            for feat_key in gpu_features.keys():
                if key_prefix in feat_key and str(size) in feat_key:
                    found_key = feat_key
                    break
                if key_prefix in feat_key and scale_name in feat_key:
                    found_key = feat_key
                    break
            
            if found_key and found_key in gpu_features:
                feat_tensor = gpu_features[found_key]
                if feat_tensor.dim() == 4:
                    feat_tensor = feat_tensor.squeeze(0)
                if isinstance(feat_tensor, torch.Tensor):
                    feat_tensor = feat_tensor.detach().cpu().numpy()
                save_dict[found_key] = feat_tensor
            elif enabled:
                # æ’å€¼è¡¥å…¨
                base_key = None
                base_feat = None
                for k in ['P4_S16', 'P5_S32', 'P3_S8']:
                    if k in gpu_features:
                        base_key = k
                        base_feat = gpu_features[k]
                        break
                
                if base_feat is not None:
                    if isinstance(base_feat, torch.Tensor):
                        base_feat = base_feat.detach().cpu()
                    if base_feat.dim() == 4:
                        base_feat = base_feat.squeeze(0)
                    base_feat = base_feat.unsqueeze(0)
                    resized = F.interpolate(
                        base_feat.unsqueeze(0),
                        size=(size, size),
                        mode='bilinear',
                        align_corners=False
                    )
                    feat_key = f'{key_prefix}_{scale_name}'
                    save_dict[feat_key] = resized.squeeze(0).squeeze(0).cpu().numpy()
    
    # 2. è¾¹ç¼˜ (Edges)
    if args.save_edge and 'edge_maps' in cpu_data:
        edge_maps = cpu_data['edge_maps']
        if 256 in edge_maps:
            save_dict['edge_256x256'] = edge_maps[256]
        if args.enable_s16 and 64 in edge_maps:
            save_dict['edge_64x64'] = edge_maps[64]
        if args.enable_s32 and 32 in edge_maps:
            save_dict['edge_32x32'] = edge_maps[32]
    
    # 3. æƒé‡ (Weights)
    if args.save_weights and 'weight_maps' in cpu_data:
        weight_maps = cpu_data['weight_maps']
        w_configs = [
            (args.enable_s4, 256),
            (args.enable_s8, 128),
            (args.enable_s16, 64),
            (args.enable_s32, 32)
        ]
        for enabled, size in w_configs:
            if enabled and size in weight_maps:
                save_dict[f'fg_map_{size}x{size}'] = weight_maps[size]['fg_map']
                save_dict[f'bg_map_{size}x{size}'] = weight_maps[size]['bg_map']
    
    # 4. é€‰æ¡† (BBox)
    if args.save_bbox and 'bboxes' in cpu_data:
        if cpu_data.get('has_bbox', False):
            save_dict['has_bbox'] = np.array(True, dtype=bool)
            save_dict['num_bboxes'] = np.array(cpu_data['num_bboxes'], dtype=np.int32)
            save_dict['bboxes'] = cpu_data['bboxes']
            save_dict['geometry_color_flag'] = np.array(cpu_data.get('geometry_color_flag', 1), dtype=np.uint8)
            if 'masks' in cpu_data and len(cpu_data['masks']) > 0:
                save_dict['masks'] = np.array(cpu_data['masks'], dtype=object)
        else:
            save_dict['has_bbox'] = np.array(False, dtype=bool)
            save_dict['num_bboxes'] = np.array(0, dtype=np.int32)
            save_dict['bboxes'] = np.empty((0, 4), dtype=np.float32)
            save_dict['geometry_color_flag'] = np.array(cpu_data.get('geometry_color_flag', 0), dtype=np.uint8)
    
    # 5. å…ƒæ•°æ® (æ€»æ˜¯ä¿å­˜)
    save_dict['image_id'] = cpu_data['image_id']
    save_dict['image_shape'] = cpu_data['original_shape']
    save_dict['model_type'] = teacher_model_type
    
    return save_dict


def _full_write_task(shard_idx, buffer, output_dir):
    """Fullæ¨¡å¼çš„åå°å†™å…¥çº¿ç¨‹"""
    name = output_dir / f"sa1b_shard_{shard_idx:05d}.tar"
    try:
        with tarfile.open(name, "w") as tar:
            for item in buffer:
                image_id = item['image_id']
                jpg_bytes = item['jpg_bytes']
                npz_data = item['npz_data']
                
                # å†™å…¥ JPG
                clean_id = image_id.replace("sa_", "") if image_id.startswith("sa_") else image_id
                jpg_name = f"sa_{clean_id}.jpg"
                
                jpg_io = io.BytesIO(jpg_bytes)
                ti = tarfile.TarInfo(name=jpg_name)
                ti.size = len(jpg_bytes)
                tar.addfile(ti, jpg_io)
                
                # å†™å…¥ NPZ
                npz_io = io.BytesIO()
                np.savez_compressed(npz_io, **npz_data)
                nb = npz_io.getvalue()
                
                npz_name = f"{image_id}_features.npz"
                ti = tarfile.TarInfo(name=npz_name)
                ti.size = len(nb)
                npz_io.seek(0)
                tar.addfile(ti, npz_io)
        
        print(f"ğŸ“¦ [Shard {shard_idx:05d}] å†™å…¥å®Œæˆ ({len(buffer)} ä¸ªæ ·æœ¬) -> {name.name}")
        return True
    except Exception as e:
        print(f"âŒ [Shard {shard_idx:05d}] å†™å…¥å¤±è´¥: {e}")
        return False


def run_full_pipeline(args):
    """æ¨¡å¼ï¼šå®Œæ•´æµæ°´çº¿"""
    print(f"\n{'='*60}")
    print("ğŸš€ å¯åŠ¨æ¨¡å¼: FULL PIPELINE (One-Pass PIL Edition)")
    print(f"{'='*60}")
    
    if not SAM2_AVAILABLE:
        print("âŒ é”™è¯¯: æ— æ³•å¯¼å…¥ SAM2Teacherï¼ŒFullæ¨¡å¼éœ€è¦SAM2æ”¯æŒ")
        return
    
    # æ„å»ºé…ç½®
    _ckpt = args.checkpoint
    if _ckpt is None:
        if args.teacher_model.endswith('hiera_b+'):
            _ckpt = 'weights/sam2.1_hiera_base_plus.pt'
        else:
            _ckpt = 'weights/sam2.1_hiera_base_plus.pt'
    
    device = args.device if args.device else ('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆå§‹åŒ– Dataset å’Œ DataLoader
    print(f"ğŸ”¥ åˆå§‹åŒ– CPU Worker (Num Workers: {args.num_workers})...")
    
    worker_config = {
        'kernel_size': args.kernel_size,
        'max_instances': args.max_instances,
        'enable_bbox_selection': args.save_bbox
    }
    
    output_path = Path(args.output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    dataset = SA1BDataset_Full(args.data_dir, args.output_dir, worker_config, args.max_images)
    
    if len(dataset) == 0:
        print("âœ… æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œæ— éœ€å¤„ç†")
        return
    
    dataloader = DataLoader(
        dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        collate_fn=collate_fn_full,
        pin_memory=True,
        persistent_workers=True if args.num_workers > 0 else False,
    )
    
    # åˆå§‹åŒ– GPU æ¨¡å‹
    print(f"ğŸ”¥ åˆå§‹åŒ– GPU Teacher ({args.teacher_model})...")
    teacher_config = {
        'model_type': args.teacher_model,
        'checkpoint_path': _ckpt,
        'device': device,
        'enable_visualization': False,
        'feature_output_dir': args.output_dir,
        'enable_diag_compare': bool(args.diag_compare),
        'fallback_if_high_std': bool(args.diag_fallback),
    }
    
    teacher = SAM2Teacher(teacher_config)
    print(f"âœ… GPUæ¨¡å‹åˆå§‹åŒ–å®Œæˆ: {teacher.model_name}")
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print(f"\nğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   æ•°æ®ç›®å½•: {args.data_dir}")
    print(f"   è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"   æ•™å¸ˆæ¨¡å‹: {args.teacher_model}")
    print(f"   æƒé‡æ–‡ä»¶: {teacher_config['checkpoint_path']}")
    print(f"   è®¡ç®—è®¾å¤‡: {device}")
    print(f"   æœ€å¤§å›¾åƒæ•°: {args.max_images or 'å…¨éƒ¨'}")
    print(f"   CPUè¿›ç¨‹æ•°: {args.num_workers}")
    print(f"   GPUæ‰¹å¤§å°: {args.batch_size}")
    print(f"   Shardå¤§å°: {args.shard_size}")
    print(f"\nğŸ’¾ ä¿å­˜è®¾ç½®:")
    print(f"   Feature: {args.save_feature} | Edge: {args.save_edge} | Weight: {args.save_weights} | BBox: {args.save_bbox}")
    print(f"   å±‚çº§è®¾ç½® -> S4:{args.enable_s4} | S8:{args.enable_s8} | S16:{args.enable_s16} | S32:{args.enable_s32}")
    print(f"\nğŸš€ å¼€å§‹æµæ°´çº¿å¤„ç†...\n")
    
    # Buffer State
    shard_buffer = []
    shard_counter = 0
    total_processed = 0
    success_count = 0
    error_count = 0
    
    timing_stats = {
        'gpu_inference': [],
        'assemble': [],
    }
    
    # åå°å†™å…¥çº¿ç¨‹æ± 
    io_executor = concurrent.futures.ThreadPoolExecutor(max_workers=4)
    
    try:
        for batch_idx, batch_result in enumerate(tqdm(dataloader, desc="æå–ç‰¹å¾")):
            if batch_result is None or batch_result[0] is None:
                continue
            
            images_list, cpu_results_list = batch_result
            
            # é€ä¸ªè¿‡æ¨¡å‹ (SAM2Teacheré€šå¸¸ä¸æ”¯æŒbatchï¼Œæ‰€ä»¥å¾ªç¯å¤„ç†)
            for i, img_rgb in enumerate(images_list):
                res = cpu_results_list[i]
                img_id = res['image_id']
                
                try:
                    # 1. GPU æ¨ç†
                    gpu_feats = {}
                    if args.save_feature:
                        gpu_start = time.time()
                        with torch.no_grad():
                            gpu_feats = teacher.extract_features(
                                img_rgb,
                                image_ids=[img_id],
                                save_features=False
                            )
                        gpu_time = time.time() - gpu_start
                        timing_stats['gpu_inference'].append(gpu_time)
                    
                    # 2. ç»„è£…æ•°æ®å­—å…¸
                    assemble_start = time.time()
                    save_dict = assemble_save_dict(res, gpu_feats, args, args.teacher_model)
                    assemble_time = time.time() - assemble_start
                    timing_stats['assemble'].append(assemble_time)
                    
                    # 3. éªŒè¯æ•°æ®å®Œæ•´æ€§
                    is_valid, missing = verify_data_integrity(save_dict, args)
                    if not is_valid:
                        error_count += 1
                        print(f"âš ï¸ [Skip] {img_id} ç¼ºå¤±å…³é”®æ•°æ®: {missing}")
                        continue
                    
                    # 4. åŠ å…¥ Buffer
                    shard_buffer.append({
                        'image_id': img_id,
                        'jpg_bytes': res['jpg_bytes'],
                        'npz_data': save_dict
                    })
                    
                    total_processed += 1
                    success_count += 1
                    
                    # 5. è§¦å‘å†™ç›˜
                    if len(shard_buffer) >= args.shard_size:
                        buffer_to_write = shard_buffer[:]
                        shard_buffer = []
                        io_executor.submit(_full_write_task, shard_counter, buffer_to_write, output_path)
                        shard_counter += 1
                        print(f"ğŸ“¦ [è¿›åº¦] å·²å¤„ç† {total_processed} å¼  | å·²ç”Ÿæˆ {shard_counter} ä¸ª Shard | Buffer: {len(shard_buffer)}")
                    
                    # æ¯100å¼ æ‰“å°ä¸€æ¬¡è¯¦ç»†è®¡æ—¶
                    if success_count % 100 == 0:
                        gpu_str = f"GPUæ¨ç†{gpu_time:.3f}s" if args.save_feature else "è·³è¿‡GPU"
                        print(f"âœ… {img_id}: {gpu_str} | ç»„è£…{assemble_time:.3f}s | ç´¯è®¡{success_count}å¼ ")
                
                except Exception as e:
                    error_count += 1
                    print(f"\nâŒ {img_id}: å¤„ç†å¤±è´¥ - {e}")
                    import traceback
                    traceback.print_exc()
    
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­")
    finally:
        # å¤„ç†å‰©ä½™ Buffer
        if len(shard_buffer) > 0:
            print(f"\nğŸ§¹ æ¸…ç†å‰©ä½™ Buffer ({len(shard_buffer)} ä¸ª)...")
            io_executor.submit(_full_write_task, shard_counter, shard_buffer, output_path)
            shard_counter += 1
        
        print("â³ ç­‰å¾…åå°å†™å…¥ä»»åŠ¡å®Œæˆ...")
        io_executor.shutdown(wait=True)
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"\n{'='*60}")
        print("ğŸ‰ ç‰¹å¾æå–å®Œæˆ!")
        print(f"{'='*60}")
        print(f"âœ… æœ¬æ¬¡æˆåŠŸ: {success_count} ä¸ª")
        print(f"âŒ å¤±è´¥: {error_count} ä¸ª")
        print(f"ğŸ“¦ ç”Ÿæˆ Shard: {shard_counter} ä¸ª")
        
        # æ‰“å°å¹³å‡è€—æ—¶ç»Ÿè®¡
        if success_count > 0:
            print(f"\nâ±ï¸  å¹³å‡è€—æ—¶ (æ¯å¼ ):")
            if timing_stats['gpu_inference']:
                avg_gpu = np.mean(timing_stats['gpu_inference'])
                print(f"  GPUæ¨ç†: {avg_gpu:.3f}s")
            if timing_stats['assemble']:
                avg_assemble = np.mean(timing_stats['assemble'])
                print(f"  æ•°æ®ç»„è£…: {avg_assemble:.3f}s")
            total_avg = sum(timing_stats['gpu_inference']) + sum(timing_stats['assemble'])
            if total_avg > 0:
                print(f"  æ€»è®¡: {total_avg/success_count:.3f}s")
        print(f"{'='*60}\n")


# =========================================================================
# ä¸»å…¥å£
# =========================================================================

def main():
    parser = argparse.ArgumentParser(
        description="SA-1B é€šç”¨å¤„ç†æµæ°´çº¿ V5 (Universal Edition - Ultimate Quality)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

  1. Fullæ¨¡å¼ (å®Œæ•´æµæ°´çº¿):
     python extract_features_v5.py --mode full \\
        --data-dir /path/to/sa1b \\
        --output-dir /path/to/output \\
        --num-workers 32 --batch-size 4 --shard-size 1024

  2. Resizeæ¨¡å¼ (ä»…å¤„ç†å›¾ç‰‡):
     python extract_features_v5.py --mode resize_only \\
        --data-dir /path/to/images \\
        --output-dir /path/to/resized \\
        --num-workers 32 --target-size 1024

  3. Packæ¨¡å¼ (ä»…æ‰“åŒ…å·²æœ‰æ–‡ä»¶):
     python extract_features_v5.py --mode pack_only \\
        --data-dir /path/to/npz \\
        --images-dir /path/to/jpg \\
        --output-dir /path/to/output \\
        --num-workers 8 --shard-size 1024
        """
    )
    
    # æ ¸å¿ƒæ¨¡å¼é€‰æ‹©
    parser.add_argument("--mode", type=str, default="full",
                       choices=["full", "pack_only", "resize_only"],
                       help="è¿è¡Œæ¨¡å¼: full(å…¨æµç¨‹), pack_only(ä»…æ‰“åŒ…ç°æˆæ–‡ä»¶), resize_only(ä»…å¤„ç†å›¾ç‰‡)")
    
    # é€šç”¨è·¯å¾„å‚æ•°
    parser.add_argument("--data-dir", type=str, required=True,
                       help="è¾“å…¥ç›®å½• (Full/Resize:åŸå›¾ç›®å½•, Pack:NPZç›®å½•)")
    parser.add_argument("--output-dir", type=str, required=True,
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--images-dir", type=str, default=None,
                       help="[Packæ¨¡å¼ä¸“ç”¨] JPGå›¾ç‰‡ç›®å½•")
    
    # æ€§èƒ½å‚æ•°
    parser.add_argument("--num-workers", type=int, default=32,
                       help="CPUå¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤32ï¼‰")
    parser.add_argument("--shard-size", type=int, default=1024,
                       help="æ¯ä¸ªTaråŒ…åŒ…å«çš„æ ·æœ¬æ•°ï¼ˆé»˜è®¤1024ï¼‰")
    
    # Fullæ¨¡å¼ä¸“ç”¨å‚æ•°
    parser.add_argument("--batch-size", type=int, default=4,
                       help="[Fullæ¨¡å¼] GPUæ‰¹å¤§å°ï¼ˆé»˜è®¤4ï¼‰")
    parser.add_argument("--teacher-model", type=str, default="sam2.1_hiera_b+",
                       choices=["sam2.1_hiera_t", "sam2.1_hiera_s", "sam2.1_hiera_b+", "sam2.1_hiera_l"],
                       help="[Fullæ¨¡å¼] æ•™å¸ˆæ¨¡å‹ç±»å‹")
    parser.add_argument("--checkpoint", type=str, default=None,
                       help="[Fullæ¨¡å¼] æƒé‡æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--device", type=str, default="cuda:4",
                       help="[Fullæ¨¡å¼] æŒ‡å®šGPUè®¾å¤‡ (é»˜è®¤cuda:4)")
    parser.add_argument("--max-images", type=int, default=None,
                       help="[Fullæ¨¡å¼] æœ€å¤§å¤„ç†å›¾åƒæ•°é‡")
    parser.add_argument("--diag-compare", action='store_true',
                       help="[Fullæ¨¡å¼] å¯ç”¨è¯Šæ–­ï¼šä¿å­˜å‰å¯¹æ¯”åˆ†å¸ƒï¼Œæ‰“å°mean/std")
    parser.add_argument("--diag-fallback", action='store_true',
                       help="[Fullæ¨¡å¼] å¯ç”¨å›é€€ï¼šè‹¥stdå¼‚å¸¸åˆ™å›é€€ä¸º/255å®æ—¶ç‰¹å¾")
    
    # Fullæ¨¡å¼å¼€å…³
    parser.add_argument("--save-feature", action="store_true", default=True,
                       help="[Fullæ¨¡å¼] æ€»å¼€å…³: ä¿å­˜ç‰¹å¾ï¼ˆé»˜è®¤Trueï¼‰")
    parser.add_argument("--no-save-feature", action="store_false", dest="save_feature",
                       help="[Fullæ¨¡å¼] å…³é—­ç‰¹å¾ä¿å­˜")
    parser.add_argument("--save-weights", action="store_true", default=True,
                       help="[Fullæ¨¡å¼] æ€»å¼€å…³: ä¿å­˜æƒé‡å›¾ï¼ˆé»˜è®¤Trueï¼‰")
    parser.add_argument("--no-save-weights", action="store_false", dest="save_weights",
                       help="[Fullæ¨¡å¼] å…³é—­æƒé‡å›¾ä¿å­˜")
    parser.add_argument("--save-edge", action="store_true", default=True,
                       help="[Fullæ¨¡å¼] æ€»å¼€å…³: ä¿å­˜è¾¹ç¼˜å›¾ï¼ˆé»˜è®¤Trueï¼‰")
    parser.add_argument("--no-save-edge", action="store_false", dest="save_edge",
                       help="[Fullæ¨¡å¼] å…³é—­è¾¹ç¼˜å›¾ä¿å­˜")
    parser.add_argument("--save-bbox", action="store_true", default=True,
                       help="[Fullæ¨¡å¼] æ€»å¼€å…³: ä¿å­˜BBoxï¼ˆé»˜è®¤Trueï¼‰")
    parser.add_argument("--no-save-bbox", action="store_false", dest="save_bbox",
                       help="[Fullæ¨¡å¼] å…³é—­BBoxä¿å­˜")
    
    # å±‚çº§å¼€å…³ (Fullæ¨¡å¼)
    parser.add_argument("--enable-s4", action="store_true", default=False,
                       help="[Fullæ¨¡å¼] å¼€å¯ S4 (256x256) å±‚çº§")
    parser.add_argument("--enable-s8", action="store_true", default=False,
                       help="[Fullæ¨¡å¼] å¼€å¯ S8 (128x128) å±‚çº§")
    parser.add_argument("--enable-s16", action="store_true", default=True,
                       help="[Fullæ¨¡å¼] å¼€å¯ S16 (64x64) å±‚çº§ï¼ˆé»˜è®¤Trueï¼‰")
    parser.add_argument("--enable-s32", action="store_true", default=True,
                       help="[Fullæ¨¡å¼] å¼€å¯ S32 (32x32) å±‚çº§ï¼ˆé»˜è®¤Trueï¼‰")
    
    # Resizeæ¨¡å¼ä¸“ç”¨å‚æ•°
    parser.add_argument("--target-size", type=int, default=1024,
                       help="[Resizeæ¨¡å¼] ç›®æ ‡å°ºå¯¸ï¼ˆé»˜è®¤1024ï¼‰")
    
    # è¾…åŠ©å‚æ•° (Fullæ¨¡å¼)
    parser.add_argument("--kernel-size", type=int, default=3,
                       help="[Fullæ¨¡å¼] è¾¹ç¼˜æå–æ ¸å¤§å°")
    parser.add_argument("--max-instances", type=int, default=1,
                       help="[Fullæ¨¡å¼] é€‰æ¡†ç­–ç•¥æœ€å¤šé€‰æ‹©çš„å®ä¾‹æ•°ï¼ˆé»˜è®¤1ï¼‰")
    
    args = parser.parse_args()
    
    # æ ¹æ®æ¨¡å¼æ‰§è¡Œ
    if args.mode == "full":
        run_full_pipeline(args)
    elif args.mode == "pack_only":
        run_pack_only(args)
    elif args.mode == "resize_only":
        run_resize_only(args)


if __name__ == "__main__":
    # å¿…é¡»è®¾ç½® spawn å¯åŠ¨æ–¹å¼ä»¥å…¼å®¹ PyTorch/OpenCV å¤šè¿›ç¨‹
    try:
        mp.set_start_method('spawn', force=True)
    except RuntimeError:
        pass  # å·²ç»è®¾ç½®è¿‡äº†
    
    main()

