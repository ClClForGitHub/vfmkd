#!/usr/bin/env python3
"""
TAR â†’ BIN è½¬æ¢å·¥å…·ï¼ˆé«˜æ€§èƒ½å®šé•¿äºŒè¿›åˆ¶å­˜å‚¨ + å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†ï¼‰

å°† tar æ–‡ä»¶ä¸­çš„ JPG å’Œ NPZ è½¬æ¢ä¸ºå®šé•¿çš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œå®ç°æè‡´ IO æ€§èƒ½ã€‚

**æ€§èƒ½ä¼˜åŒ–**ï¼š
- ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†ï¼ˆé»˜è®¤ä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒï¼‰
- ä¸»è¿›ç¨‹è´Ÿè´£å¿«é€Ÿè¯»å– TAR æ–‡ä»¶å’Œå†™å…¥ç»“æœï¼ˆIO å¯†é›†ï¼‰
- Worker è¿›ç¨‹è´Ÿè´£ CPU å¯†é›†æ“ä½œï¼ˆJPG è§£ç ã€å›¾åƒç¼©æ”¾ã€NPZ åŠ è½½ã€æ•°æ®è½¬æ¢ï¼‰
- æ‰¹å¤„ç†æ§åˆ¶å†…å­˜ç§¯å‹ï¼Œé¿å… OOM
- é¢„æœŸæ€§èƒ½æå‡ï¼š10-20 å€ï¼ˆå–å†³äº CPU æ ¸å¿ƒæ•°ï¼‰

è¾“å‡ºæ–‡ä»¶ç»“æ„:
- images.bin: (1024, 1024, 3) uint8 - æ¯ä¸ªæ ·æœ¬ 3,145,728 bytes
- features.bin: P4_S16 + P5_S32 - æ¯ä¸ªæ ·æœ¬ 5,242,880 bytes
- edge_maps.bin: edge_256x256 + edge_64x64 + edge_32x32 - æ¯ä¸ªæ ·æœ¬ 70,656 bytes
- weight_maps.bin: fg_map_* + bg_map_* - æ¯ä¸ªæ ·æœ¬ 172,032 bytes
- bboxes.bin: (1, 4) float32 - æ¯ä¸ªæ ·æœ¬ 16 bytes
- masks.bin: (1, 256, 256) uint8 - æ¯ä¸ªæ ·æœ¬ 65,536 bytes
- metadata.bin: num_bboxes + has_bbox + image_shape - æ¯ä¸ªæ ·æœ¬ 20 bytes
- keys.txt: æ ·æœ¬ ID åˆ—è¡¨ï¼ˆç”¨äºè°ƒè¯•ï¼‰
- config.json: å…¨å±€é…ç½®ï¼ˆmodel_type ç­‰ï¼‰

å†™å…¥çš„é”®:
- P4_S16, P5_S32 (ç‰¹å¾)
- edge_256x256, edge_64x64, edge_32x32 (è¾¹ç¼˜å›¾)
- fg_map_128x128, bg_map_128x128, fg_map_64x64, bg_map_64x64, fg_map_32x32, bg_map_32x32 (æƒé‡å›¾)
- bboxes (è§„èŒƒåŒ–), masks (è§„èŒƒåŒ–)
- num_bboxes, has_bbox, image_shape (å…ƒæ•°æ®)

ä¸å†™å…¥çš„é”®:
- IMAGE_EMB_S16 (ä¸ P4_S16 é‡å¤)
- edge_original (ä½¿ç”¨ç‡ä½ï¼Œä»…9%)
- image_id (å­˜ keys.txt)
- model_type (å­˜ config.json)
- feature_flag, edge_flag, edge_version, geometry_color_flag (å†…éƒ¨æ ‡è®°ï¼Œä¸éœ€è¦)

ç”¨æ³•:
    python convert_tar_to_bin.py \
        --tar-path /path/to/sa1b_shard_00000.tar \
        --output-dir ./binary_dataset \
        [--max-samples 1000] \
        [--model-type "sam2.1_hiera_b+"] \
        [--workers 32]  # å¹¶è¡Œ Worker è¿›ç¨‹æ•°ï¼ˆé»˜è®¤ï¼šæ‰€æœ‰ CPU æ ¸å¿ƒï¼‰
"""

import argparse
import tarfile
import numpy as np
import cv2
import io
import json
import os
import sys
import multiprocessing
import concurrent.futures
from pathlib import Path
from typing import Dict, Optional, Tuple, List
try:
    from tqdm import tqdm
except ImportError:
    tqdm = None


# ==================== é…ç½®å¸¸é‡ ====================

# å°ºå¯¸å®šä¹‰
IMG_SIZE = 1024
MASK_SIZE = 256

# æ¯ä¸ªæ ·æœ¬çš„å­—èŠ‚å¤§å°ï¼ˆç”¨äºéªŒè¯ï¼‰
SAMPLE_SIZE_IMAGE = IMG_SIZE * IMG_SIZE * 3  # 3,145,728 bytes
SAMPLE_SIZE_P4 = 1 * 256 * 64 * 64 * 4  # 4,194,304 bytes (float32)
SAMPLE_SIZE_P5 = 1 * 256 * 32 * 32 * 4  # 1,048,576 bytes (float32)
SAMPLE_SIZE_FEATURES = SAMPLE_SIZE_P4 + SAMPLE_SIZE_P5  # 5,242,880 bytes
SAMPLE_SIZE_EDGE_256 = 256 * 256 * 1  # 65,536 bytes (uint8)
SAMPLE_SIZE_EDGE_64 = 64 * 64 * 1  # 4,096 bytes (uint8)
SAMPLE_SIZE_EDGE_32 = 32 * 32 * 1  # 1,024 bytes (uint8)
SAMPLE_SIZE_EDGE_MAPS = SAMPLE_SIZE_EDGE_256 + SAMPLE_SIZE_EDGE_64 + SAMPLE_SIZE_EDGE_32  # 70,656 bytes
SAMPLE_SIZE_WEIGHT_128 = 128 * 128 * 4  # 65,536 bytes (float32)
SAMPLE_SIZE_WEIGHT_64 = 64 * 64 * 4  # 16,384 bytes (float32)
SAMPLE_SIZE_WEIGHT_32 = 32 * 32 * 4  # 4,096 bytes (float32)
SAMPLE_SIZE_WEIGHT_MAPS = (SAMPLE_SIZE_WEIGHT_128 + SAMPLE_SIZE_WEIGHT_64 + SAMPLE_SIZE_WEIGHT_32) * 2  # 172,032 bytes
SAMPLE_SIZE_BBOX = 1 * 4 * 4  # 16 bytes (float32)
SAMPLE_SIZE_MASK = 1 * MASK_SIZE * MASK_SIZE * 1  # 65,536 bytes (uint8)
SAMPLE_SIZE_METADATA = 5 * 4  # 20 bytes (5ä¸ª int32)


# ==================== è¾…åŠ©å‡½æ•° ====================

def normalize_mask(mask_arr: np.ndarray, target_size: int = MASK_SIZE) -> np.ndarray:
    """
    å°†å˜é•¿æ©ç è§„èŒƒåŒ–åˆ°å›ºå®šå°ºå¯¸ 256x256
    
    ä½¿ç”¨ cv2.INTER_AREA æ’å€¼æ–¹æ³•ï¼ˆä¸ç‰¹å¾æå–å’Œè®­ç»ƒè„šæœ¬ä¸€è‡´ï¼‰
    
    Args:
        mask_arr: åŸå§‹æ©ç ï¼Œå¯èƒ½æ˜¯ (H, W) æˆ– (1, H, W) æˆ– object æ•°ç»„
        target_size: ç›®æ ‡å°ºå¯¸ï¼Œé»˜è®¤ 256
    
    Returns:
        è§„èŒƒåŒ–åçš„æ©ç ï¼Œå½¢çŠ¶ (1, 256, 256)ï¼Œdtype=uint8
    """
    # ç¡®ä¿æ˜¯ numpy æ•°ç»„ï¼ˆå…¼å®¹æ ‡é‡ã€åˆ—è¡¨ç­‰ï¼‰
    if not isinstance(mask_arr, np.ndarray):
        # å¦‚æœæ˜¯æ ‡é‡æˆ–å…¶ä»–ç±»å‹ï¼Œè¿”å›å…¨é›¶æ©ç 
        if isinstance(mask_arr, (int, float)) or mask_arr is None:
            return np.zeros((1, target_size, target_size), dtype=np.uint8)
        mask_arr = np.array(mask_arr)
    
    # å¤„ç† object æ•°ç»„ï¼ˆmasks å¯èƒ½æ˜¯ object ç±»å‹ï¼‰
    if mask_arr.dtype == object:
        if mask_arr.size == 0:
            # ç©ºæ©ç ï¼Œè¿”å›å…¨é›¶
            return np.zeros((1, target_size, target_size), dtype=np.uint8)
        # å–ç¬¬ä¸€ä¸ªå…ƒç´ 
        mask_item = mask_arr.item(0)
        # ç¡®ä¿å–å‡ºçš„å…ƒç´ æ˜¯ numpy æ•°ç»„
        if not isinstance(mask_item, np.ndarray):
            mask_arr = np.array(mask_item)
        else:
            mask_arr = mask_item
    
    # å†æ¬¡ç¡®ä¿æ˜¯ numpy æ•°ç»„
    if not isinstance(mask_arr, np.ndarray):
        mask_arr = np.array(mask_arr)
    
    # ç¡®ä¿æ˜¯ 2D æˆ– 3D
    if mask_arr.ndim == 0:
        # 0 ç»´æ•°ç»„ï¼ˆæ ‡é‡ï¼‰ï¼Œè¿”å›å…¨é›¶æ©ç 
        return np.zeros((1, target_size, target_size), dtype=np.uint8)
    elif mask_arr.ndim == 1:
        # 1 ç»´æ•°ç»„ï¼Œå¯èƒ½æ˜¯ä¸è§„åˆ™å½¢çŠ¶ï¼Œè¿”å›å…¨é›¶æ©ç 
        return np.zeros((1, target_size, target_size), dtype=np.uint8)
    elif mask_arr.ndim == 2:
        mask_arr = mask_arr[None, ...]  # (H, W) -> (1, H, W)
    elif mask_arr.ndim == 3 and mask_arr.shape[0] > 1:
        # å¦‚æœå¤šä¸ªé€šé“ï¼Œå–ç¬¬ä¸€ä¸ª
        mask_arr = mask_arr[0:1, ...]
    elif mask_arr.ndim > 3:
        # è¶…è¿‡ 3 ç»´ï¼Œå°è¯•é™ç»´
        while mask_arr.ndim > 3:
            mask_arr = mask_arr[0]
        if mask_arr.ndim == 2:
            mask_arr = mask_arr[None, ...]
    
    # éªŒè¯ç»´åº¦
    if mask_arr.ndim != 3:
        # æ— æ³•å¤„ç†çš„ç»´åº¦ï¼Œè¿”å›å…¨é›¶æ©ç 
        return np.zeros((1, target_size, target_size), dtype=np.uint8)
    
    # æå– H, W
    if mask_arr.shape[0] == 0:
        return np.zeros((1, target_size, target_size), dtype=np.uint8)
    _, h, w = mask_arr.shape
    
    # ä½¿ç”¨ cv2.INTER_AREA ä¸‹é‡‡æ ·ï¼ˆä¸ç‰¹å¾æå–å’Œè®­ç»ƒè„šæœ¬ä¸€è‡´ï¼‰
    # å‚è€ƒ: tools/core/bbox/sa1b_bbox_extractor.py:392
    # å‚è€ƒ: tools/core/exper/train_distill_single_test.py:633
    mask_2d = mask_arr[0].astype(np.float32)
    mask_resized = cv2.resize(
        mask_2d,
        (target_size, target_size),
        interpolation=cv2.INTER_AREA
    )
    
    # äºŒå€¼åŒ–ï¼š> 0.5 åˆ™ä¸º 1ï¼ˆä¸ç‰¹å¾æå–è„šæœ¬ä¸€è‡´ï¼‰
    mask_binary = (mask_resized > 0.5).astype(np.uint8)
    
    # æ·»åŠ  batch ç»´åº¦
    return mask_binary[None, ...]  # (1, 256, 256)


def normalize_bbox(bbox_arr: np.ndarray) -> Tuple[np.ndarray, int, int]:
    """
    è§„èŒƒåŒ–è¾¹ç•Œæ¡†åˆ°å›ºå®šå½¢çŠ¶ (1, 4)
    
    Args:
        bbox_arr: åŸå§‹è¾¹ç•Œæ¡†ï¼Œå¯èƒ½æ˜¯ (0, 4) æˆ– (1, 4) æˆ–æ ‡é‡/åˆ—è¡¨
    
    Returns:
        (fixed_bbox, num_bboxes, has_bbox)
        - fixed_bbox: (1, 4) float32
        - num_bboxes: å®é™…æ¡†æ•°é‡
        - has_bbox: æ˜¯å¦æœ‰æ¡† (0/1)
    """
    # ç¡®ä¿æ˜¯ numpy æ•°ç»„
    if not isinstance(bbox_arr, np.ndarray):
        if bbox_arr is None or (isinstance(bbox_arr, (int, float)) and bbox_arr == 0):
            bbox_arr = np.empty((0, 4), dtype=np.float32)
        else:
            bbox_arr = np.array(bbox_arr, dtype=np.float32)
    
    # ç¡®ä¿æ˜¯ 2D
    if bbox_arr.ndim == 1:
        bbox_arr = bbox_arr[None, ...]  # (4,) -> (1, 4)
    elif bbox_arr.ndim == 0:
        # æ ‡é‡ï¼Œå½“ä½œç©ºæ¡†å¤„ç†
        bbox_arr = np.empty((0, 4), dtype=np.float32)
    
    if bbox_arr.shape[0] == 0:
        # æ— æ¡†æ—¶ï¼šå¡«å……å·¦ä¸Šè§’å°æ¡† [0, 0, 1, 1]ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰
        # å‚è€ƒ: tools/core/exper/train_distill_single_test.py:2079
        fixed_bbox = np.array([[0.0, 0.0, 1.0, 1.0]], dtype=np.float32)
        num_bboxes = 0
        has_bbox = 0
    else:
        # æœ‰æ¡†æ—¶ï¼šç›´æ¥ä½¿ç”¨ï¼ˆç¡®ä¿æ˜¯ (1, 4)ï¼‰
        fixed_bbox = bbox_arr.astype(np.float32)
        if fixed_bbox.ndim == 1:
            fixed_bbox = fixed_bbox[None, ...]  # (4,) -> (1, 4)
        num_bboxes = fixed_bbox.shape[0]
        has_bbox = 1
    
    # ç¡®ä¿å½¢çŠ¶æ˜¯ (1, 4)
    if fixed_bbox.shape[0] > 1:
        fixed_bbox = fixed_bbox[0:1, ...]  # åªå–ç¬¬ä¸€ä¸ªæ¡†
    
    return fixed_bbox, num_bboxes, has_bbox


def jpg_to_raw(jpg_bytes: bytes, target_size: int = IMG_SIZE) -> np.ndarray:
    """
    å°† JPG è§£ç ä¸ºå›ºå®šå¤§å°çš„ RGB æ•°ç»„
    
    Args:
        jpg_bytes: JPG æ–‡ä»¶çš„å­—èŠ‚æ•°æ®
        target_size: ç›®æ ‡å°ºå¯¸ï¼Œé»˜è®¤ 1024
    
    Returns:
        RGB å›¾åƒæ•°ç»„ï¼Œå½¢çŠ¶ (1024, 1024, 3)ï¼Œdtype=uint8
    """
    # è§£ç  JPG
    img_arr = cv2.imdecode(np.frombuffer(jpg_bytes, dtype=np.uint8), cv2.IMREAD_COLOR)
    if img_arr is None:
        raise ValueError("æ— æ³•è§£ç  JPG å›¾åƒ")
    
    # è½¬æ¢ä¸º RGB
    img_rgb = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)
    
    # ç¡®ä¿å°ºå¯¸ä¸¥æ ¼ä¸º target_size x target_size
    if img_rgb.shape[:2] != (target_size, target_size):
        img_rgb = cv2.resize(
            img_rgb,
            (target_size, target_size),
            interpolation=cv2.INTER_LINEAR
        )
    
    # ç¡®ä¿æ˜¯ uint8
    return img_rgb.astype(np.uint8)  # (1024, 1024, 3)


# ==================== Worker å‡½æ•°ï¼ˆå¤šè¿›ç¨‹å¤„ç†ï¼‰ ====================

def process_single_pair(args: Tuple[str, bytes, bytes, int, int]) -> Optional[Dict]:
    """
    Worker è¿›ç¨‹æ‰§è¡Œçš„å‡½æ•°ï¼šæ¥æ”¶åŸå§‹å­—èŠ‚ï¼Œè¿”å›å¤„ç†å¥½çš„å®šé•¿å­—èŠ‚æ•°æ®
    
    è¿™æ˜¯ä¸€ä¸ªé¡¶çº§å‡½æ•°ï¼ˆå¿…é¡»åœ¨æ¨¡å—çº§åˆ«ï¼‰ï¼Œä»¥ä¾¿ multiprocessing å¯ä»¥ pickle å®ƒã€‚
    
    Args:
        args: (base_name, jpg_bytes, npz_bytes, img_size, mask_size)
    
    Returns:
        å¤„ç†ç»“æœå­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦å†™å…¥çš„äºŒè¿›åˆ¶æ•°æ®ï¼Œå¦‚æœå¤„ç†å¤±è´¥è¿”å› None
    """
    base_name, jpg_bytes, npz_bytes, img_size, mask_size = args
    
    try:
        # === 1. å¤„ç†å›¾åƒ (CPU å¯†é›†ï¼šJPG è§£ç  + Resize) ===
        img_arr = cv2.imdecode(np.frombuffer(jpg_bytes, dtype=np.uint8), cv2.IMREAD_COLOR)
        if img_arr is None:
            raise ValueError("æ— æ³•è§£ç  JPG å›¾åƒ")
        
        # è½¬æ¢ä¸º RGB
        img_rgb = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)
        
        # ç¡®ä¿å°ºå¯¸ä¸¥æ ¼ä¸º img_size x img_size
        if img_rgb.shape[:2] != (img_size, img_size):
            img_rgb = cv2.resize(
                img_rgb,
                (img_size, img_size),
                interpolation=cv2.INTER_LINEAR
            )
        
        img_raw = img_rgb.astype(np.uint8)
        
        # éªŒè¯å°ºå¯¸
        if img_raw.shape != (img_size, img_size, 3):
            raise ValueError(f"å›¾åƒå°ºå¯¸ä¸æ­£ç¡®: {img_raw.shape}, æœŸæœ›: ({img_size}, {img_size}, 3)")
        
        # === 2. å¤„ç† NPZ æ•°æ® (CPU å¯†é›†ï¼šNPZ åŠ è½½ + æ•°æ®è½¬æ¢) ===
        npz_buffer = io.BytesIO(npz_bytes)
        with np.load(npz_buffer, allow_pickle=True) as data:
            # A. Features (P4_S16 + P5_S32)
            if "P4_S16" in data:
                p4 = data["P4_S16"]
            elif "IMAGE_EMB_S16" in data:
                # å¦‚æœåªæœ‰ IMAGE_EMB_S16ï¼Œä½¿ç”¨å®ƒï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                p4 = data["IMAGE_EMB_S16"]
            else:
                raise KeyError("æœªæ‰¾åˆ° P4_S16 æˆ– IMAGE_EMB_S16")
            
            if "P5_S32" not in data:
                raise KeyError("æœªæ‰¾åˆ° P5_S32")
            p5 = data["P5_S32"]
            
            # ç¡®ä¿æ˜¯ numpy æ•°ç»„å¹¶è½¬æ¢ç±»å‹
            if not isinstance(p4, np.ndarray):
                p4 = np.array(p4, dtype=np.float32)
            else:
                p4 = p4.astype(np.float32)
            
            if not isinstance(p5, np.ndarray):
                p5 = np.array(p5, dtype=np.float32)
            else:
                p5 = p5.astype(np.float32)
            
            # ç¡®ä¿æœ‰ batch ç»´åº¦ï¼ˆå†æ¬¡æ£€æŸ¥æ˜¯å¦ä¸ºæ•°ç»„ï¼‰
            if not isinstance(p4, np.ndarray):
                raise ValueError(f"P4_S16 ä¸æ˜¯ numpy æ•°ç»„: {type(p4)}")
            if not isinstance(p5, np.ndarray):
                raise ValueError(f"P5_S32 ä¸æ˜¯ numpy æ•°ç»„: {type(p5)}")
            
            if p4.ndim == 3:
                p4 = p4[None, ...]
            if p5.ndim == 3:
                p5 = p5[None, ...]
            
            # éªŒè¯å½¢çŠ¶
            if p4.shape != (1, 256, 64, 64):
                raise ValueError(f"P4_S16 å½¢çŠ¶ä¸æ­£ç¡®: {p4.shape}, æœŸæœ›: (1, 256, 64, 64)")
            if p5.shape != (1, 256, 32, 32):
                raise ValueError(f"P5_S32 å½¢çŠ¶ä¸æ­£ç¡®: {p5.shape}, æœŸæœ›: (1, 256, 32, 32)")
            
            # B. Edge Maps
            # ç¡®ä¿å­—æ®µå­˜åœ¨å¹¶æ˜¯ numpy æ•°ç»„
            for key in ["edge_256x256", "edge_64x64", "edge_32x32"]:
                if key not in data:
                    raise KeyError(f"ç¼ºå¤±å­—æ®µ: {key}")
            
            raw_edge_256 = data["edge_256x256"]
            raw_edge_64 = data["edge_64x64"]
            raw_edge_32 = data["edge_32x32"]
            
            # å¤„ç† 0 ç»´æ•°ç»„ï¼ˆæ ‡é‡æ•°ç»„ï¼‰
            if isinstance(raw_edge_256, np.ndarray) and raw_edge_256.ndim == 0:
                raise ValueError(f"edge_256x256 æ˜¯æ ‡é‡æ•°ç»„ï¼ŒæœŸæœ› 2D æ•°ç»„")
            if isinstance(raw_edge_64, np.ndarray) and raw_edge_64.ndim == 0:
                raise ValueError(f"edge_64x64 æ˜¯æ ‡é‡æ•°ç»„ï¼ŒæœŸæœ› 2D æ•°ç»„")
            if isinstance(raw_edge_32, np.ndarray) and raw_edge_32.ndim == 0:
                raise ValueError(f"edge_32x32 æ˜¯æ ‡é‡æ•°ç»„ï¼ŒæœŸæœ› 2D æ•°ç»„")
            
            if not isinstance(raw_edge_256, np.ndarray):
                raw_edge_256 = np.array(raw_edge_256, dtype=np.uint8)
            if not isinstance(raw_edge_64, np.ndarray):
                raw_edge_64 = np.array(raw_edge_64, dtype=np.uint8)
            if not isinstance(raw_edge_32, np.ndarray):
                raw_edge_32 = np.array(raw_edge_32, dtype=np.uint8)
            
            edge_256 = raw_edge_256.astype(np.uint8)
            edge_64 = raw_edge_64.astype(np.uint8)
            edge_32 = raw_edge_32.astype(np.uint8)
            
            # éªŒè¯å½¢çŠ¶
            if edge_256.shape != (256, 256):
                raise ValueError(f"edge_256x256 å½¢çŠ¶ä¸æ­£ç¡®: {edge_256.shape}, æœŸæœ›: (256, 256)")
            if edge_64.shape != (64, 64):
                raise ValueError(f"edge_64x64 å½¢çŠ¶ä¸æ­£ç¡®: {edge_64.shape}, æœŸæœ›: (64, 64)")
            if edge_32.shape != (32, 32):
                raise ValueError(f"edge_32x32 å½¢çŠ¶ä¸æ­£ç¡®: {edge_32.shape}, æœŸæœ›: (32, 32)")
            
            # C. Weight Maps
            # ç¡®ä¿å­—æ®µå­˜åœ¨å¹¶æ˜¯ numpy æ•°ç»„
            weight_map_keys = [
                "fg_map_128x128", "bg_map_128x128",
                "fg_map_64x64", "bg_map_64x64",
                "fg_map_32x32", "bg_map_32x32",
            ]
            for key in weight_map_keys:
                if key not in data:
                    raise KeyError(f"ç¼ºå¤±å­—æ®µ: {key}")
            
            weight_maps_data = {
                key: data[key] for key in weight_map_keys
            }
            
            weight_maps = {}
            for name, raw_arr in weight_maps_data.items():
                # æ£€æŸ¥æ˜¯å¦ä¸ºæ ‡é‡æ•°ç»„
                if isinstance(raw_arr, np.ndarray) and raw_arr.ndim == 0:
                    raise ValueError(f"{name} æ˜¯æ ‡é‡æ•°ç»„ï¼ŒæœŸæœ› 2D æ•°ç»„")
                if not isinstance(raw_arr, np.ndarray):
                    raw_arr = np.array(raw_arr, dtype=np.float32)
                weight_maps[name] = raw_arr.astype(np.float32)
            
            fg_128 = weight_maps["fg_map_128x128"]
            bg_128 = weight_maps["bg_map_128x128"]
            fg_64 = weight_maps["fg_map_64x64"]
            bg_64 = weight_maps["bg_map_64x64"]
            fg_32 = weight_maps["fg_map_32x32"]
            bg_32 = weight_maps["bg_map_32x32"]
            
            # éªŒè¯å½¢çŠ¶
            for name, arr in [
                ("fg_map_128x128", fg_128),
                ("bg_map_128x128", bg_128),
                ("fg_map_64x64", fg_64),
                ("bg_map_64x64", bg_64),
                ("fg_map_32x32", fg_32),
                ("bg_map_32x32", bg_32),
            ]:
                expected_shape = tuple(map(int, name.split('_')[-1].split('x')))
                if arr.shape != expected_shape:
                    raise ValueError(f"{name} å½¢çŠ¶ä¸æ­£ç¡®: {arr.shape}, æœŸæœ›: {expected_shape}")
            
            # D. BBoxes (è§„èŒƒåŒ–)
            if "bboxes" in data:
                raw_bbox = data["bboxes"]
            else:
                raw_bbox = np.empty((0, 4), dtype=np.float32)
            
            fixed_bbox, num_bboxes, has_bbox = normalize_bbox(raw_bbox)
            
            # E. Masks (è§„èŒƒåŒ–)
            if "masks" in data:
                raw_mask = data["masks"]
                fixed_mask = normalize_mask(raw_mask, target_size=mask_size)
            else:
                fixed_mask = np.zeros((1, mask_size, mask_size), dtype=np.uint8)
            
            # éªŒè¯æ©ç å½¢çŠ¶
            if fixed_mask.shape != (1, mask_size, mask_size):
                raise ValueError(f"è§„èŒƒåŒ–åçš„æ©ç å½¢çŠ¶ä¸æ­£ç¡®: {fixed_mask.shape}, æœŸæœ›: (1, {mask_size}, {mask_size})")
            
            # F. Metadata
            if "image_shape" in data:
                raw_shape = data["image_shape"]
                # å…ˆè½¬æ¢ä¸º numpy æ•°ç»„ï¼ˆå…¼å®¹æ ‡é‡ã€åˆ—è¡¨ã€æ•°ç»„ç­‰ï¼‰
                if not isinstance(raw_shape, np.ndarray):
                    raw_shape = np.array(raw_shape, dtype=np.int32)
                else:
                    raw_shape = raw_shape.astype(np.int32)
                
                # å¤„ç†ä¸åŒå½¢çŠ¶
                if raw_shape.ndim == 0:
                    # æ ‡é‡ï¼Œä½¿ç”¨é»˜è®¤å½¢çŠ¶
                    image_shape = np.array([img_size, img_size, 3], dtype=np.int32)
                elif raw_shape.size == 3:
                    # æœ‰3ä¸ªå…ƒç´ ï¼Œé‡å¡‘ä¸º (3,)
                    image_shape = raw_shape.reshape(3) if raw_shape.ndim > 1 else raw_shape.flatten()
                else:
                    raise ValueError(f"image_shape å½¢çŠ¶ä¸æ­£ç¡®: {raw_shape.shape}, æœŸæœ›: (3,)")
            else:
                image_shape = np.array([img_size, img_size, 3], dtype=np.int32)
            
            # å…ƒæ•°æ®: [num_bboxes, has_bbox, H, W, C] (5ä¸ª int32)
            meta_vec = np.array(
                [num_bboxes, has_bbox, image_shape[0], image_shape[1], image_shape[2]],
                dtype=np.int32
            )
        
        # === 3. è¿”å›æ‰€æœ‰å¤„ç†å¥½çš„äºŒè¿›åˆ¶æ•°æ® ===
        return {
            "name": base_name,
            "img": img_raw.tobytes(),
            "feat_p4": p4.tobytes(),
            "feat_p5": p5.tobytes(),
            "edge_256": edge_256.tobytes(),
            "edge_64": edge_64.tobytes(),
            "edge_32": edge_32.tobytes(),
            "fg_128": fg_128.tobytes(),
            "bg_128": bg_128.tobytes(),
            "fg_64": fg_64.tobytes(),
            "bg_64": bg_64.tobytes(),
            "fg_32": fg_32.tobytes(),
            "bg_32": bg_32.tobytes(),
            "bbox": fixed_bbox.tobytes(),
            "mask": fixed_mask.tobytes(),
            "meta": meta_vec.tobytes(),
        }
    
    except Exception as e:
        # è¿”å›é”™è¯¯ä¿¡æ¯ï¼ˆåŒ…å«è¯¦ç»†å †æ ˆè·Ÿè¸ªï¼Œæ–¹ä¾¿è°ƒè¯•ï¼‰
        import traceback
        error_detail = f"{type(e).__name__}: {str(e)}"
        # åªåœ¨å¼€å‘æ¨¡å¼ä¸‹åŒ…å«å®Œæ•´å †æ ˆ
        if len(str(e)) < 200:  # å¦‚æœé”™è¯¯ä¿¡æ¯ç®€çŸ­ï¼Œå¯èƒ½ç¼ºå°‘ä¸Šä¸‹æ–‡
            error_detail += f"\n{traceback.format_exc()}"
        return {
            "name": base_name,
            "error": error_detail,
        }


# ==================== ä¸»è½¬æ¢å‡½æ•° ====================

def convert_tar_to_bin(
    tar_path: Path,
    output_dir: Path,
    max_samples: Optional[int] = None,
    model_type: str = "sam2.1_hiera_b+",
    verbose: bool = True,
    max_workers: Optional[int] = None,
    append: bool = False,
) -> Dict[str, int]:
    """
    å°† TAR æ–‡ä»¶è½¬æ¢ä¸ºå®šé•¿äºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆå¤šè¿›ç¨‹å¹¶è¡Œç‰ˆæœ¬ï¼‰
    
    Args:
        tar_path: TAR æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        max_samples: æœ€å¤§è½¬æ¢æ ·æœ¬æ•°
        model_type: æ¨¡å‹ç±»å‹ï¼ˆå†™å…¥ config.jsonï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        max_workers: å¹¶è¡Œ Worker æ•°é‡ï¼ˆNone è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒï¼‰
        append: æ˜¯å¦è¿½åŠ æ¨¡å¼ï¼ˆTrue=è¿½åŠ ï¼ŒFalse=è¦†ç›–ï¼‰
    
    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è®¾ç½®å¹¶è¡Œåº¦
    if max_workers is None:
        max_workers = multiprocessing.cpu_count()
    
    # å†³å®šæ–‡ä»¶æ‰“å¼€æ¨¡å¼
    mode_bin = "ab" if append else "wb"
    mode_txt = "a" if append else "w"
    
    if verbose:
        mode_str = "è¿½åŠ " if append else "è¦†ç›–"
        print(f"ğŸš€ å¯åŠ¨å¹¶è¡Œå¤„ç†ï¼Œä½¿ç”¨ {max_workers} ä¸ª Worker è¿›ç¨‹... (æ¨¡å¼: {mode_str})")
    
    # æ‰“å¼€è¾“å‡ºæ–‡ä»¶ï¼ˆæ ¹æ® append å‚æ•°å†³å®šæ¨¡å¼ï¼‰
    files = {
        "images": open(output_dir / "images.bin", mode_bin),
        "features": open(output_dir / "features.bin", mode_bin),
        "edge_maps": open(output_dir / "edge_maps.bin", mode_bin),
        "weight_maps": open(output_dir / "weight_maps.bin", mode_bin),
        "bboxes": open(output_dir / "bboxes.bin", mode_bin),
        "masks": open(output_dir / "masks.bin", mode_bin),
        "metadata": open(output_dir / "metadata.bin", mode_bin),
    }
    f_keys = open(output_dir / "keys.txt", mode_txt, encoding="utf-8")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "total": 0,
        "success": 0,
        "skipped": 0,
        "errors": 0,
        "error_details": [],
    }
    
    # ç”¨äºç¼“å­˜æˆå¯¹çš„ jpg å’Œ npzï¼ˆä¸»è¿›ç¨‹å¿«é€Ÿè¯»å–ï¼‰
    buffer: Dict[str, Dict[str, bytes]] = {}
    
    # æ‰¹å¤„ç†é…ç½®ï¼šæ§åˆ¶å†…å­˜ä¸­çš„ä»»åŠ¡ç§¯å‹æ•°é‡
    BATCH_SIZE = max_workers * 4
    
    try:
        with tarfile.open(tar_path, "r|*") as tar:
            # åˆ›å»ºè¿›ç¨‹æ± 
            with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:
                # å¾…å¤„ç†çš„ä»»åŠ¡åˆ—è¡¨ï¼ˆFuture å¯¹è±¡ï¼‰
                pending_futures: List[concurrent.futures.Future] = []
                
                # è¿›åº¦æ¡ï¼ˆç”¨äºæ˜¾ç¤ºè¯»å–è¿›åº¦ï¼‰
                if verbose and tqdm:
                    read_pbar = tqdm(desc="è¯»å– TAR", unit="æ–‡ä»¶")
                else:
                    read_pbar = None
                
                # ç¬¬ä¸€é˜¶æ®µï¼šå¿«é€Ÿè¯»å– TAR æ–‡ä»¶ï¼Œæäº¤ä»»åŠ¡åˆ°è¿›ç¨‹æ± ï¼ˆç”Ÿäº§è€…ï¼‰
                for member in tar:
                    if read_pbar is not None:
                        read_pbar.update(1)
                    
                    if not member.isfile():
                        continue
                    
                    # æå–æ–‡ä»¶åå’Œæ‰©å±•å
                    name = member.name
                    base_name = os.path.splitext(os.path.basename(name))[0]
                    ext = os.path.splitext(name)[1].lower()
                    
                    # åªå¤„ç† .jpg å’Œ .npz æ–‡ä»¶
                    if ext not in ['.jpg', '.npz']:
                        continue
                    
                    # æ ‡å‡†åŒ– base_nameï¼ˆç§»é™¤ _features åç¼€ï¼‰
                    if base_name.endswith('_features'):
                        base_name = base_name[:-9]  # ç§»é™¤ '_features'
                    elif base_name.endswith('_sam2_features'):
                        base_name = base_name[:-15]  # ç§»é™¤ '_sam2_features'
                    
                    # è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆåªè¯»å–åŸå§‹ bytesï¼Œä¸è¿›è¡Œè§£ç ï¼‰
                    f = tar.extractfile(member)
                    if f is None:
                        continue
                    content = f.read()
                    f.close()
                    
                    # ç¼“å­˜æ–‡ä»¶
                    if base_name not in buffer:
                        buffer[base_name] = {}
                    buffer[base_name][ext] = content
                    
                    # å¦‚æœä¸€å¯¹æ–‡ä»¶éƒ½é½äº† (.jpg å’Œ .npz)
                    if '.jpg' in buffer[base_name] and '.npz' in buffer[base_name]:
                        stats["total"] += 1
                        
                        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æ ·æœ¬æ•°
                        if max_samples is not None and stats["success"] >= max_samples:
                            del buffer[base_name]
                            continue
                        
                        # æäº¤ä»»åŠ¡åˆ°è¿›ç¨‹æ± ï¼ˆä¼ é€’åŸå§‹ bytesï¼‰
                        jpg_bytes = buffer[base_name]['.jpg']
                        npz_bytes = buffer[base_name]['.npz']
                        
                        future = executor.submit(
                            process_single_pair,
                            (base_name, jpg_bytes, npz_bytes, IMG_SIZE, MASK_SIZE)
                        )
                        pending_futures.append(future)
                        
                        # æ¸…ç† bufferï¼ˆå·²æäº¤å¤„ç†ï¼‰
                        del buffer[base_name]
                        
                        # å†…å­˜æ§åˆ¶ï¼šå¦‚æœç§¯å‹ä»»åŠ¡å¤ªå¤šï¼Œå…ˆå¤„ç†å®Œä¸€æ‰¹å†ç»§ç»­è¯» TAR
                        if len(pending_futures) >= BATCH_SIZE:
                            # å¤„ç†ä¸€æ‰¹ä»»åŠ¡ï¼ˆæ¶ˆè´¹è€…ï¼‰
                            _process_batch_results(
                                pending_futures, files, f_keys, stats, verbose, read_pbar
                            )
                            pending_futures.clear()
                
                # å…³é—­è¯»å–è¿›åº¦æ¡
                if read_pbar is not None:
                    read_pbar.close()
                
                # ç¬¬äºŒé˜¶æ®µï¼šå¤„ç†å‰©ä½™çš„ä»»åŠ¡
                if pending_futures:
                    if verbose and tqdm:
                        process_pbar = tqdm(
                            desc="å¤„ç†ä¸­",
                            total=len(pending_futures),
                            unit="æ ·æœ¬"
                        )
                    else:
                        process_pbar = None
                    
                    _process_batch_results(
                        pending_futures, files, f_keys, stats, verbose, process_pbar
                    )
                    
                    if process_pbar is not None:
                        process_pbar.close()
    
    finally:
        # å…³é—­æ‰€æœ‰æ–‡ä»¶
        for f in files.values():
            f.close()
        f_keys.close()
    
    # ç”Ÿæˆ/æ›´æ–° config.json
    # model_type å­˜åˆ° config.jsonï¼ˆä¸å†™å…¥äºŒè¿›åˆ¶ï¼‰
    config_path = output_dir / "config.json"
    
    # è®¡ç®—æ€»æ ·æœ¬æ•°ï¼ˆè¿½åŠ æ¨¡å¼éœ€è¦ç´¯åŠ ï¼‰
    total_samples = stats["success"]
    if append and config_path.exists():
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                old_config = json.load(f)
                # ç´¯åŠ æ€»æ ·æœ¬æ•°
                if "total_samples" in old_config:
                    old_total = int(old_config["total_samples"])
                    total_samples = old_total + stats["success"]
                    if verbose:
                        print(f"ğŸ“Š ç´¯åŠ æ ·æœ¬æ•°: {old_total} (å·²æœ‰) + {stats['success']} (æœ¬æ¬¡) = {total_samples} (æ€»è®¡)")
        except Exception as e:
            if verbose:
                print(f"âš ï¸  è­¦å‘Š: è¯»å–æ—§ config.json å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨æœ¬æ¬¡æ ·æœ¬æ•°")
    
    config = {
        "model_type": model_type,
        "image_size": IMG_SIZE,
        "mask_size": MASK_SIZE,
        "total_samples": total_samples,  # ä½¿ç”¨ç´¯åŠ åçš„å€¼
        "version": "1.0",
        "description": "SA-1B dataset converted to fixed-length binary format",
        "sample_sizes": {
            "image_bytes": SAMPLE_SIZE_IMAGE,
            "features_bytes": SAMPLE_SIZE_FEATURES,
            "edge_maps_bytes": SAMPLE_SIZE_EDGE_MAPS,
            "weight_maps_bytes": SAMPLE_SIZE_WEIGHT_MAPS,
            "bboxes_bytes": SAMPLE_SIZE_BBOX,
            "masks_bytes": SAMPLE_SIZE_MASK,
            "metadata_bytes": SAMPLE_SIZE_METADATA,
        },
        "interpolation_method": "cv2.INTER_AREA",
        "mask_binarization_threshold": 0.5,
    }
    
    with open(config_path, "w", encoding="utf-8") as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    return stats


def _process_batch_results(
    futures: List[concurrent.futures.Future],
    files: Dict[str, any],
    f_keys: any,
    stats: Dict[str, int],
    verbose: bool,
    pbar: Optional[tqdm] = None,
) -> None:
    """
    å¤„ç†ä¸€æ‰¹ä»»åŠ¡çš„ç»“æœå¹¶å†™å…¥æ–‡ä»¶ï¼ˆè¾…åŠ©å‡½æ•°ï¼‰
    
    Args:
        futures: Future å¯¹è±¡åˆ—è¡¨
        files: è¾“å‡ºæ–‡ä»¶å¥æŸ„å­—å…¸
        f_keys: keys.txt æ–‡ä»¶å¥æŸ„
        stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        pbar: è¿›åº¦æ¡å¯¹è±¡ï¼ˆå¯é€‰ï¼‰
    """
    for future in concurrent.futures.as_completed(futures):
        result = future.result()
        
        if result is None:
            stats["errors"] += 1
            continue
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if "error" in result:
            stats["errors"] += 1
            error_msg = f"{result['name']}: {result['error']}"
            stats["error_details"].append(error_msg)
            if verbose:
                print(f"\n[é”™è¯¯] {error_msg}", file=sys.stderr)
            continue
        
        # å†™å…¥æ‰€æœ‰å¤„ç†å¥½çš„äºŒè¿›åˆ¶æ•°æ®
        try:
            files["images"].write(result["img"])
            files["features"].write(result["feat_p4"])
            files["features"].write(result["feat_p5"])
            files["edge_maps"].write(result["edge_256"])
            files["edge_maps"].write(result["edge_64"])
            files["edge_maps"].write(result["edge_32"])
            files["weight_maps"].write(result["fg_128"])
            files["weight_maps"].write(result["bg_128"])
            files["weight_maps"].write(result["fg_64"])
            files["weight_maps"].write(result["bg_64"])
            files["weight_maps"].write(result["fg_32"])
            files["weight_maps"].write(result["bg_32"])
            files["bboxes"].write(result["bbox"])
            files["masks"].write(result["mask"])
            files["metadata"].write(result["meta"])
            
            # è®°å½• Key
            f_keys.write(result["name"] + "\n")
            f_keys.flush()
            
            stats["success"] += 1
            
            if pbar is not None:
                pbar.update(1)
                pbar.set_postfix({
                    "æˆåŠŸ": stats["success"],
                    "é”™è¯¯": stats["errors"]
                })
        
        except Exception as e:
            stats["errors"] += 1
            error_msg = f"{result['name']}: å†™å…¥å¤±è´¥ - {str(e)}"
            stats["error_details"].append(error_msg)
            if verbose:
                print(f"\n[é”™è¯¯] {error_msg}", file=sys.stderr)


# ==================== ä¸»å‡½æ•° ====================

def main():
    parser = argparse.ArgumentParser(
        description="å°† TAR æ–‡ä»¶è½¬æ¢ä¸ºå®šé•¿äºŒè¿›åˆ¶æ–‡ä»¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è½¬æ¢å•ä¸ª shardï¼ˆä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒï¼‰
  python convert_tar_to_bin.py \\
      --tar-path /path/to/sa1b_shard_00000.tar \\
      --output-dir ./binary_dataset \\
      --model-type "sam2.1_hiera_b+"
  
  # é™åˆ¶è½¬æ¢æ ·æœ¬æ•°ï¼ˆæµ‹è¯•ç”¨ï¼‰
  python convert_tar_to_bin.py \\
      --tar-path /path/to/sa1b_shard_00000.tar \\
      --output-dir ./binary_dataset \\
      --max-samples 100
  
  # æŒ‡å®š Worker è¿›ç¨‹æ•°ï¼ˆä¾‹å¦‚ï¼š32 æ ¸æœåŠ¡å™¨ä½¿ç”¨ 30 ä¸ªè¿›ç¨‹ï¼‰
  python convert_tar_to_bin.py \\
      --tar-path /path/to/sa1b_shard_00000.tar \\
      --output-dir ./binary_dataset \\
      --workers 30
        """
    )
    
    parser.add_argument(
        "--tar-path",
        type=Path,
        required=True,
        help="è¾“å…¥çš„ TAR æ–‡ä»¶è·¯å¾„"
    )
    
    parser.add_argument(
        "--output-dir",
        type=Path,
        required=True,
        help="è¾“å‡ºç›®å½•ï¼ˆå°†åˆ›å»º .bin æ–‡ä»¶ï¼‰"
    )
    
    parser.add_argument(
        "--max-samples",
        type=int,
        default=None,
        help="æœ€å¤§è½¬æ¢æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼Œé»˜è®¤ï¼šå…¨éƒ¨ï¼‰"
    )
    
    parser.add_argument(
        "--model-type",
        type=str,
        default="sam2.1_hiera_b+",
        help="æ¨¡å‹ç±»å‹ï¼ˆå°†å†™å…¥ config.jsonï¼‰"
    )
    
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="é™é»˜æ¨¡å¼ï¼ˆä¸æ˜¾ç¤ºè¿›åº¦æ¡ï¼‰"
    )
    
    parser.add_argument(
        "--workers",
        type=int,
        default=None,
        help=f"å¹¶è¡Œ Worker è¿›ç¨‹æ•°é‡ï¼ˆé»˜è®¤ï¼šä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒï¼Œå½“å‰ä¸º {multiprocessing.cpu_count()}ï¼‰"
    )
    
    parser.add_argument(
        "--append",
        action="store_true",
        help="è¿½åŠ æ¨¡å¼ï¼ˆä¸è¦†ç›–ç°æœ‰æ–‡ä»¶ï¼Œç”¨äºæ‰¹é‡è½¬æ¢å¤šä¸ª shard æ—¶ä»ç¬¬äºŒä¸ªå¼€å§‹ä½¿ç”¨ï¼‰"
    )
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not args.tar_path.exists():
        print(f"âŒ é”™è¯¯ï¼šTAR æ–‡ä»¶ä¸å­˜åœ¨: {args.tar_path}", file=sys.stderr)
        sys.exit(1)
    
    # æ‰§è¡Œè½¬æ¢
    print(f"ğŸ“¦ å¼€å§‹è½¬æ¢: {args.tar_path}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    if args.max_samples:
        print(f"ğŸ”¢ æœ€å¤§æ ·æœ¬æ•°: {args.max_samples}")
    if args.workers:
        print(f"ğŸ‘· Worker è¿›ç¨‹æ•°: {args.workers}")
    print()
    
    stats = convert_tar_to_bin(
        tar_path=args.tar_path,
        output_dir=args.output_dir,
        max_samples=args.max_samples,
        model_type=args.model_type,
        verbose=not args.quiet,
        max_workers=args.workers,
        append=args.append,
    )
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*80)
    print("ğŸ“Š è½¬æ¢å®Œæˆï¼")
    print("="*80)
    print(f"æ€»æ ·æœ¬æ•°: {stats['total']}")
    print(f"æˆåŠŸè½¬æ¢: {stats['success']}")
    print(f"è·³è¿‡: {stats['skipped']}")
    print(f"é”™è¯¯: {stats['errors']}")
    
    if stats['error_details'] and len(stats['error_details']) <= 10:
        print("\né”™è¯¯è¯¦æƒ…:")
        for err in stats['error_details']:
            print(f"  - {err}")
    elif stats['error_details']:
        print(f"\né”™è¯¯è¯¦æƒ…ï¼ˆå‰10ä¸ªï¼‰:")
        for err in stats['error_details'][:10]:
            print(f"  - {err}")
        print(f"  ... è¿˜æœ‰ {len(stats['error_details']) - 10} ä¸ªé”™è¯¯")
    
    print()
    print(f"âœ… è¾“å‡ºæ–‡ä»¶å·²ä¿å­˜åˆ°: {args.output_dir}")
    print("="*80)


if __name__ == "__main__":
    main()

