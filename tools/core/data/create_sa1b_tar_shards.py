#!/usr/bin/env python3
"""
SA-1B TAR Sharding Tool (Extreme Performance Edition)

é’ˆå¯¹ 100æ ¸+ CPU å’Œé«˜é€Ÿå­˜å‚¨ä¼˜åŒ–çš„æ‰“åŒ…å·¥å…·ã€‚

ä¸»è¦ä¼˜åŒ–ï¼š
1. ä½¿ç”¨ os.scandir æ›¿ä»£ globï¼Œé€Ÿåº¦æå‡æ˜æ˜¾
2. å…¨ç¨‹ä½¿ç”¨ str æ›¿ä»£ Path å¯¹è±¡ï¼Œå¤§å¹…é™ä½å†…å­˜å ç”¨å’Œå¤šè¿›ç¨‹åºåˆ—åŒ–å¼€é”€
3. tarfile å†™å…¥å¼€å¯ 4MB ç¼“å†²åŒºï¼Œä¼˜åŒ– I/Oåå
4. ç¦ç”¨ä¸å¿…è¦çš„ GCï¼Œæè‡´å‹æ¦¨ CPU

ç”¨æ³•:
    python create_sa1b_tar_shards.py \
        --features-dir /path/to/npz \
        --images-dir /path/to/jpg \
        --output-dir /path/to/shards \
        --workers 80
"""

import argparse
import os
import re
import tarfile
import time
import gc
import multiprocessing as mp
from pathlib import Path
from typing import Dict, List, Set, Tuple
try:
    from tqdm import tqdm
except ImportError:  # pragma: no cover
    tqdm = None


# ==========================================
# æ ¸å¿ƒå·¥ä½œå‡½æ•° (Worker)
# ==========================================

def _write_one_shard(args):
    """
    å¤šè¿›ç¨‹ Worker: å†™å…¥å•ä¸ª Tar Shard
    
    Args:
        args: (shard_idx, shard_data, output_dir, mode, suffix)
            shard_data: [(npz_path_str, img_path_str, image_id_str), ...]
    """
    shard_idx, shard_data, output_dir, mode, suffix, overwrite = args
    
    # æ„é€ è¾“å‡ºæ–‡ä»¶å
    shard_name = f"sa1b_shard_{shard_idx:05d}{suffix}"
    shard_path = os.path.join(output_dir, shard_name)
    
    count = 0
    
    if (not overwrite) and os.path.exists(shard_path):
        return shard_idx, 0, "skip_existing"

    try:
        # å¼€å¯å¤§ç¼“å†²åŒº (4MB)ï¼Œè¿™å¯¹å¤§æ‰¹é‡å°æ–‡ä»¶å†™å…¥è‡³å…³é‡è¦
        # format=tarfile.PAX_FORMAT æ”¯æŒé•¿æ–‡ä»¶åå’Œå¤§äº8GBçš„æ–‡ä»¶
        with tarfile.open(shard_path, mode, bufsize=4*1024*1024, format=tarfile.PAX_FORMAT) as tar:
            for npz_path, img_path, image_id in shard_data:
                # 1. æ·»åŠ  NPZ
                # ä¿æŒåŸå: sa_12345_features.npz
                npz_arcname = os.path.basename(npz_path)
                tar.add(npz_path, arcname=npz_arcname)
                
                # 2. æ·»åŠ  JPG
                # è§„èŒƒåŒ–å‘½å: sa_12345.jpg
                # image_id å·²ç»æ˜¯è§„èŒƒåŒ–çš„ key (sa_xxxx)
                img_arcname = f"{image_id}.jpg"
                tar.add(img_path, arcname=img_arcname)
                
                count += 1
                
        return shard_idx, count, None
    except Exception as e:
        return shard_idx, 0, str(e)


# ==========================================
# é«˜æ€§èƒ½æ‰«æä¸ç´¢å¼•å‡½æ•°
# ==========================================

def fast_scan_images(images_dir: str) -> Dict[str, str]:
    """
    ä½¿ç”¨ os.scandir å¿«é€Ÿæ‰«æç›®å½•å¹¶å»ºç«‹ç´¢å¼•ã€‚
    
    Returns:
        { 'sa_12345': '/full/path/to/sa_12345.jpg' }
    """
    print(f"[Scanning] æ­£åœ¨æ‰«æå›¾åƒç›®å½•: {images_dir} ...")
    index = {}
    
    try:
        # ä¸´æ—¶ç¦ç”¨ GC åŠ é€Ÿå¤§é‡å¯¹è±¡çš„åˆ›å»º
        gc.disable()
        
        # os.scandir æ˜¯ç›®å‰ Python æœ€å¿«çš„æ–‡ä»¶éå†æ–¹å¼
        with os.scandir(images_dir) as it:
            for entry in it:
                if entry.is_file() and entry.name.endswith('.jpg'):
                    # è§£ææ–‡ä»¶å sa_123.jpg -> sa_123
                    # é¿å…ä½¿ç”¨ splitextï¼Œç›´æ¥åˆ‡ç‰‡æ›´å¿«
                    name = entry.name
                    stem = name[:-4]  # å»æ‰ .jpg
                    
                    # è§„èŒƒåŒ– Key: ç¡®ä¿æ˜¯ sa_ å¼€å¤´
                    if stem.startswith('sa_'):
                        key = stem
                    else:
                        key = 'sa_' + stem
                        
                    index[key] = entry.path
    finally:
        gc.enable()
        
    print(f"[Index] å›¾åƒæ‰«æå®Œæˆï¼Œç´¢å¼•å¤§å°: {len(index)}")
    return index


def fast_scan_npz(features_dir: str) -> List[str]:
    """
    å¿«é€Ÿæ‰«æ NPZ æ–‡ä»¶åˆ—è¡¨
    
    Returns:
        ['/full/path/to/sa_123_features.npz', ...]
    """
    print(f"[Scanning] æ­£åœ¨æ‰«æç‰¹å¾ç›®å½•: {features_dir} ...")
    npz_files = []
    
    try:
        gc.disable()
        with os.scandir(features_dir) as it:
            for entry in it:
                if entry.is_file() and entry.name.endswith('_features.npz'):
                    npz_files.append(entry.path)
    finally:
        gc.enable()
    
    # æ’åºä»¥ä¿è¯ Shard å†…å®¹çš„ç¡®å®šæ€§
    npz_files.sort()
    print(f"[Index] ç‰¹å¾æ‰«æå®Œæˆï¼Œå…±å‘ç°: {len(npz_files)} ä¸ª NPZ")
    return npz_files


def match_pairs(npz_files: List[str], image_index: Dict[str, str], max_samples: int = None) -> Tuple[List[Tuple[str, str, str]], List[str]]:
    """
    åŒ¹é… NPZ å’Œ JPG
    
    Returns:
        (pairs, missing)
        pairs: [(npz_path_str, img_path_str, image_id_str), ...]
        missing: [image_id_str, ...]
    """
    pairs = []
    missing = []
    
    print("[Matching] å¼€å§‹åŒ¹é… NPZ å’Œ JPG...")
    
    iterator = npz_files
    if max_samples:
        iterator = npz_files[:max_samples]
    
    for npz_path in tqdm(iterator, desc="Matching", unit="file"):
        # ä»è·¯å¾„æå–æ–‡ä»¶å: /path/to/sa_123_features.npz -> sa_123
        filename = os.path.basename(npz_path)
        # å»æ‰ _features.npz (é•¿åº¦ä¸º 13)
        image_id = filename[:-13]
        
        img_path = image_index.get(image_id)
        
        if img_path:
            pairs.append((npz_path, img_path, image_id))
        else:
            missing.append(image_id)
            
    print(f"[Result] åŒ¹é…æˆåŠŸ: {len(pairs)}, ç¼ºå¤±å›¾åƒ: {len(missing)}")
    if missing and len(missing) <= 10:
        print(f"[WARN] ç¼ºå¤± image_id ç¤ºä¾‹: {missing[:10]}")
    
    return pairs, missing


# ==========================================
# ä¸»é€»è¾‘
# ==========================================

def _scan_existing_shards(output_dir: str) -> Set[int]:
    """
    æ‰«æå·²å­˜åœ¨çš„ shardï¼Œè¿”å›å…¶ç´¢å¼•é›†åˆï¼ˆå¦‚ 0, 1, 2 ...ï¼‰
    """
    if not os.path.isdir(output_dir):
        return set()

    shard_indices: Set[int] = set()
    pattern = re.compile(r"sa1b_shard_(\d+)\.tar(\.\w+)?$")

    with os.scandir(output_dir) as it:
        for entry in it:
            if not entry.is_file():
                continue
            match = pattern.match(entry.name)
            if match:
                shard_indices.add(int(match.group(1)))

    return shard_indices


def create_tar_shards(
    features_dir: str,
    images_dir: str,
    output_dir: str,
    shard_size: int = 1024,
    compress: str | None = None,
    max_samples: int | None = None,
    workers: int = 8,
    overwrite_existing: bool = False,
) -> None:
    """
    åˆ›å»º tar shards
    
    Args:
        features_dir: NPZ ç‰¹å¾æ–‡ä»¶ç›®å½•ï¼ˆå­—ç¬¦ä¸²è·¯å¾„ï¼‰
        images_dir: Resize åçš„ JPG å›¾åƒç›®å½•ï¼ˆå­—ç¬¦ä¸²è·¯å¾„ï¼‰
        output_dir: è¾“å‡º Tar Shard ç›®å½•ï¼ˆå­—ç¬¦ä¸²è·¯å¾„ï¼‰
        shard_size: æ¯ä¸ª Shard çš„æ ·æœ¬æ•°
        compress: å‹ç¼©æ ¼å¼ ("gz", "bz2", "xz" æˆ– None)
        max_samples: è°ƒè¯•ç”¨: æœ€å¤§å¤„ç†æ ·æœ¬æ•°
        workers: å·¥ä½œè¿›ç¨‹æ•°
    """
    t0 = time.time()
    
    # 1. å»ºç«‹ç´¢å¼• (å•çº¿ç¨‹æé€Ÿæ‰«æ)
    # å¯¹äºå•ä¸ªå¤§ç›®å½•ï¼ŒPythonçš„å¤šçº¿ç¨‹/å¤šè¿›ç¨‹æ‰«æç”±äºGILå’ŒOSé”ï¼Œå¾€å¾€ä¸å¦‚å•çº¿ç¨‹ scandir å¿«
    image_index = fast_scan_images(images_dir)
    npz_files = fast_scan_npz(features_dir)
    
    # 2. åŒ¹é…
    pairs, missing = match_pairs(npz_files, image_index, max_samples)
    if not pairs:
        raise RuntimeError("æ²¡æœ‰æ‰¾åˆ°ä»»ä½• npz + jpg é…å¯¹ï¼Œè¯·æ£€æŸ¥è·¯å¾„å’Œå‘½åè§„åˆ™ã€‚")
    
    # 3. å‡†å¤‡åˆ†ç‰‡ä»»åŠ¡
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # è®¡ç®— Shard æ•°é‡
    num_shards = (len(pairs) + shard_size - 1) // shard_size
    print(f"[Plan] è®¡åˆ’ç”Ÿæˆ {num_shards} ä¸ª Shards, æ¯ä¸ªåŒ…å«çº¦ {shard_size} ä¸ªæ ·æœ¬")

    existing_indices = _scan_existing_shards(output_dir)
    if existing_indices and not overwrite_existing:
        print(f"[Resume] æ£€æµ‹åˆ° {len(existing_indices)} ä¸ªå·²å­˜åœ¨çš„ shardï¼Œå°†è‡ªåŠ¨è·³è¿‡åŒåæ–‡ä»¶ï¼ˆä½¿ç”¨ --overwrite-existing å¯è¦†ç›–ï¼‰")
    
    # ç¡®å®šå‹ç¼©æ¨¡å¼ (é»˜è®¤ä¸å‹ç¼© 'w' ä»¥è¿½æ±‚æœ€å¤§ I/O åå)
    mode = "w"
    suffix = ".tar"
    if compress:
        c = compress.lower()
        if c == "gz":
            mode, suffix = "w:gz", ".tar.gz"
        elif c == "bz2":
            mode, suffix = "w:bz2", ".tar.bz2"
        elif c in ("xz", "lzma"):
            mode, suffix = "w:xz", ".tar.xz"
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å‹ç¼©æ ¼å¼: {compress}")
    
    # ç”Ÿæˆä»»åŠ¡åˆ—è¡¨
    tasks = []
    total_target_samples = 0
    skipped_samples = 0

    for i in range(num_shards):
        start_idx = i * shard_size
        end_idx = start_idx + shard_size
        shard_data = pairs[start_idx:end_idx]
        if not shard_data:
            continue

        if (not overwrite_existing) and (i in existing_indices):
            skipped_samples += len(shard_data)
            continue

        tasks.append((i, shard_data, output_dir, mode, suffix, overwrite_existing))
        total_target_samples += len(shard_data)

    if not tasks:
        print("[Plan] æ‰€æœ‰ shard å·²å­˜åœ¨ï¼Œæœªå‘ç°éœ€è¦å†™å…¥çš„ä»»åŠ¡ã€‚")
        return

    if skipped_samples:
        print(f"[Resume] è‡ªåŠ¨è·³è¿‡ {skipped_samples} æ¡å·²å­˜åœ¨çš„æ ·æœ¬ï¼ˆå¯¹åº” {len(existing_indices & set(range(num_shards)))} ä¸ª shardï¼‰")
    
    # 4. å¤šè¿›ç¨‹æ‰§è¡Œ
    # ä½¿ç”¨ min(workers, num_shards) é¿å…åˆ›å»ºæ— ç”¨çš„è¿›ç¨‹
    real_workers = max(1, min(workers, len(tasks)))
    print(f"[Exec] å¯åŠ¨ {real_workers} ä¸ª Worker è¿›ç¨‹è¿›è¡Œå¹¶è¡Œæ‰“åŒ…...")
    
    total_written = 0
    errors = []
    
    # ä½¿ç”¨ imap_unordered å®ç°æ›´å¹³æ»‘çš„è¿›åº¦æ¡æ›´æ–°
    with mp.Pool(processes=real_workers) as pool:
        pbar = tqdm(total=total_target_samples, desc="Writing Shards", unit="sample")
        
        for idx, count, error in pool.imap_unordered(_write_one_shard, tasks):
            if error and error != "skip_existing":
                errors.append((idx, error))
                print(f"\nâŒ Shard {idx:05d} å¤±è´¥: {error}")
            else:
                total_written += count
                pbar.update(count)
        
        pbar.close()
    
    t1 = time.time()
    duration = t1 - t0
    speed = total_written / duration if duration > 0 else 0
    
    print("\n" + "="*50)
    print(f"âœ… æ‰“åŒ…å®Œæˆ!")
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {total_written}")
    print(f"â±ï¸  æ€»è€—æ—¶: {duration:.2f} ç§’")
    print(f"ğŸš€ å¹³å‡é€Ÿåº¦: {speed:.2f} samples/s")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    if errors:
        print(f"âš ï¸  å¤±è´¥ shard æ•°: {len(errors)}")
    print("="*50)


def main():
    parser = argparse.ArgumentParser(description="SA-1B TAR Sharding (Extreme Optimized)")
    parser.add_argument("--features-dir", type=str, required=True,
                        help="NPZ ç‰¹å¾æ–‡ä»¶ç›®å½•ï¼Œä¾‹å¦‚ /home/.../sa1b/extracted")
    parser.add_argument("--images-dir", type=str, required=True,
                        help="Resize åçš„ JPG å›¾åƒç›®å½•ï¼Œä¾‹å¦‚ /home/.../sa1b_resized_1024")
    parser.add_argument("--output-dir", type=str, required=True,
                        help="è¾“å‡º Tar Shard ç›®å½•ï¼Œä¾‹å¦‚ /home/.../sa1b_tar_shards")
    
    # æ€§èƒ½ç›¸å…³é»˜è®¤å€¼è°ƒæ•´
    parser.add_argument("--shard-size", type=int, default=1000,
                        help="æ¯ä¸ª Shard çš„æ ·æœ¬æ•°ï¼ˆé»˜è®¤ 1000ï¼Œå»ºè®® 1000~2000ï¼‰")
    parser.add_argument("--workers", type=int, default=mp.cpu_count(),
                        help=f"å·¥ä½œè¿›ç¨‹æ•° (é»˜è®¤: {mp.cpu_count()} æ ¸å¿ƒï¼Œå»ºè®® 80% CPU æ ¸å¿ƒæ•°)")
    parser.add_argument("--compress", type=str, default=None,
                        choices=["gz", "bz2", "xz"],
                        help="å‹ç¼©æ ¼å¼ (å»ºè®®ç•™ç©ºä»¥è·å¾—æœ€é«˜é€Ÿåº¦)")
    parser.add_argument("--max-samples", type=int, default=None,
                        help="è°ƒè¯•ç”¨: æœ€å¤§å¤„ç†æ ·æœ¬æ•°")
    parser.add_argument("--overwrite-existing", action="store_true",
                        help="è‹¥ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œå¼ºåˆ¶è¦†ç›–ï¼ˆé»˜è®¤è·³è¿‡å·²å­˜åœ¨çš„ shardï¼‰")
    
    args = parser.parse_args()
    
    # è·¯å¾„æ£€æŸ¥
    if not os.path.isdir(args.features_dir):
        print(f"âŒ é”™è¯¯: ç‰¹å¾ç›®å½•ä¸å­˜åœ¨ {args.features_dir}")
        return
    if not os.path.isdir(args.images_dir):
        print(f"âŒ é”™è¯¯: å›¾åƒç›®å½•ä¸å­˜åœ¨ {args.images_dir}")
        return
    
    create_tar_shards(
        features_dir=args.features_dir,
        images_dir=args.images_dir,
        output_dir=args.output_dir,
        shard_size=args.shard_size,
        compress=args.compress,
        max_samples=args.max_samples,
        workers=args.workers,
        overwrite_existing=args.overwrite_existing,
    )


if __name__ == "__main__":
    # è®¾ç½®å¯åŠ¨æ–¹æ³•ä¸º fork (Linuxé»˜è®¤) æˆ– spawn (æ›´å®‰å…¨ä½†æ…¢)ï¼Œè¿™é‡Œä¸åšå¼ºåˆ¶é™åˆ¶
    # å¦‚æœé‡åˆ° deadlock é—®é¢˜ï¼Œå¯ä»¥å°è¯•å–æ¶ˆæ³¨é‡Šä¸‹é¢è¿™è¡Œ:
    # mp.set_start_method('spawn')
    main()
