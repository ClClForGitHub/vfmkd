#!/usr/bin/env python3
"""
SA-1B å®ä¾‹æ¡†æå–å™¨
ä» SA-1B JSON æ ‡æ³¨æ–‡ä»¶ä¸­å¿«é€Ÿæå–å®ä¾‹æ¡†ï¼ˆ2ä¸ªå¤§æ¡†+1ä¸ªä¸­æ¡†ï¼‰
"""

import json
import time
from pathlib import Path
from typing import Dict, Any, Optional
import numpy as np
import cv2
import matplotlib.pyplot as plt
from pycocotools import mask as mask_utils
from tqdm import tqdm
import torch
import torchvision.ops


class SA1BInstanceBoxExtractor:
    """SA-1B å®ä¾‹æ¡†æå–å™¨ï¼šæå–2ä¸ªå¤§æ¡†+1ä¸ªä¸­æ¡†"""
    
    def __init__(
        self,
        min_area_threshold: int = 1000,
        min_iou_threshold: float = 0.90,
        nms_iou_threshold: float = 0.5,
        use_cuda: bool = True,
        device: Optional[torch.device] = None,
        cuda_device_id: int = 0,
        use_composite_score: bool = True,
        area_weight: float = 0.2,  # é™ä½é¢ç§¯æƒé‡ï¼Œä¼˜å…ˆè´¨é‡å’Œç¨³å®šæ€§
        iou_weight: float = 0.5,   # æé«˜IoUæƒé‡ï¼Œä¼˜å…ˆé«˜è´¨é‡æ©ç 
        stability_weight: float = 0.3,  # æé«˜ç¨³å®šæ€§æƒé‡ï¼Œè¿‡æ»¤ä¸ç¨³å®šæ©ç 
        two_stage_nms: bool = True,
        mask_size: int = 256,
        # æ–°å¢ï¼šå®Œæ•´æ€§æƒé‡ä¸åŠ¨æ€Ké€‰æ‹©
        use_integrity: bool = True,
        score_threshold: float = 0.80,
        max_instances: int = 5,
        # æ–°å¢ï¼šèƒŒæ™¯/å¤©ç©ºæŠ‘åˆ¶è§„åˆ™
        max_area_ratio: float = 0.50,  # æ©ç é¢ç§¯å æ•´å›¾æ¯”ä¾‹çš„ä¸Šé™ï¼ˆå¤§äºåˆ™è§†ä¸ºèƒŒæ™¯/å¤©ç©ºï¼‰
        reject_top_band: bool = True,  # è¿‡æ»¤é¡¶éƒ¨æ¨ªå‘å¤§å¸¦çŠ¶åŒºåŸŸ
        top_edge_margin_frac: float = 0.02,  # è·ç¦»é¡¶éƒ¨é˜ˆå€¼ï¼ˆç›¸å¯¹é«˜åº¦ï¼‰
        min_top_band_width_frac: float = 0.60,  # é¡¶éƒ¨å¸¦çŠ¶åŒºåŸŸéœ€è¦†ç›–çš„æœ€å°å®½åº¦æ¯”ä¾‹
        min_top_band_area_ratio: float = 0.20,  # é¡¶éƒ¨å¸¦çŠ¶åŒºåŸŸçš„æœ€å°é¢ç§¯å æ¯”
    ):
        """
        Args:
            min_area_threshold: æœ€å°æ©ç é¢ç§¯ï¼ˆåƒç´ ï¼‰ï¼Œè¿‡æ»¤å°ç‰©ä½“
            min_iou_threshold: æœ€å° predicted_iouï¼Œè¿‡æ»¤ä½è´¨é‡æ©ç 
            nms_iou_threshold: NMS çš„ IoU é˜ˆå€¼ï¼Œåˆå¹¶é‡å æ¡†ï¼ˆé‡è¦ï¼å»ºè®®0.3-0.7ï¼‰
            use_cuda: æ˜¯å¦ä½¿ç”¨CUDAåŠ é€Ÿï¼ˆæ‰¹é‡å¤„ç†æ—¶æœ‰æ•ˆï¼‰
            device: CUDAè®¾å¤‡ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æ£€æµ‹
            cuda_device_id: CUDAè®¾å¤‡IDï¼ˆè¶…å‚æ•°ï¼Œé»˜è®¤0ï¼‰
            use_composite_score: æ˜¯å¦ä½¿ç”¨ç»¼åˆè¯„åˆ†ï¼ˆarea+iou+stabilityï¼‰
            area_weight: é¢ç§¯æƒé‡ï¼ˆç»¼åˆè¯„åˆ†ï¼‰
            iou_weight: predicted_iouæƒé‡ï¼ˆç»¼åˆè¯„åˆ†ï¼‰
            stability_weight: stability_scoreæƒé‡ï¼ˆç»¼åˆè¯„åˆ†ï¼‰
            two_stage_nms: æ˜¯å¦ä½¿ç”¨ä¸¤é˜¶æ®µNMS
            mask_size: æ©ç ä¿å­˜çš„å°ºå¯¸ï¼ˆé»˜è®¤256x256ï¼‰
            use_integrity: æ˜¯å¦ä½¿ç”¨â€œå®ä¾‹å®Œæ•´æ€§â€æƒé‡ï¼ˆå•ç‚¹/å…¨å›¾è§†ä¸ºæ•´ä½“ï¼‰
            score_threshold: åŠ¨æ€Kçš„åˆ†æ•°é˜ˆå€¼ï¼ˆ>=è¯¥åˆ†æ•°çš„å®ä¾‹è¢«ä¿ç•™ï¼‰
            max_instances: æœ€å¤§å®ä¾‹æ•°ï¼ˆé»˜è®¤5ï¼‰
        """
        self.min_area = min_area_threshold
        self.min_iou = min_iou_threshold
        self.nms_iou = nms_iou_threshold
        self.use_composite_score = use_composite_score
        self.area_weight = area_weight
        self.iou_weight = iou_weight
        self.stability_weight = stability_weight
        self.two_stage_nms = two_stage_nms
        self.mask_size = mask_size
        self.use_integrity = use_integrity
        self.score_threshold = score_threshold
        self.max_instances = max_instances
        # èƒŒæ™¯æŠ‘åˆ¶å‚æ•°
        self.max_area_ratio = max_area_ratio
        self.reject_top_band = reject_top_band
        self.top_edge_margin_frac = top_edge_margin_frac
        self.min_top_band_width_frac = min_top_band_width_frac
        self.min_top_band_area_ratio = min_top_band_area_ratio
        
        # CUDAé…ç½®ï¼ˆæ”¯æŒè¶…å‚æ•°è®¾ç½®ï¼‰
        if use_cuda and torch.cuda.is_available():
            if device is None:
                # ä½¿ç”¨è¶…å‚æ•°æŒ‡å®šçš„è®¾å¤‡ID
                if cuda_device_id >= torch.cuda.device_count():
                    print(f"âš ï¸  è®¾å¤‡ cuda:{cuda_device_id} ä¸å­˜åœ¨ï¼Œä½¿ç”¨ cuda:0")
                    cuda_device_id = 0
                self.device = torch.device(f'cuda:{cuda_device_id}')
            else:
                self.device = device
            self.use_cuda = True
        else:
            self.device = torch.device('cpu')
            self.use_cuda = False
        
        print(f"âœ… SA1BInstanceBoxExtractor åˆå§‹åŒ–")
        print(f"  CUDAåŠ é€Ÿ: {self.use_cuda}")
        if self.use_cuda:
            print(f"  è®¾å¤‡: {self.device}")
        print(f"  NMSé˜ˆå€¼: {self.nms_iou}")
        print(f"  ç»¼åˆè¯„åˆ†: {self.use_composite_score} (Area:{self.area_weight}, IoU:{self.iou_weight}, Stability:{self.stability_weight})")
        print(f"  ä¸¤é˜¶æ®µNMS: {self.two_stage_nms}")
        print(f"  æ©ç å°ºå¯¸: {self.mask_size}x{self.mask_size}")
        print(f"  å®Œæ•´æ€§æƒé‡: {self.use_integrity}")
        print(f"  åŠ¨æ€K: é˜ˆå€¼={self.score_threshold}, æœ€å¤§å®ä¾‹={self.max_instances}")
        print(f"  èƒŒæ™¯æŠ‘åˆ¶: max_area_ratio={self.max_area_ratio}, reject_top_band={self.reject_top_band}")
        print(f"\nğŸ“Œ é€‰æ¡†é€»è¾‘è¯´æ˜:")
        print(f"  1. è¿‡æ»¤: é¢ç§¯â‰¥{self.min_area}, IoUâ‰¥{self.min_iou}")
        print(f"  2. è¯„åˆ†: ç»¼åˆè¯„åˆ†æ’åº (é¢ç§¯+è´¨é‡+ç¨³å®šæ€§){' Ã— å®Œæ•´æ€§' if self.use_integrity else ''}")
        print(f"  3. NMS: {'ä¸¤é˜¶æ®µ' if self.two_stage_nms else 'å•é˜¶æ®µ'} å»é‡å ")
        print(f"  4. é€‰æ‹©: åŠ¨æ€K(åˆ†æ•°â‰¥{self.score_threshold})ï¼Œæœ€å¤š{self.max_instances} ä¸ªå®ä¾‹")
    
    def extract_top_boxes_simple(
        self, 
        json_path: str
    ) -> Dict[str, Any]:
        """
        æå–2ä¸ªå¤§æ¡† + 1ä¸ªä¸­æ¡†ï¼ˆç¬¬3å¤§çš„ï¼‰
        ä½¿ç”¨ç»¼åˆè¯„åˆ†å’Œä¸¤é˜¶æ®µNMSä¼˜åŒ–
        è‡ªåŠ¨å¤„ç†ä¸è¶³3ä¸ªçš„æƒ…å†µ
        
        Returns:
            {
                'large_boxes': [[x, y, w, h], ...],  # æœ€å¤š2ä¸ª
                'medium_boxes': [[x, y, w, h]],      # æœ€å¤š1ä¸ª
                'masks': np.array,  # [3, 256, 256] æ©ç ï¼Œæ¯ä¸ªé€šé“å¯¹åº”ä¸€ä¸ªæ¡†
                'annotation_indices': [int, int, int],  # å¯¹åº”åŸå§‹annotationçš„ç´¢å¼•
                'total_available': int
            }
        """
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        annotations = data.get('annotations', [])
        image_height = data['image']['height']
        image_width = data['image']['width']
        
        # è¿‡æ»¤å¹¶æå–æ¡†ï¼ˆå¸¦é¢ç§¯ä¿¡æ¯ï¼‰
        boxes_list = []
        areas_list = []
        ious_list = []
        stability_list = []
        rle_list = []  # ä¿å­˜RLEç”¨äºåç»­ç”Ÿæˆæ©ç 
        integrity_list = []  # æ–°å¢ï¼šå®ä¾‹å®Œæ•´æ€§
        
        # è·å–å›¾åƒå°ºå¯¸ï¼ˆç”¨äºé¢ç§¯å æ¯”ä¸å¸¦çŠ¶æ£€æµ‹ï¼‰
        image_info = data.get('image', {})
        image_height = int(image_info.get('height', 0) or image_info.get('h', 0) or 0)
        image_width = int(image_info.get('width', 0) or image_info.get('w', 0) or 0)
        image_area = float(max(1, image_height * image_width))

        for ann in annotations:
            # ç›´æ¥ä» RLE æå–æ¡†ï¼ˆéå¸¸å¿«ï¼ï¼‰
            bbox = mask_utils.toBbox(ann['segmentation'])
            x, y, w, h = float(bbox[0]), float(bbox[1]), float(bbox[2]), float(bbox[3])
            area_val = float(ann['area'])

            # èƒŒæ™¯/å¤©ç©ºæŠ‘åˆ¶ï¼šé¢ç§¯å æ¯”è¿‡å¤§æˆ–é¡¶éƒ¨æ¨ªå‘å¤§å¸¦çŠ¶
            area_ratio = area_val / image_area
            is_reject = False
            if area_ratio >= self.max_area_ratio:
                is_reject = True
            if (not is_reject) and self.reject_top_band and image_height > 0 and image_width > 0:
                top_touch = (y <= self.top_edge_margin_frac * image_height)
                width_frac = w / image_width
                if top_touch and width_frac >= self.min_top_band_width_frac and area_ratio >= self.min_top_band_area_ratio:
                    is_reject = True
            if is_reject:
                # è·³è¿‡ç–‘ä¼¼å¤©ç©º/å¤§èƒŒæ™¯åŒºåŸŸ
                continue

            boxes_list.append([x, y, w, h])
            areas_list.append(area_val)
            ious_list.append(ann.get('predicted_iou', 0.0))
            stability_list.append(ann.get('stability_score', 0.0))
            rle_list.append(ann['segmentation'])  # ä¿å­˜RLE
            # å®Œæ•´æ€§ï¼šå•ç‚¹(point_coordsé•¿åº¦ä¸º1æˆ–2) æˆ– æœªè£å‰ª(crop_n_layers=0) è§†ä¸ºæ•´ä½“
            point_coords = ann.get('point_coords', [])
            crop_n_layers = ann.get('crop_n_layers', None)
            is_high_integrity = False
            if isinstance(point_coords, list) and 0 < len(point_coords) < 3:
                is_high_integrity = True
            if crop_n_layers is not None and crop_n_layers == 0:
                is_high_integrity = True
            integrity_list.append(1.0 if is_high_integrity else 0.5)
        
        if len(boxes_list) == 0:
            return {
                'large_boxes': [],
                'medium_boxes': [],
                'masks': np.zeros((self.max_instances, self.mask_size, self.mask_size), dtype=np.uint8),
                'annotation_indices': [],
                'total_available': 0
            }
        
        # ä½¿ç”¨CUDAåŠ é€Ÿè¿‡æ»¤å’Œæ’åºï¼ˆæ‰¹é‡å¤„ç†æ—¶æ›´é«˜æ•ˆï¼‰
        if self.use_cuda and len(boxes_list) > 100:
            # æ‰¹é‡å¤„ç†ï¼šè½¬ä¸ºtensorè¿›è¡Œå‘é‡åŒ–æ“ä½œ
            areas_tensor = torch.tensor(areas_list, dtype=torch.float32, device=self.device)
            ious_tensor = torch.tensor(ious_list, dtype=torch.float32, device=self.device)
            stability_tensor = torch.tensor(stability_list, dtype=torch.float32, device=self.device)
            integrity_tensor = torch.tensor(integrity_list, dtype=torch.float32, device=self.device)
            
            # å‘é‡åŒ–è¿‡æ»¤
            area_mask = areas_tensor >= self.min_area
            iou_mask = ious_tensor >= self.min_iou
            valid_mask = area_mask & iou_mask
            
            valid_indices = torch.where(valid_mask)[0]
            
            if len(valid_indices) == 0:
                return {
                    'large_boxes': [],
                    'medium_boxes': [],
                    'masks': np.zeros((self.max_instances, self.mask_size, self.mask_size), dtype=np.uint8),
                    'annotation_indices': [],
                    'total_available': 0
                }
            
            # è·å–æœ‰æ•ˆçš„æ•°æ®
            valid_areas = areas_tensor[valid_indices]
            valid_ious = ious_tensor[valid_indices]
            valid_stability = stability_tensor[valid_indices]
            valid_integrity = integrity_tensor[valid_indices]
            valid_indices_cpu = valid_indices.cpu().numpy()
            
            # ç»¼åˆè¯„åˆ†ç­–ç•¥ + å®Œæ•´æ€§ä¹˜å­
            if self.use_composite_score:
                # å½’ä¸€åŒ–å„é¡¹æŒ‡æ ‡ï¼ˆé¿å…é‡çº²å·®å¼‚ï¼‰
                areas_norm = (valid_areas - valid_areas.min()) / (valid_areas.max() - valid_areas.min() + 1e-8)
                ious_norm = valid_ious  # å·²åœ¨[0,1]
                stability_norm = valid_stability  # å·²åœ¨[0,1]
                composite_scores = (
                    self.area_weight * areas_norm +
                    self.iou_weight * ious_norm +
                    self.stability_weight * stability_norm
                )
                if self.use_integrity:
                    composite_scores = composite_scores * valid_integrity
                scores_tensor = composite_scores
            else:
                scores_tensor = valid_areas * (valid_integrity if self.use_integrity else 1.0)
            
            # è½¬æ¢ä¸º [x1, y1, x2, y2] æ ¼å¼ç”¨äºNMS
            boxes_xywh = np.array([boxes_list[i] for i in valid_indices_cpu], dtype=np.float32)
            boxes_xyxy = boxes_xywh.copy()
            boxes_xyxy[:, 2] = boxes_xywh[:, 0] + boxes_xywh[:, 2]  # x2 = x + w
            boxes_xyxy[:, 3] = boxes_xywh[:, 1] + boxes_xywh[:, 3]  # y2 = y + h
            
            boxes_tensor = torch.tensor(boxes_xyxy, dtype=torch.float32, device=self.device)
            
            # ä¸¤é˜¶æ®µNMS
            if self.two_stage_nms:
                keep_indices_stage1 = torchvision.ops.nms(boxes_tensor, scores_tensor, 0.7)
                boxes_tensor_stage1 = boxes_tensor[keep_indices_stage1]
                scores_tensor_stage1 = scores_tensor[keep_indices_stage1]
                keep_indices_stage2 = torchvision.ops.nms(boxes_tensor_stage1, scores_tensor_stage1, self.nms_iou)
                keep_indices = keep_indices_stage1[keep_indices_stage2]
            else:
                keep_indices = torchvision.ops.nms(boxes_tensor, scores_tensor, self.nms_iou)
            
            kept_boxes_xywh = boxes_xywh[keep_indices.cpu().numpy()]
            kept_scores = scores_tensor[keep_indices].cpu().numpy()
            kept_original_indices = valid_indices_cpu[keep_indices.cpu().numpy()]
            
            # æŒ‰åˆ†æ•°æ’åº
            order = np.argsort(kept_scores)[::-1]
            valid_boxes = []
            for i in order:
                valid_boxes.append({
                    'box': kept_boxes_xywh[i].tolist(),
                    'score': float(kept_scores[i]),
                    'original_idx': int(kept_original_indices[i])
                })
        else:
            # CPUç‰ˆæœ¬ï¼š
            valid_boxes_data = []
            for i in range(len(boxes_list)):
                if areas_list[i] < self.min_area:
                    continue
                if ious_list[i] < self.min_iou:
                    continue
                boxes_xywh = boxes_list[i]
                boxes_xyxy = [boxes_xywh[0], boxes_xywh[1], boxes_xywh[0] + boxes_xywh[2], boxes_xywh[1] + boxes_xywh[3]]
                valid_boxes_data.append({
                    'box': boxes_xywh,
                    'box_xyxy': boxes_xyxy,
                    'area': areas_list[i],
                    'iou': ious_list[i],
                    'stability': stability_list[i],
                    'integrity': integrity_list[i],
                    'original_idx': i
                })
            if len(valid_boxes_data) == 0:
                return {
                    'large_boxes': [],
                    'medium_boxes': [],
                    'masks': np.zeros((self.max_instances, self.mask_size, self.mask_size), dtype=np.uint8),
                    'annotation_indices': [],
                    'total_available': 0
                }
            if self.use_composite_score:
                areas_arr = np.array([x['area'] for x in valid_boxes_data])
                ious_arr = np.array([x['iou'] for x in valid_boxes_data])
                stability_arr = np.array([x['stability'] for x in valid_boxes_data])
                integrity_arr = np.array([x['integrity'] for x in valid_boxes_data])
                areas_norm = (areas_arr - areas_arr.min()) / (areas_arr.max() - areas_arr.min() + 1e-8)
                composite_scores = (
                    self.area_weight * areas_norm +
                    self.iou_weight * ious_arr +
                    self.stability_weight * stability_arr
                )
                if self.use_integrity:
                    composite_scores = composite_scores * integrity_arr
            else:
                composite_scores = np.array([x['area'] for x in valid_boxes_data]) * (
                    np.array([x['integrity'] for x in valid_boxes_data]) if self.use_integrity else 1.0
                )
            for i, s in enumerate(composite_scores):
                valid_boxes_data[i]['score'] = float(s)
            # æ’åº
            valid_boxes_data.sort(key=lambda x: x['score'], reverse=True)
            # NMSï¼ˆä¸¤é˜¶æ®µï¼‰
            boxes_xyxy = torch.tensor([x['box_xyxy'] for x in valid_boxes_data], dtype=torch.float32)
            scores = torch.tensor([x['score'] for x in valid_boxes_data], dtype=torch.float32)
            if self.two_stage_nms:
                keep1 = torchvision.ops.nms(boxes_xyxy, scores, 0.7)
                boxes_t1 = boxes_xyxy[keep1]
                scores_t1 = scores[keep1]
                keep2 = torchvision.ops.nms(boxes_t1, scores_t1, self.nms_iou)
                keep_indices = keep1[keep2].numpy()
            else:
                keep_indices = torchvision.ops.nms(boxes_xyxy, scores, self.nms_iou).numpy()
            valid_boxes = [{
                'box': valid_boxes_data[i]['box'],
                'score': valid_boxes_data[i]['score'],
                'original_idx': valid_boxes_data[i]['original_idx']
            } for i in keep_indices]
            valid_boxes.sort(key=lambda x: x['score'], reverse=True)
        
        total = len(valid_boxes)
        
        # åŠ¨æ€Kï¼šæŒ‰é˜ˆå€¼ä¿ç•™ï¼Œæœ€å¤šmax_instances
        selected_boxes = []
        selected_indices = []
        for item in valid_boxes:
            if item['score'] >= self.score_threshold and len(selected_boxes) < self.max_instances:
                selected_boxes.append(item['box'])
                selected_indices.append(item['original_idx'])
            else:
                if len(selected_boxes) >= self.max_instances:
                    break
                # å½“é‡åˆ°ç¬¬ä¸€ä¸ªä½äºé˜ˆå€¼çš„ï¼Œåç»­æ›´ä½ï¼Œç›´æ¥åœæ­¢
                if item['score'] < self.score_threshold:
                    break
        if len(selected_boxes) == 0 and total > 0:
            # è‡³å°‘ä¿ç•™ä¸€ä¸ª
            selected_boxes.append(valid_boxes[0]['box'])
            selected_indices.append(valid_boxes[0]['original_idx'])
        
        masks = self._generate_masks(rle_list, selected_indices)
        
        return {
            'boxes': selected_boxes,
            'masks': masks,
            'annotation_indices': selected_indices,
            'total_available': len(selected_boxes),
            # å…¼å®¹æ—§å­—æ®µï¼šå–å‰3ä¸ªåšæ—§ç‰ˆåˆ‡ç‰‡ï¼ˆæœ€å¤š2å¤§+1ä¸­ï¼‰
            'large_boxes': selected_boxes[:2],
            'medium_boxes': selected_boxes[2:3],
        }
    
    def _generate_masks(
        self,
        rle_list: list,
        selected_indices: list,
        ) -> np.ndarray:
        """
        ç”Ÿæˆæ©ç ï¼šmax_instancesé€šé“ï¼Œæ¯ä¸ªé€šé“å¯¹åº”ä¸€ä¸ªæ¡†çš„æ©ç ï¼Œresizeåˆ°256x256
        """
        masks = np.zeros((self.max_instances, self.mask_size, self.mask_size), dtype=np.uint8)
        for channel_idx, ann_idx in enumerate(selected_indices[: self.max_instances]):
            if ann_idx >= len(rle_list):
                continue
            try:
                rle = rle_list[ann_idx]
                mask = mask_utils.decode(rle)
                mask_resized = cv2.resize(mask.astype(np.float32), (self.mask_size, self.mask_size), interpolation=cv2.INTER_AREA)
                masks[channel_idx] = (mask_resized > 0.5).astype(np.uint8)
            except Exception:
                continue
        return masks
    
    def batch_extract_test(
        self,
        json_dir: str,
        num_files: int = 50
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡æµ‹è¯•æå–é€Ÿåº¦
        
        Returns:
            åŒ…å«é€Ÿåº¦å’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        json_dir = Path(json_dir)
        json_files = sorted([f for f in json_dir.glob("sa_*.json")])[:num_files]
        
        print(f"ğŸ“ æµ‹è¯• {len(json_files)} ä¸ª JSON æ–‡ä»¶...")
        print(f"   ä½¿ç”¨CUDA: {self.use_cuda}, è®¾å¤‡: {self.device}")
        
        total_time = 0.0
        success_count = 0
        error_count = 0
        
        box_stats = {
            'total_files': len(json_files),
            'files_with_0_boxes': 0,
            'files_with_1_boxes': 0,
            'files_with_2_boxes': 0,
            'files_with_3_boxes': 0,
        }
        
        # é¢„çƒ­ï¼ˆé¿å…é¦–æ¬¡è¿è¡Œæ…¢ï¼‰
        if len(json_files) > 0 and self.use_cuda:
            try:
                _ = self.extract_top_boxes_simple(str(json_files[0]))
            except:
                pass
        
        for json_file in tqdm(json_files, desc="æå–bbox"):
            try:
                t0 = time.time()
                result = self.extract_top_boxes_simple(str(json_file))
                elapsed = time.time() - t0
                
                total_time += elapsed
                success_count += 1
                
                total_boxes = len(result['large_boxes']) + len(result['medium_boxes'])
                if total_boxes == 0:
                    box_stats['files_with_0_boxes'] += 1
                elif total_boxes == 1:
                    box_stats['files_with_1_boxes'] += 1
                elif total_boxes == 2:
                    box_stats['files_with_2_boxes'] += 1
                else:
                    box_stats['files_with_3_boxes'] += 1
                    
            except Exception as e:
                error_count += 1
                print(f"âŒ å¤„ç† {json_file.name} æ—¶å‡ºé”™: {e}")
        
        avg_time = total_time / success_count if success_count > 0 else 0
        
        print(f"\nâœ… æµ‹è¯•å®Œæˆ!")
        print(f"  æˆåŠŸ: {success_count} ä¸ªæ–‡ä»¶")
        print(f"  å¤±è´¥: {error_count} ä¸ªæ–‡ä»¶")
        print(f"  å¹³å‡é€Ÿåº¦: {avg_time*1000:.2f} ms/æ–‡ä»¶")
        print(f"  æ€»è€—æ—¶: {total_time:.2f} ç§’")
        if self.use_cuda:
            print(f"  âš¡ CUDAåŠ é€Ÿ: å¯ç”¨")
        else:
            print(f"  âš¡ CUDAåŠ é€Ÿ: æœªå¯ç”¨")
        print(f"\nğŸ“Š æ¡†æ•°é‡ç»Ÿè®¡:")
        print(f"  0ä¸ªæ¡†: {box_stats['files_with_0_boxes']} ä¸ªæ–‡ä»¶")
        print(f"  1ä¸ªæ¡†: {box_stats['files_with_1_boxes']} ä¸ªæ–‡ä»¶")
        print(f"  2ä¸ªæ¡†: {box_stats['files_with_2_boxes']} ä¸ªæ–‡ä»¶")
        print(f"  3ä¸ªæ¡†: {box_stats['files_with_3_boxes']} ä¸ªæ–‡ä»¶")
        
        return {
            'avg_time_ms': avg_time * 1000,
            'total_time': total_time,
            'success_count': success_count,
            'box_stats': box_stats,
            'use_cuda': self.use_cuda
        }
    
    def visualize_boxes_on_image(
        self,
        image_path: str,
        json_path: str,
        output_path: str
    ):
        """
        å¯è§†åŒ–ï¼š4ä¸ªå­å›¾
        1. åŸå›¾+æ¡†æ ‡æ³¨ï¼ˆå¤§æ¡†1çº¢è‰²ï¼Œå¤§æ¡†2ç»¿è‰²ï¼Œä¸­æ¡†è“è‰²ï¼‰
        2. æ©ç é€šé“1ï¼ˆå¯¹åº”å¤§æ¡†1ï¼‰
        3. æ©ç é€šé“2ï¼ˆå¯¹åº”å¤§æ¡†2ï¼‰
        4. æ©ç é€šé“3ï¼ˆå¯¹åº”ä¸­æ¡†ï¼‰
        """
        # æå–æ¡†å’Œæ©ç 
        result = self.extract_top_boxes_simple(json_path)
        large_boxes = result['large_boxes']
        medium_boxes = result['medium_boxes']
        masks = result['masks']  # [max_instances, 256, 256]
        
        # åŠ è½½å›¾åƒ
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {image_path}")
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # åˆ›å»º4ä¸ªå­å›¾
        fig, axes = plt.subplots(1, 4, figsize=(20, 5))
        
        # å­å›¾1ï¼šåŸå›¾+æ¡†æ ‡æ³¨
        ax0 = axes[0]
        ax0.imshow(image_rgb)
        
        # ç»˜åˆ¶å¤§æ¡†1ï¼ˆçº¢è‰²ï¼Œç²—çº¿ï¼‰
        if len(large_boxes) > 0:
            x, y, w, h = large_boxes[0]
            rect = plt.Rectangle(
                (x, y), w, h,
                linewidth=3, edgecolor='red', facecolor='none',
                label='Large Box 1'
            )
            ax0.add_patch(rect)
        
        # ç»˜åˆ¶å¤§æ¡†2ï¼ˆç»¿è‰²ï¼Œç²—çº¿ï¼‰
        if len(large_boxes) > 1:
            x, y, w, h = large_boxes[1]
            rect = plt.Rectangle(
                (x, y), w, h,
                linewidth=3, edgecolor='green', facecolor='none',
                label='Large Box 2'
            )
            ax0.add_patch(rect)
        
        # ç»˜åˆ¶ä¸­æ¡†ï¼ˆè“è‰²ï¼Œç»†çº¿ï¼‰
        if len(medium_boxes) > 0:
            x, y, w, h = medium_boxes[0]
            rect = plt.Rectangle(
                (x, y), w, h,
                linewidth=2, edgecolor='blue', facecolor='none',
                label='Medium Box'
            )
            ax0.add_patch(rect)
        
        ax0.set_title(
            f"Original Image + Boxes\nLarge: {len(large_boxes)}, Medium: {len(medium_boxes)}",
            fontsize=11, fontweight='bold'
        )
        ax0.axis('off')
        if len(large_boxes) > 0 or len(medium_boxes) > 0:
            ax0.legend(loc='upper right', fontsize=8)
        
        # å­å›¾2-4ï¼šæ©ç é€šé“å¯è§†åŒ–
        mask_titles = ['Mask Channel 1\n(Large Box 1)', 'Mask Channel 2\n(Large Box 2)', 'Mask Channel 3\n(Medium Box)']
        mask_colors = ['Reds', 'Greens', 'Blues']
        
        for i in range(3):
            ax = axes[i + 1]
            mask = masks[i]  # [256, 256]
            
            # å¯è§†åŒ–æ©ç ï¼ˆä½¿ç”¨colormapï¼‰
            ax.imshow(mask, cmap=mask_colors[i], vmin=0, vmax=1, interpolation='nearest')
            ax.set_title(mask_titles[i], fontsize=11, fontweight='bold')
            ax.axis('off')
            
            # æ˜¾ç¤ºæ©ç åƒç´ ç»Ÿè®¡
            mask_pixels = mask.sum()
            ax.text(0.5, -0.1, f"Pixels: {mask_pixels}", 
                   transform=ax.transAxes, ha='center', fontsize=9)
        
        plt.suptitle(
            f"Bbox Extraction Result - {Path(json_path).stem}",
            fontsize=14, fontweight='bold', y=1.02
        )
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        return result
    
    def batch_visualize(
        self,
        json_dir: str,
        output_dir: str,
        num_visualize: int = 5,
        start_index: int = 0
    ):
        """
        æ‰¹é‡å¯è§†åŒ–æ–‡ä»¶
        
        Args:
            json_dir: JSONæ–‡ä»¶ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            num_visualize: è¦å¯è§†åŒ–çš„æ–‡ä»¶æ•°é‡
            start_index: èµ·å§‹ç´¢å¼•ï¼ˆè·³è¿‡å‰é¢çš„æ–‡ä»¶ï¼‰
        """
        json_dir = Path(json_dir)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        json_files = sorted([f for f in json_dir.glob("sa_*.json")])
        
        # ä»æŒ‡å®šç´¢å¼•å¼€å§‹é€‰æ‹©
        selected_files = json_files[start_index:start_index + num_visualize]
        
        print(f"\nğŸ“ å¯è§†åŒ– {len(selected_files)} ä¸ªæ–‡ä»¶ï¼ˆä»ç¬¬ {start_index+1} ä¸ªå¼€å§‹ï¼‰...")
        
        for json_file in tqdm(selected_files, desc="å¯è§†åŒ–"):
            image_file = json_dir / f"{json_file.stem}.jpg"
            
            if not image_file.exists():
                print(f"âš ï¸  è·³è¿‡ {json_file.stem}: å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨")
                continue
            
            output_path = output_dir / f"{json_file.stem}_bboxes.png"
            
            try:
                result = self.visualize_boxes_on_image(
                    str(image_file),
                    str(json_file),
                    str(output_path)
                )
                
                # ä¿å­˜æ©ç ä¸º.npyæ–‡ä»¶
                masks_dir = output_dir / "masks"
                masks_dir.mkdir(parents=True, exist_ok=True)
                mask_path = masks_dir / f"{json_file.stem}_masks.npy"
                np.save(str(mask_path), result['masks'])
                
                print(f"âœ… {json_file.stem}: Large={len(result['large_boxes'])}, Medium={len(result['medium_boxes'])}, Mask shape: {result['masks'].shape}")
            except Exception as e:
                print(f"âŒ {json_file.stem}: {e}")

