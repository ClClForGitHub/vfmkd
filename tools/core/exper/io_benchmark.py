import os
import sys
import time
import shutil
import tempfile
import tarfile
import argparse
import logging
import torch
import numpy as np
from pathlib import Path
from torch.utils.data import IterableDataset, DataLoader
# from torchvision.io import decode_image, ImageReadMode  # æœªä½¿ç”¨ï¼Œæ³¨é‡Šæ‰é¿å…å¯¼å…¥é”™è¯¯

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("IO_Benchmark")

class BenchmarkTarDataset(IterableDataset):
    """
    ç‹¬ç«‹å®ç°çš„ RAM ç¼“å­˜ Datasetï¼Œç”¨äºéªŒè¯ IO æ€§èƒ½
    """
    def __init__(
        self,
        shard_dir: str,
        use_ram_cache: bool = True,
        shuffle_buffer: int = 500,
    ):
        super().__init__()
        self.shard_dir = Path(shard_dir)
        self.use_ram_cache = use_ram_cache
        self.shuffle_buffer_size = shuffle_buffer
        
        # æ‰«ææ–‡ä»¶
        self.shard_files = sorted(
            list(self.shard_dir.glob("*.tar")) + 
            list(self.shard_dir.glob("*.tar.gz"))
        )
        if not self.shard_files:
            raise RuntimeError(f"âŒ é”™è¯¯ï¼šåœ¨ {shard_dir} æ²¡æ‰¾åˆ° .tar æ–‡ä»¶ï¼")
        
        logger.info(f"[Init] æ‰¾åˆ° {len(self.shard_files)} ä¸ª Tar æ–‡ä»¶ã€‚RAM ç¼“å­˜ç­–ç•¥: {'âœ… å¼€å¯' if use_ram_cache else 'âŒ å…³é—­'}")

    def _check_ram_space(self, size_needed):
        """æ£€æŸ¥ /dev/shm ç©ºé—´"""
        if not os.path.exists('/dev/shm'): return False
        try:
            total, used, free = shutil.disk_usage('/dev/shm')
            # é¢„ç•™ 2GB å®‰å…¨æ°´ä½
            return (size_needed + 2 * 1024**3) < free
        except:
            return False

    def _parse_tar_content(self, tar_path):
        worker_info = torch.utils.data.get_worker_info()
        worker_id = worker_info.id if worker_info else 0
        
        process_path = tar_path
        temp_file = None
        
        # === æ ¸å¿ƒï¼šRAM ç¼“å­˜é€»è¾‘ ===
        if self.use_ram_cache:
            try:
                file_size = os.path.getsize(tar_path)
                # æ£€æŸ¥ç©ºé—´
                if self._check_ram_space(file_size):
                    t0 = time.time()
                    # 1. åœ¨å†…å­˜ç›˜åˆ›å»ºæ–‡ä»¶
                    fd, temp_path = tempfile.mkstemp(dir='/dev/shm', suffix='.tar')
                    os.close(fd)
                    # 2. æ‰§è¡Œæ‹·è´ (HDD é¡ºåºè¯» -> RAM å†™)
                    shutil.copyfile(tar_path, temp_path)
                    copy_time = time.time() - t0
                    
                    logger.info(f"[Worker {worker_id}] ğŸš€ å·²ç¼“å­˜ {tar_path.name} åˆ°å†…å­˜ (è€—æ—¶ {copy_time:.2f}s, {file_size/1024/1024:.1f}MB)")
                    
                    process_path = Path(temp_path)
                    temp_file = temp_path
                else:
                    logger.warning(f"[Worker {worker_id}] âš ï¸ å†…å­˜ç©ºé—´ä¸è¶³ï¼Œè·³è¿‡ç¼“å­˜ {tar_path.name}")
            except Exception as e:
                logger.warning(f"[Worker {worker_id}] âš ï¸ ç¼“å­˜å¤±è´¥: {e}ï¼Œå°†ç›´æ¥è¯»å–ç¡¬ç›˜")

        # === è¯»å–é€»è¾‘ ===
        local_buffer = {}
        try:
            # æ¨¡æ‹ŸçœŸå®è¯»å–ï¼šæ‰“å¼€ tar å¹¶è¯»å–æ–‡ä»¶å†…å®¹
            with tarfile.open(process_path, mode='r|*') as tar:
                for member in tar:
                    if not member.isfile(): continue
                    fname = member.name
                    
                    # ç®€å•è§£æ ID
                    if fname.endswith('.npz'):
                        img_id = fname[:-13]
                        type_k = 'npz'
                    elif fname.endswith('.jpg'):
                        img_id = fname[:-4]
                        type_k = 'img'
                    else:
                        continue
                        
                    f_obj = tar.extractfile(member)
                    if f_obj is None: continue
                    content = f_obj.read() # çœŸå®å‘ç”Ÿ IO è¯»å–
                    
                    if img_id not in local_buffer:
                        local_buffer[img_id] = {type_k: content}
                    else:
                        local_buffer[img_id][type_k] = content
                    
                    # é…å¯¹
                    if 'npz' in local_buffer[img_id] and 'img' in local_buffer[img_id]:
                        item = local_buffer.pop(img_id)
                        # æ¨¡æ‹Ÿè§£ç å¼€é”€ (ä½†ä¸åšå¤æ‚çš„åå¤„ç†ï¼Œåªæµ‹ IO)
                        yield self._mock_process(item['img'], item['npz'])
                        
        except Exception as e:
            logger.error(f"Error reading: {e}")
        finally:
            # æ¸…ç†å†…å­˜
            if temp_file and os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except:
                    pass

    def _mock_process(self, img_bytes, npz_bytes):
        # æœ€å°åŒ–è§£ç ï¼Œæ¨¡æ‹ŸçœŸå®è´Ÿè½½
        img_buffer = torch.frombuffer(img_bytes, dtype=torch.uint8)
        # åªè¦è¿™æ­¥ä¸æŠ¥é”™ï¼Œè¯´æ˜æ•°æ®è¯»å¯¹äº†
        # img = decode_image(img_buffer, mode=ImageReadMode.RGB) 
        return torch.zeros(3, 1024, 1024) # è¿”å›å‡æ•°æ®ï¼Œåªæµ‹é€Ÿåº¦

    def __iter__(self):
        worker_info = torch.utils.data.get_worker_info()
        if worker_info is None:
            my_shards = self.shard_files
        else:
            # åˆ†ç‰‡
            my_shards = self.shard_files[worker_info.id :: worker_info.num_workers]
        
        my_shards_list = list(my_shards)
        np.random.shuffle(my_shards_list) # Shuffle Tar files
        
        iterator = self._shard_iterator(my_shards_list)
        
        # Shuffle Buffer
        shuffle_buffer = []
        try:
            for sample in iterator:
                shuffle_buffer.append(sample)
                if len(shuffle_buffer) >= self.shuffle_buffer_size:
                    idx = np.random.randint(len(shuffle_buffer))
                    yield shuffle_buffer.pop(idx)
        except StopIteration:
            pass
        for sample in shuffle_buffer:
            yield sample

    def _shard_iterator(self, shard_paths):
        for p in shard_paths:
            yield from self._parse_tar_content(p)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--shard-dir", type=str, required=True, help="Tar Shard æ‰€åœ¨ç›®å½•")
    parser.add_argument("--batch-size", type=int, default=32)
    parser.add_argument("--num-workers", type=int, default=4, help="Worker æ•°é‡ï¼ŒHDDå»ºè®®4")
    parser.add_argument("--prefetch", type=int, default=2, help="é¢„å–å› å­")
    parser.add_argument("--no-ram-cache", action="store_true", help="ç¦ç”¨ RAM ç¼“å­˜ï¼ˆç”¨äºå¯¹æ¯”ï¼‰")
    args = parser.parse_args()
    
    print("="*60)
    print(f"ğŸ› ï¸  IO æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print(f"ğŸ“‚ æ•°æ®ç›®å½•: {args.shard_dir}")
    print(f"âš™ï¸  é…ç½®: Batch={args.batch_size}, Workers={args.num_workers}, Prefetch={args.prefetch}")
    print(f"ğŸ§  RAM ç¼“å­˜: {'âŒ ç¦ç”¨ (æ¨¡æ‹Ÿç°çŠ¶)' if args.no_ram_cache else 'âœ… å¯ç”¨ (ä¼˜åŒ–æ–¹æ¡ˆ)'}")
    print("="*60)
    
    dataset = BenchmarkTarDataset(
        shard_dir=args.shard_dir,
        use_ram_cache=not args.no_ram_cache,
        shuffle_buffer=500
    )
    
    loader = DataLoader(
        dataset,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        prefetch_factor=args.prefetch if args.num_workers > 0 else None,
        persistent_workers=(args.num_workers > 0),
        pin_memory=True
    )
    
    print("â³ æ­£åœ¨å¯åŠ¨ DataLoader (å†·å¯åŠ¨è®¡æ—¶å¼€å§‹)...")
    t_start = time.time()
    
    iterator = iter(loader)
    
    # å¼ºåˆ¶è·å–ç¬¬ä¸€ä¸ª Batch
    try:
        first_batch = next(iterator)
        t_first = time.time()
        print(f"ğŸ”¥ [å†·å¯åŠ¨å®Œæˆ] é¦–ä¸ª Batch è€—æ—¶: {t_first - t_start:.2f} ç§’")
    except StopIteration:
        print("âŒ æ•°æ®é›†ä¸ºç©ºæˆ–è¯»å–å¤±è´¥ï¼")
        return
    
    # è¿ç»­è¯»å–æµ‹è¯•
    print("ğŸš€ å¼€å§‹è¿ç»­è¯»å– 50 ä¸ª Batchï¼Œæµ‹è¯•ååé‡...")
    
    times = []
    start_loop = time.time()
    
    try:
        for i in range(50):
            t0 = time.time()
            batch = next(iterator)
            dt = time.time() - t0
            times.append(dt)
            
            # æ¨¡æ‹Ÿ GPU è®­ç»ƒè€—æ—¶ (å‡è®¾ 0.3s ä¸€ä¸ª batch)
            # çœ‹çœ‹ IO èƒ½ä¸èƒ½è·Ÿä¸Š
            time.sleep(0.3) 
            
            print(f"\rBatch {i+1}/50 | Load Time: {dt:.4f}s | (æ¨¡æ‹ŸGPUè®¡ç®—ä¸­...)", end="")
    except StopIteration:
        pass
    
    print("\n" + "="*60)
    avg_time = np.mean(times)
    total_time = time.time() - start_loop
    print(f"ğŸ“Š æµ‹è¯•ç»“æœæŠ¥å‘Š:")
    print(f"   - å¹³å‡æ•°æ®åŠ è½½æ—¶é—´: {avg_time:.4f} ç§’/Batch")
    print(f"   - é¢„æœŸçš„ç†æƒ³æ—¶é—´: 0.00xx ç§’ (åº”è¯¥è¢«é¢„å–æ©ç›–)")
    
    if avg_time > 0.5:
        print(f"\nâŒ ç»“è®º: IO ä¾ç„¶æ˜¯ç“¶é¢ˆ (åŠ è½½æ¯”è®¡ç®—æ…¢)ã€‚")
    else:
        print(f"\nâœ… ç»“è®º: IO æå…¶æµç•…ï¼RAM ç¼“å­˜ç­–ç•¥æœ‰æ•ˆã€‚")
    print("="*60)

if __name__ == "__main__":
    main()

