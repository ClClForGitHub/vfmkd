#!/usr/bin/env python3
"""
åˆ†æ tar æ–‡ä»¶ä¸­çš„ npz æ–‡ä»¶ç»“æ„ï¼Œåˆ¤æ–­æ•°æ®æ˜¯å®šé•¿è¿˜æ˜¯å˜é•¿çš„ã€‚

ç”¨é€”ï¼š
- æ£€æŸ¥æ¯ä¸ª npz æ–‡ä»¶ä¸­çš„é”®ï¼ˆkeysï¼‰
- åˆ†ææ¯ä¸ªé”®çš„æ•°æ®å½¢çŠ¶ï¼ˆshapeï¼‰å’Œç±»å‹ï¼ˆdtypeï¼‰
- åˆ¤æ–­æ•°æ®æ˜¯å®šé•¿è¿˜æ˜¯å˜é•¿
- ä¸ºåç»­çš„äºŒè¿›åˆ¶å­˜å‚¨æ ¼å¼è®¾è®¡æä¾›ä¾æ®
"""

import tarfile
import numpy as np
import io
import sys
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Tuple, Any
import argparse


def analyze_npz_structure(npz_bytes: bytes, npz_name: str) -> Dict[str, Any]:
    """åˆ†æå•ä¸ª npz æ–‡ä»¶çš„ç»“æ„"""
    try:
        with np.load(io.BytesIO(npz_bytes), allow_pickle=True) as data:
            result = {
                'name': npz_name,
                'keys': list(data.files),
                'key_info': {},
                'has_variable_length': False,
            }
            
            for key in data.files:
                try:
                    arr = data[key]
                    key_info = {
                        'dtype': str(arr.dtype),
                        'shape': arr.shape,
                        'size': arr.size,
                        'is_object': arr.dtype == object,
                        'is_variable_length': False,
                    }
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å˜é•¿æ•°æ®
                    if arr.dtype == object:
                        # object ç±»å‹é€šå¸¸æ˜¯å˜é•¿çš„ï¼ˆå¦‚åˆ—è¡¨ã€ä¸åŒå½¢çŠ¶çš„æ•°ç»„ï¼‰
                        key_info['is_variable_length'] = True
                        result['has_variable_length'] = True
                        
                        # å°è¯•åˆ†æ object æ•°ç»„çš„å†…å®¹
                        if arr.size > 0:
                            first_item = arr.item(0)
                            if isinstance(first_item, np.ndarray):
                                key_info['first_item_shape'] = first_item.shape
                                key_info['first_item_dtype'] = str(first_item.dtype)
                            else:
                                key_info['first_item_type'] = str(type(first_item))
                    else:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é‡æˆ–å›ºå®šå½¢çŠ¶æ•°ç»„
                        if arr.ndim == 0:
                            # æ ‡é‡
                            key_info['value'] = arr.item()
                        elif arr.ndim > 0:
                            # æ•°ç»„ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„å˜é•¿ç‰¹å¾
                            # ä¾‹å¦‚ï¼šä¸€ç»´æ•°ç»„çš„é•¿åº¦å¯èƒ½ä¸åŒ
                            if arr.ndim == 1:
                                # ä¸€ç»´æ•°ç»„å¯èƒ½æ˜¯å˜é•¿çš„ï¼ˆå¦‚ä¸åŒæ•°é‡çš„æ¡†ï¼‰
                                key_info['is_variable_length'] = True
                                result['has_variable_length'] = True
                    
                    result['key_info'][key] = key_info
                    
                except Exception as e:
                    result['key_info'][key] = {
                        'error': str(e)
                    }
            
            return result
            
    except Exception as e:
        return {
            'name': npz_name,
            'error': str(e)
        }


def analyze_tar_file(tar_path: Path, max_samples: int = 100) -> Dict[str, Any]:
    """åˆ†æ tar æ–‡ä»¶ä¸­çš„æ‰€æœ‰ npz æ–‡ä»¶"""
    print(f"ğŸ“¦ åˆ†æ tar æ–‡ä»¶: {tar_path}")
    
    if not tar_path.exists():
        print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨: {tar_path}")
        return {}
    
    results = []
    key_statistics = defaultdict(list)  # ç»Ÿè®¡æ¯ä¸ªé”®çš„å½¢çŠ¶ä¿¡æ¯
    
    try:
        with tarfile.open(tar_path, "r:*") as tar:
            npz_members = [m for m in tar.getmembers() if m.name.endswith(".npz")]
            
            if not npz_members:
                print("âŒ æœªæ‰¾åˆ° .npz æ–‡ä»¶")
                return {}
            
            print(f"ğŸ“Š æ‰¾åˆ° {len(npz_members)} ä¸ª .npz æ–‡ä»¶")
            
            # é™åˆ¶åˆ†æçš„æ ·æœ¬æ•°é‡
            sample_count = min(max_samples, len(npz_members))
            print(f"ğŸ” åˆ†æå‰ {sample_count} ä¸ªæ ·æœ¬...")
            
            for idx, member in enumerate(npz_members[:sample_count]):
                if idx % 10 == 0:
                    print(f"  å¤„ç†è¿›åº¦: {idx+1}/{sample_count}")
                
                npz_file_obj = tar.extractfile(member)
                if npz_file_obj is None:
                    continue
                
                npz_bytes = npz_file_obj.read()
                result = analyze_npz_structure(npz_bytes, member.name)
                results.append(result)
                
                # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
                if 'key_info' in result:
                    for key, info in result['key_info'].items():
                        if 'shape' in info:
                            key_statistics[key].append({
                                'shape': info['shape'],
                                'dtype': info['dtype'],
                                'is_variable_length': info.get('is_variable_length', False),
                            })
    
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼š{e}")
        return {}
    
    # åˆ†æç»Ÿè®¡ç»“æœ
    analysis = {
        'total_samples': len(results),
        'key_statistics': {},
        'summary': {},
    }
    
    for key, stats in key_statistics.items():
        shapes = [s['shape'] for s in stats]
        dtypes = [s['dtype'] for s in stats]
        is_variable = [s['is_variable_length'] for s in stats]
        
        # æ£€æŸ¥å½¢çŠ¶æ˜¯å¦ä¸€è‡´
        unique_shapes = set(str(s) for s in shapes)
        unique_dtypes = set(dtypes)
        has_variable_length = any(is_variable)
        
        analysis['key_statistics'][key] = {
            'count': len(stats),
            'unique_shapes': list(unique_shapes),
            'unique_dtypes': list(unique_dtypes),
            'is_variable_length': has_variable_length,
            'is_fixed_length': len(unique_shapes) == 1 and not has_variable_length,
            'sample_shapes': shapes[:5],  # å‰5ä¸ªæ ·æœ¬çš„å½¢çŠ¶
        }
    
    # ç”Ÿæˆæ‘˜è¦
    fixed_keys = []
    variable_keys = []
    for key, stats in analysis['key_statistics'].items():
        if stats['is_fixed_length']:
            fixed_keys.append(key)
        else:
            variable_keys.append(key)
    
    analysis['summary'] = {
        'fixed_length_keys': fixed_keys,
        'variable_length_keys': variable_keys,
        'total_keys': len(analysis['key_statistics']),
    }
    
    return {
        'tar_path': str(tar_path),
        'results': results,
        'analysis': analysis,
    }


def print_analysis_report(analysis_result: Dict[str, Any]):
    """æ‰“å°åˆ†ææŠ¥å‘Š"""
    if not analysis_result:
        print("âŒ æ²¡æœ‰åˆ†æç»“æœ")
        return
    
    print("\n" + "="*80)
    print("ğŸ“Š NPZ æ•°æ®ç»“æ„åˆ†ææŠ¥å‘Š")
    print("="*80)
    
    analysis = analysis_result['analysis']
    summary = analysis['summary']
    
    print(f"\nğŸ“ˆ æ‘˜è¦:")
    print(f"  - åˆ†ææ ·æœ¬æ•°: {analysis['total_samples']}")
    print(f"  - æ€»é”®æ•°: {summary['total_keys']}")
    print(f"  - å®šé•¿é”®æ•°: {len(summary['fixed_length_keys'])}")
    print(f"  - å˜é•¿é”®æ•°: {len(summary['variable_length_keys'])}")
    
    print(f"\nâœ… å®šé•¿é”® (Fixed Length):")
    if summary['fixed_length_keys']:
        for key in summary['fixed_length_keys']:
            stats = analysis['key_statistics'][key]
            print(f"  - {key:<30} å½¢çŠ¶: {stats['unique_shapes'][0]}, ç±»å‹: {stats['unique_dtypes'][0]}")
    else:
        print("  (æ— )")
    
    print(f"\nâš ï¸  å˜é•¿é”® (Variable Length):")
    if summary['variable_length_keys']:
        for key in summary['variable_length_keys']:
            stats = analysis['key_statistics'][key]
            print(f"  - {key:<30} å½¢çŠ¶å˜åŒ–: {len(stats['unique_shapes'])} ç§")
            print(f"    ç¤ºä¾‹å½¢çŠ¶: {stats['sample_shapes'][:3]}")
            if stats['is_variable_length']:
                print(f"    åŸå› : æ•°æ®æœ¬èº«æ˜¯å˜é•¿çš„ï¼ˆobject ç±»å‹æˆ–ä¸€ç»´æ•°ç»„ï¼‰")
    else:
        print("  (æ— )")
    
    print(f"\nğŸ“‹ è¯¦ç»†ç»Ÿè®¡:")
    for key, stats in analysis['key_statistics'].items():
        print(f"\n  {key}:")
        print(f"    - å‡ºç°æ¬¡æ•°: {stats['count']}")
        print(f"    - å”¯ä¸€å½¢çŠ¶æ•°: {len(stats['unique_shapes'])}")
        print(f"    - å”¯ä¸€ç±»å‹æ•°: {len(stats['unique_dtypes'])}")
        print(f"    - æ˜¯å¦å®šé•¿: {stats['is_fixed_length']}")
        if len(stats['unique_shapes']) <= 5:
            print(f"    - æ‰€æœ‰å½¢çŠ¶: {stats['unique_shapes']}")
        else:
            print(f"    - å‰5ä¸ªå½¢çŠ¶: {stats['sample_shapes']}")
    
    print("\n" + "="*80)
    print("ğŸ’¡ å­˜å‚¨æ ¼å¼å»ºè®®:")
    print("="*80)
    
    if summary['fixed_length_keys']:
        print("\nâœ… å®šé•¿æ•°æ®å¯ä»¥ç›´æ¥æ‹¼æ¥å­˜å‚¨ï¼ˆç±»ä¼¼ EdgeSAM æ–¹æ¡ˆï¼‰:")
        for key in summary['fixed_length_keys']:
            stats = analysis['key_statistics'][key]
            shape_str = stats['unique_shapes'][0]
            print(f"  - {key}: {shape_str}")
    
    if summary['variable_length_keys']:
        print("\nâš ï¸  å˜é•¿æ•°æ®éœ€è¦ç´¢å¼•æ–‡ä»¶ï¼ˆè®°å½• offset å’Œ lengthï¼‰:")
        for key in summary['variable_length_keys']:
            print(f"  - {key}")
        print("\n  å»ºè®®æ–¹æ¡ˆ:")
        print("  1. å°†ä¸åŒé”®æ‹†åˆ†åˆ°ä¸åŒçš„ .bin æ–‡ä»¶ï¼ˆåˆ—å¼å­˜å‚¨ï¼‰")
        print("  2. å®šé•¿é”®: features.bin, edge_*.bin ç­‰")
        print("  3. å˜é•¿é”®: bboxes.bin, masks.bin ç­‰ + ç´¢å¼•æ–‡ä»¶")
        print("  4. ç´¢å¼•æ–‡ä»¶æ ¼å¼: sample_id, offset, length (æ¯ä¸ªå˜é•¿é”®ä¸€ä¸ªç´¢å¼•)")
    
    print("\n" + "="*80)


def main():
    parser = argparse.ArgumentParser(
        description="åˆ†æ tar æ–‡ä»¶ä¸­çš„ npz æ–‡ä»¶ç»“æ„ï¼Œåˆ¤æ–­æ•°æ®æ˜¯å®šé•¿è¿˜æ˜¯å˜é•¿"
    )
    parser.add_argument(
        'tar_path',
        type=Path,
        nargs='?',
        help='tar æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ª shardï¼‰'
    )
    parser.add_argument(
        '--max-samples',
        type=int,
        default=100,
        help='æœ€å¤§åˆ†ææ ·æœ¬æ•°ï¼ˆé»˜è®¤: 100ï¼‰'
    )
    parser.add_argument(
        '--shard-dir',
        type=Path,
        help='shard ç›®å½•ï¼ˆå¦‚æœæœªæŒ‡å®š tar_pathï¼Œåˆ™ä»è¯¥ç›®å½•æŸ¥æ‰¾ç¬¬ä¸€ä¸ª .tar æ–‡ä»¶ï¼‰'
    )
    
    args = parser.parse_args()
    
    # ç¡®å®š tar æ–‡ä»¶è·¯å¾„
    tar_path = args.tar_path
    if tar_path is None:
        if args.shard_dir:
            shard_dir = args.shard_dir
        else:
            # é»˜è®¤è·¯å¾„
            shard_dir = Path("/home/team/zouzhiyuan/dataset/sa1b_tar_shards")
        
        if shard_dir.exists():
            tar_files = sorted(list(shard_dir.glob("*.tar*")))
            if tar_files:
                tar_path = tar_files[0]
                print(f"ğŸ“ æœªæŒ‡å®š tar æ–‡ä»¶ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª: {tar_path}")
            else:
                print(f"âŒ é”™è¯¯ï¼šåœ¨ {shard_dir} ä¸­æœªæ‰¾åˆ° .tar æ–‡ä»¶")
                sys.exit(1)
        else:
            print(f"âŒ é”™è¯¯ï¼šç›®å½•ä¸å­˜åœ¨: {shard_dir}")
            sys.exit(1)
    
    # æ‰§è¡Œåˆ†æ
    analysis_result = analyze_tar_file(tar_path, max_samples=args.max_samples)
    
    # æ‰“å°æŠ¥å‘Š
    print_analysis_report(analysis_result)
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    output_path = Path("npz_structure_analysis.txt")
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("NPZ æ•°æ®ç»“æ„åˆ†ææŠ¥å‘Š\n")
        f.write("="*80 + "\n\n")
        
        if analysis_result:
            analysis = analysis_result['analysis']
            summary = analysis['summary']
            
            f.write(f"åˆ†ææ ·æœ¬æ•°: {analysis['total_samples']}\n")
            f.write(f"æ€»é”®æ•°: {summary['total_keys']}\n")
            f.write(f"å®šé•¿é”®æ•°: {len(summary['fixed_length_keys'])}\n")
            f.write(f"å˜é•¿é”®æ•°: {len(summary['variable_length_keys'])}\n\n")
            
            f.write("å®šé•¿é”®:\n")
            for key in summary['fixed_length_keys']:
                stats = analysis['key_statistics'][key]
                f.write(f"  {key}: {stats['unique_shapes'][0]}\n")
            
            f.write("\nå˜é•¿é”®:\n")
            for key in summary['variable_length_keys']:
                stats = analysis['key_statistics'][key]
                f.write(f"  {key}: {len(stats['unique_shapes'])} ç§å½¢çŠ¶\n")
    
    print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")


if __name__ == "__main__":
    main()

