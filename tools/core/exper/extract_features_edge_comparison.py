#!/usr/bin/env python3
"""
è¾¹ç¼˜æå–æ–¹æ³•å¯¹æ¯”å®éªŒè„šæœ¬
å¯¹æ¯”ä¸‰ç§è¾¹ç¼˜æå–æ–¹æ³•ï¼š
- Method A (Baseline): Union mask then extract edge
- Method B (Improvement 1): Extract edge per instance then merge
- Method C (Improvement 2): Instance mask map (different values) then morphology

åªå…³æ³¨è¾¹ç¼˜æå–é€Ÿåº¦ï¼Œä¸‰ç§æ–¹æ³•éƒ½ä»åŒä¸€ä¸ªJSONå¼€å§‹ç‹¬ç«‹å¤„ç†
"""

import os
import sys
import torch
import torch.nn.functional as F
import numpy as np
from pathlib import Path
import argparse
from tqdm import tqdm
import json
import cv2
from pycocotools import mask as mask_utils
import time
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„å’ŒSAM2è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


def set_cuda_device(device_str):
    """
    Set CUDA device and ensure single GPU usage
    
    Args:
        device_str: Device string like 'cuda:5' or 'cuda'
    """
    if not torch.cuda.is_available():
        print("[WARNING] CUDA not available, using CPU")
        return torch.device('cpu')
    
    # Extract device index from string like 'cuda:5'
    if ':' in device_str:
        device_idx = int(device_str.split(':')[1])
    else:
        device_idx = 0
    
    # Check if device exists
    if device_idx >= torch.cuda.device_count():
        print(f"[WARNING] Device cuda:{device_idx} does not exist. Available devices: {torch.cuda.device_count()}")
        print(f"[WARNING] Using default device: cuda:0")
        device_idx = 0
    
    # Set CUDA device (this ensures all operations use this device)
    torch.cuda.set_device(device_idx)
    device = torch.device(f'cuda:{device_idx}')
    
    print(f"[CUDA] Using device: cuda:{device_idx} ({torch.cuda.get_device_name(device_idx)})")
    print(f"[CUDA] Current device: {torch.cuda.current_device()}")
    
    # Verify device setting
    test_tensor = torch.randn(1, 1).to(device)
    if test_tensor.device.index != device_idx:
        raise RuntimeError(f"Device setting failed: tensor on {test_tensor.device} but expected cuda:{device_idx}")
    
    return device


# å¯¼å…¥ bbox æå–å™¨
from tools.core.bbox import SA1BInstanceBoxExtractor


class EdgeExtractionComparison:
    """è¾¹ç¼˜æå–æ–¹æ³•å¯¹æ¯”å®éªŒ"""
    
    def __init__(self, config):
        """
        åˆå§‹åŒ–
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        
        # è¾¹ç¼˜æå–é…ç½®
        self.kernel_size = config.get('kernel_size', 3)
        self.kernel = np.ones((self.kernel_size, self.kernel_size), dtype=np.uint8)
        
        # CUDAè®¾å¤‡é…ç½®
        self.device = None
        if 'device' in config:
            device_str = config['device']
            if isinstance(device_str, str) and 'cuda' in device_str:
                if ':' in device_str:
                    device_idx = int(device_str.split(':')[1])
                else:
                    device_idx = 0
                self.device = torch.device(f'cuda:{device_idx}')
            elif hasattr(device_str, 'index'):
                self.device = device_str
            else:
                self.device = torch.device('cpu')
        
        # åˆ›å»ºPyTorchå½¢æ€å­¦æ¢¯åº¦kernelï¼ˆç”¨äºCUDAåŠ é€Ÿï¼‰
        if self.device and self.device.type == 'cuda':
            # å½¢æ€å­¦æ¢¯åº¦ = dilation - erosion
            # dilationç”¨max_pool2då®ç°ï¼Œerosionç”¨min_pool2då®ç°
            self.use_cuda = True
            self.kernel_tensor = torch.ones(1, 1, self.kernel_size, self.kernel_size, dtype=torch.float32, device=self.device)
        else:
            self.use_cuda = False
            self.kernel_tensor = None
        
        print(f"âœ… Edge Extraction Comparison Initialized")
        print(f"Kernel size: {self.kernel_size}")
        print(f"CUDA acceleration: {self.use_cuda}")
        if self.use_cuda:
            print(f"Device: {self.device}")
    
    def method_a_baseline(self, json_path, edge_sizes=[256, 64, 32]):
        """
        Method A (Baseline): Union mask then extract edge
        ä»JSONå¼€å§‹ç‹¬ç«‹å¤„ç†ï¼šè§£ç â†’åˆå¹¶æ©ç â†’æå–è¾¹ç¼˜
        """
        # ä»JSONå¼€å§‹å¤„ç†ï¼ˆç‹¬ç«‹ï¼‰
        with open(json_path, 'r') as f:
            data = json.load(f)
        
        height = data['image']['height']
        width = data['image']['width']
        annotations = data['annotations']
        
        # è§£ç å¹¶åˆå¹¶æ©ç 
        if len(annotations) == 0:
            union_mask = np.zeros((height, width), dtype=np.uint8)
        else:
            union_mask = np.zeros((height, width), dtype=np.uint8)
            for ann in annotations:
                rle = ann['segmentation']
                mask = mask_utils.decode(rle)  # ä»RLEè§£ç 
                union_mask = np.maximum(union_mask, mask)
        
        # æå–è¾¹ç¼˜
        combined_edge_map = cv2.morphologyEx(union_mask, cv2.MORPH_GRADIENT, self.kernel)
        
        # ç”Ÿæˆå¤šå°ºåº¦è¾¹ç¼˜å›¾
        edge_maps = {'original': combined_edge_map}
        for size in edge_sizes:
            edge_float = combined_edge_map.astype(np.float32)
            edge_small = cv2.resize(edge_float, (size, size), interpolation=cv2.INTER_AREA)
            edge_maps[size] = (edge_small > 0).astype(np.uint8)
        
        return edge_maps, union_mask
    def _morphological_gradient_cuda(self, mask_tensor):
        """
        ä½¿ç”¨CUDAå®ç°çš„å½¢æ€å­¦æ¢¯åº¦ï¼šdilation - erosion
        mask_tensor: [N, 1, H, W] float32 tensor on GPU
        Returns: [N, 1, H, W] gradient tensor
        """
        # Dilation: max pooling (å–é‚»åŸŸæœ€å¤§å€¼)
        dilation = F.max_pool2d(
            mask_tensor,
            kernel_size=self.kernel_size,
            stride=1,
            padding=self.kernel_size // 2
        )
        
        # Erosion: ä½¿ç”¨æŠ€å·§ -max_pool2d(-mask)
        erosion = -F.max_pool2d(
            -mask_tensor,
            kernel_size=self.kernel_size,
            stride=1,
            padding=self.kernel_size // 2
        )
        
        # Gradient = dilation - erosion
        gradient = dilation - erosion
        
        return gradient

    
    
    
    def method_b_per_instance(self, json_path, edge_sizes=[256, 64, 32], use_cuda=False):
        """
        Method B (Optimized): Extract edge per instance then merge
        ä¼˜åŒ–ï¼šä½¿ç”¨bitwise_oræ›¿ä»£logical_orï¼Œå»æ‰å¾ªç¯å†…çš„ç±»å‹è½¬æ¢
        CUDAåŠ é€Ÿï¼šå¦‚æœuse_cuda=Trueä¸”è®¾å¤‡å¯ç”¨ï¼Œæ‰¹é‡å¤„ç†maskåœ¨GPUä¸Š
        """
        # ä»JSONå¼€å§‹å¤„ç†ï¼ˆç‹¬ç«‹ï¼‰
        with open(json_path, 'r') as f:
            data = json.load(f)
        
        height = data['image']['height']
        width = data['image']['width']
        annotations = data['annotations']
        
        # å†³å®šæ˜¯å¦ä½¿ç”¨CUDA
        use_cuda_accel = use_cuda and self.use_cuda and self.device is not None
        
        if use_cuda_accel and len(annotations) > 0:
            # CUDAåŠ é€Ÿç‰ˆæœ¬ï¼šåˆ†æ‰¹å¤„ç†maské¿å…OOM
            mask_list = []
            union_mask = np.zeros((height, width), dtype=np.uint8)
            
            for ann in annotations:
                rle = ann['segmentation']
                mask = mask_utils.decode(rle).astype(np.float32)
                union_mask = np.maximum(union_mask, mask.astype(np.uint8))
                mask_list.append(mask)
            
            # åˆ†æ‰¹å¤„ç†ï¼šæ¯æ‰¹æœ€å¤š32ä¸ªmaskï¼ˆå¯æ ¹æ®GPUå†…å­˜è°ƒæ•´ï¼‰
            batch_size = 32
            combined_edge_map = np.zeros((height, width), dtype=np.uint8)
            
            for i in range(0, len(mask_list), batch_size):
                batch_masks = mask_list[i:i+batch_size]
                
                # å †å æˆtensor [N, 1, H, W]
                masks_tensor = torch.stack([
                    torch.from_numpy(m).to(self.device).unsqueeze(0)
                    for m in batch_masks
                ])  # [N, 1, H, W]
                
                # æ‰¹é‡è®¡ç®—å½¢æ€å­¦æ¢¯åº¦
                edges_tensor = self._morphological_gradient_cuda(masks_tensor)  # [N, 1, H, W]
                
                # åˆå¹¶è¾¹ç¼˜ï¼šä½¿ç”¨torch.maxåˆå¹¶å½“å‰æ‰¹æ¬¡
                batch_edges = edges_tensor.max(dim=0)[0]  # [1, H, W]
                batch_edges = (batch_edges > 0).float()
                
                # è½¬å›CPU numpyå¹¶åˆå¹¶åˆ°æ€»ç»“æœ
                batch_edge_map = (batch_edges.squeeze().cpu().numpy() > 0).astype(np.uint8)
                combined_edge_map = np.bitwise_or(combined_edge_map, batch_edge_map)
                
                # æ¸…ç†GPUå†…å­˜
                del masks_tensor, edges_tensor, batch_edges
                torch.cuda.empty_cache()
        else:
            # CPUç‰ˆæœ¬ï¼ˆåŸå§‹ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
            combined_edge_map = np.zeros((height, width), dtype=np.uint8)
            union_mask = np.zeros((height, width), dtype=np.uint8)
            
            if len(annotations) == 0:
                pass
            else:
                for ann in annotations:
                    rle = ann['segmentation']
                    mask = mask_utils.decode(rle)  # ä»RLEè§£ç 
                    
                    # åˆå¹¶æ©ç ï¼ˆç”¨äºè¿”å›ï¼‰
                    union_mask = np.maximum(union_mask, mask)
                    
                    # å¯¹æ¯ä¸ªå®ä¾‹å•ç‹¬æå–è¾¹ç¼˜
                    edge = cv2.morphologyEx(mask, cv2.MORPH_GRADIENT, self.kernel)
                    # äºŒå€¼åŒ–å¹¶ç¡®ä¿uint8ç±»å‹ï¼ˆé¿å…ç±»å‹ä¸åŒ¹é…å’Œæº¢å‡ºè­¦å‘Šï¼‰
                    edge = (edge > 0).astype(np.uint8)
                    
                    # ä½¿ç”¨bitwise_oræ›¿ä»£logical_orï¼ˆç›´æ¥åœ¨uint8ä¸Šæ“ä½œï¼‰
                    combined_edge_map = np.bitwise_or(combined_edge_map, edge)
        
        # ç”Ÿæˆå¤šå°ºåº¦è¾¹ç¼˜å›¾
        edge_maps = {'original': combined_edge_map}
        for size in edge_sizes:
            edge_float = combined_edge_map.astype(np.float32)
            edge_small = cv2.resize(edge_float, (size, size), interpolation=cv2.INTER_AREA)
            edge_maps[size] = (edge_small > 0).astype(np.uint8)
        
        return edge_maps, union_mask
    def method_b_per_instance_original(self, json_path, edge_sizes=[256, 64, 32]):
        """
        Method B (Original): Extract edge per instance then merge
        åŸå§‹ç‰ˆæœ¬ï¼šä½¿ç”¨logical_or + astype(np.uint8)ï¼ˆæ¯æ¬¡å¾ªç¯éƒ½è½¬æ¢ï¼‰
        ç”¨äºå¯¹æ¯”ä¼˜åŒ–å‰åçš„æ•ˆæœ
        """
        # ä»JSONå¼€å§‹å¤„ç†ï¼ˆç‹¬ç«‹ï¼‰
        with open(json_path, 'r') as f:
            data = json.load(f)
        
        height = data['image']['height']
        width = data['image']['width']
        annotations = data['annotations']
        
        # åˆå¹¶è¾¹ç¼˜å›¾
        combined_edge_map = np.zeros((height, width), dtype=np.uint8)
        union_mask = np.zeros((height, width), dtype=np.uint8)
        
        if len(annotations) == 0:
            pass
        else:
            for ann in annotations:
                rle = ann['segmentation']
                mask = mask_utils.decode(rle)  # ä»RLEè§£ç 
                
                # åˆå¹¶æ©ç ï¼ˆç”¨äºè¿”å›ï¼‰
                union_mask = np.maximum(union_mask, mask)
                
                # å¯¹æ¯ä¸ªå®ä¾‹å•ç‹¬æå–è¾¹ç¼˜
                edge = cv2.morphologyEx(mask, cv2.MORPH_GRADIENT, self.kernel)
                
                # åŸå§‹ç‰ˆæœ¬ï¼šä½¿ç”¨logical_or + æ¯æ¬¡å¾ªç¯éƒ½è½¬æ¢ç±»å‹
                combined_edge_map = np.logical_or(combined_edge_map, edge).astype(np.uint8)
        
        # ç”Ÿæˆå¤šå°ºåº¦è¾¹ç¼˜å›¾
        edge_maps = {'original': combined_edge_map}
        for size in edge_sizes:
            edge_float = combined_edge_map.astype(np.float32)
            edge_small = cv2.resize(edge_float, (size, size), interpolation=cv2.INTER_AREA)
            edge_maps[size] = (edge_small > 0).astype(np.uint8)
        
        return edge_maps, union_mask
    
    def method_c_instance_mask(self, json_path, edge_sizes=[256, 64, 32]):
        """
        Method C (Improvement 2): Instance mask map (different values) then morphology
        ä»JSONå¼€å§‹ç‹¬ç«‹å¤„ç†ï¼šè§£ç â†’å®ä¾‹æ©ç å›¾ï¼ˆä¸åŒå€¼ï¼‰â†’å½¢æ€å­¦æ“ä½œ
        ä¼˜åŒ–ï¼šç›´æ¥ä½¿ç”¨uint8ï¼Œæ— éœ€æ£€æŸ¥
        """
        # ä»JSONå¼€å§‹å¤„ç†ï¼ˆç‹¬ç«‹ï¼‰
        with open(json_path, 'r') as f:
            data = json.load(f)
        
        height = data['image']['height']
        width = data['image']['width']
        annotations = data['annotations']
        
        # å®ä¾‹æ©ç å›¾ï¼šæ¯ä¸ªå®ä¾‹ä½¿ç”¨ä¸åŒçš„å€¼ï¼ˆç›´æ¥ä½¿ç”¨uint8ï¼Œ1, 2, 3, ...ï¼‰
        instance_mask_map = np.zeros((height, width), dtype=np.uint8)
        union_mask = np.zeros((height, width), dtype=np.uint8)
        
        if len(annotations) == 0:
            pass
        else:
            for idx, ann in enumerate(annotations):
                rle = ann['segmentation']
                mask = mask_utils.decode(rle)  # ä»RLEè§£ç 
                
                # åˆå¹¶æ©ç ï¼ˆç”¨äºè¿”å›æ™®é€šunion_maskï¼‰
                union_mask = np.maximum(union_mask, mask)
                
                # ç›´æ¥åˆ†é…ï¼šç¬¬ä¸€ä¸ªå®ä¾‹=1ï¼Œç¬¬äºŒä¸ª=2ï¼Œ...ï¼ˆæ— éœ€æ£€æŸ¥ï¼Œå‡è®¾<256ä¸ªå®ä¾‹ï¼‰
                instance_mask_map[mask > 0] = idx + 1
        
        # ç›´æ¥åº”ç”¨å½¢æ€å­¦æ¢¯åº¦ï¼ˆæ— éœ€ç±»å‹è½¬æ¢å’Œæ£€æŸ¥ï¼‰
        combined_edge_map = cv2.morphologyEx(instance_mask_map, cv2.MORPH_GRADIENT, self.kernel)
        
        # è½¬æ¢ä¸ºäºŒå€¼ï¼šä»»ä½•å€¼å˜åŒ–ï¼ˆéé›¶æ¢¯åº¦ï¼‰éƒ½æ˜¯è¾¹ç¼˜
        combined_edge_map = (combined_edge_map > 0).astype(np.uint8)
        
        # ç”Ÿæˆå¤šå°ºåº¦è¾¹ç¼˜å›¾
        edge_maps = {'original': combined_edge_map}
        for size in edge_sizes:
            edge_float = combined_edge_map.astype(np.float32)
            edge_small = cv2.resize(edge_float, (size, size), interpolation=cv2.INTER_AREA)
            edge_maps[size] = (edge_small > 0).astype(np.uint8)
        
        # è¿”å›edge_maps, union_mask, instance_mask_mapï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        return edge_maps, union_mask, instance_mask_map
    
    def method_c_instance_mask_optimized(self, json_path, edge_sizes=[256, 64, 32]):
        """
        Method C (Optimized): è´¨é‡ä¼˜åŒ–ç‰ˆæœ¬ - å¤„ç†é‡å åŒºåŸŸ
        éé‡å åŒºåŸŸï¼šä½¿ç”¨å®ä¾‹æ©ç å›¾ä¸€æ¬¡å½¢æ€å­¦
        é‡å åŒºåŸŸï¼šå•ç‹¬æå–è¾¹ç¼˜
        """
        # ä»JSONå¼€å§‹å¤„ç†ï¼ˆç‹¬ç«‹ï¼‰
        with open(json_path, 'r') as f:
            data = json.load(f)
        
        height = data['image']['height']
        width = data['image']['width']
        annotations = data['annotations']
        
        # å®ä¾‹æ©ç å›¾ï¼šæ¯ä¸ªå®ä¾‹ä½¿ç”¨ä¸åŒçš„å€¼
        instance_mask_map = np.zeros((height, width), dtype=np.uint8)
        union_mask = np.zeros((height, width), dtype=np.uint8)
        overlap_masks = []  # å­˜å‚¨æœ‰é‡å çš„mask
        
        if len(annotations) == 0:
            pass
        else:
            for idx, ann in enumerate(annotations):
                rle = ann['segmentation']
                mask = mask_utils.decode(rle)
                
                union_mask = np.maximum(union_mask, mask)
                
                # æ£€æµ‹æ˜¯å¦æœ‰é‡å ï¼ˆä¸å·²åˆ†é…çš„åŒºåŸŸé‡å ï¼‰
                has_overlap = (instance_mask_map > 0) & (mask > 0)
                
                if has_overlap.any():
                    # æœ‰é‡å ï¼šä¿å­˜è¿™ä¸ªmaskï¼Œåç»­å•ç‹¬å¤„ç†
                    overlap_masks.append(mask)
                else:
                    # æ— é‡å ï¼šæ­£å¸¸åˆ†é…ID
                    instance_mask_map[mask > 0] = idx + 1
        
        # éé‡å åŒºåŸŸçš„è¾¹ç¼˜ï¼ˆä»å®ä¾‹æ©ç å›¾æå–ï¼‰
        if instance_mask_map.max() > 0:
            edge_from_instance = cv2.morphologyEx(instance_mask_map, cv2.MORPH_GRADIENT, self.kernel)
            edge_from_instance = (edge_from_instance > 0).astype(np.uint8)
        else:
            edge_from_instance = np.zeros((height, width), dtype=np.uint8)
        
        # é‡å åŒºåŸŸçš„è¾¹ç¼˜ï¼ˆå•ç‹¬æå–ï¼‰
        edge_from_overlap = np.zeros((height, width), dtype=np.uint8)
        for mask in overlap_masks:
            edge = cv2.morphologyEx(mask, cv2.MORPH_GRADIENT, self.kernel)
            edge_from_overlap = np.logical_or(edge_from_overlap, edge).astype(np.uint8)
        
        # åˆå¹¶ä¸¤ç§è¾¹ç¼˜
        combined_edge_map = np.logical_or(edge_from_instance, edge_from_overlap).astype(np.uint8)
        
        # ç”Ÿæˆå¤šå°ºåº¦è¾¹ç¼˜å›¾
        edge_maps = {'original': combined_edge_map}
        for size in edge_sizes:
            edge_float = combined_edge_map.astype(np.float32)
            edge_small = cv2.resize(edge_float, (size, size), interpolation=cv2.INTER_AREA)
            edge_maps[size] = (edge_small > 0).astype(np.uint8)
        
        return edge_maps, union_mask, instance_mask_map
    
    def process_single_image_speed_test(self, json_path, methods=['a', 'b', 'c']):
        """
        çº¯é€Ÿåº¦æµ‹è¯•ï¼šåªç»Ÿè®¡è¾¹ç¼˜æå–æ—¶é—´ï¼ˆä»JSONå¼€å§‹åˆ°è¿”å›è¾¹ç¼˜å›¾ï¼‰
        ä¸åŠ è½½å›¾åƒï¼Œä¸ç”Ÿæˆå¯è§†åŒ–ï¼Œä¸ä¿å­˜æ–‡ä»¶
        
        Args:
            methods: è¦æµ‹è¯•çš„æ–¹æ³•åˆ—è¡¨ï¼Œå¦‚ ['b'] åªæµ‹è¯•Method B
        
        Returns:
            dict: åŒ…å«timingså’Œedge_pixelsç»Ÿè®¡
        """
        timings = {}
        edge_pixels = {}
        
        if 'a' in methods:
            # Method A: ä»JSONå¼€å§‹ï¼Œç»Ÿè®¡å®Œæ•´æ—¶é—´
            t0 = time.time()
            edge_maps_a, union_mask_a = self.method_a_baseline(json_path)
            timings['method_a'] = time.time() - t0
            edge_pixels['method_a'] = edge_maps_a[256].sum()
        
        if 'b' in methods:
            # Method B: ä»JSONå¼€å§‹ï¼Œç»Ÿè®¡å®Œæ•´æ—¶é—´
            t0 = time.time()
            edge_maps_b, union_mask_b = self.method_b_per_instance(json_path)
            timings['method_b'] = time.time() - t0
            edge_pixels['method_b'] = edge_maps_b[256].sum()
        
        if 'c' in methods:
            # Method C: ä»JSONå¼€å§‹ï¼Œç»Ÿè®¡å®Œæ•´æ—¶é—´
            t0 = time.time()
            edge_maps_c, union_mask_c, instance_mask_map_c = self.method_c_instance_mask(json_path)
            timings['method_c'] = time.time() - t0
            edge_pixels['method_c'] = edge_maps_c[256].sum()
            
            # Method C Optimized: è´¨é‡ä¼˜åŒ–ç‰ˆæœ¬
            t0 = time.time()
            edge_maps_c_opt, union_mask_c_opt, instance_mask_map_c_opt = self.method_c_instance_mask_optimized(json_path)
            timings['method_c_optimized'] = time.time() - t0
            edge_pixels['method_c_optimized'] = edge_maps_c_opt[256].sum()
        
        return {
            'timings': timings,
            'edge_pixels': edge_pixels
        }
    
    def process_single_image_visualization(self, image_path, json_path, output_dir, show_method_b_only=False):
        """
        å¯è§†åŒ–ï¼šä¸è®¡æ—¶ï¼Œåªç”Ÿæˆå¯¹æ¯”å›¾
        
        Args:
            show_method_b_only: å¦‚æœTrueï¼Œåªæ˜¾ç¤ºåŸå›¾+A+B+Bä¼˜åŒ–ï¼ˆ4åˆ—ï¼‰
        """
        image_id = Path(image_path).stem
        
        try:
            # åŠ è½½å›¾åƒ
            image = cv2.imread(str(image_path))
            if image is None:
                raise ValueError(f"Cannot load image: {image_path}")
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            if show_method_b_only:
                # åªè¿è¡ŒAå’ŒBæ–¹æ³•ï¼ˆBçš„åŸå§‹ç‰ˆæœ¬å’Œä¼˜åŒ–ç‰ˆæœ¬ï¼‰
                edge_maps_a, union_mask_a = self.method_a_baseline(json_path)
                edge_maps_b_original, union_mask_b_orig = self.method_b_per_instance_original(json_path)  # åŸå§‹ç‰ˆæœ¬
                edge_maps_b_optimized, union_mask_b_opt = self.method_b_per_instance(json_path)  # ä¼˜åŒ–ç‰ˆæœ¬
                
                # ç”Ÿæˆå¯è§†åŒ–ï¼ˆ4åˆ—ï¼šåŸå›¾+A+BåŸå§‹+Bä¼˜åŒ–ï¼‰
                self.visualize_comparison_method_b_only(
                    image_rgb,
                    edge_maps_a[256],
                    edge_maps_b_original[256],  # åŸå§‹ç‰ˆæœ¬
                    edge_maps_b_optimized[256],  # ä¼˜åŒ–ç‰ˆæœ¬
                    output_dir / f"{image_id}_comparison.png"
                )
            else:
                # è¿è¡Œæ‰€æœ‰æ–¹æ³•ï¼ˆåŸå§‹5åˆ—å¸ƒå±€ï¼‰
                edge_maps_a, union_mask_a = self.method_a_baseline(json_path)
                edge_maps_b, union_mask_b = self.method_b_per_instance(json_path)  # å·²ä¼˜åŒ–
                edge_maps_c, union_mask_c, instance_mask_map = self.method_c_instance_mask(json_path)
                edge_maps_c_opt, union_mask_c_opt, instance_mask_map_opt = self.method_c_instance_mask_optimized(json_path)
                
                # ç”Ÿæˆå¯è§†åŒ–ï¼ˆ5åˆ—ï¼šåŸå›¾+A+B+C+ä¼˜åŒ–Cï¼‰
                self.visualize_comparison(
                    image_rgb,
                    edge_maps_a[256],
                    edge_maps_b[256],
                    edge_maps_c[256],
                    edge_maps_c_opt[256],
                    instance_mask_map,
                    output_dir / f"{image_id}_comparison.png"
                )
            
            return {'success': True, 'image_id': image_id}
            
        except Exception as e:
            return {'success': False, 'image_id': image_id, 'error': str(e)}
    
    def visualize_comparison(self, image, edge_a, edge_b, edge_c, edge_c_opt, instance_mask_map, output_path):
        """
        Visualize comparison: 5 subplots (Original, Method A, Method B, Method C, Method C Optimized)
        """
        fig = plt.figure(figsize=(20, 4))
        gs = GridSpec(1, 5, figure=fig, hspace=0.3, wspace=0.3)
        
        # Original image
        ax0 = fig.add_subplot(gs[0, 0])
        ax0.imshow(image)
        ax0.set_title("Original Image", fontsize=12, fontweight='bold')
        ax0.axis('off')
        
        # Method A: Baseline
        ax1 = fig.add_subplot(gs[0, 1])
        ax1.imshow(edge_a, cmap='hot', vmin=0, vmax=1)
        ax1.set_title(f"Method A (Baseline)\nUnion mask â†’ Edge\nPixels: {edge_a.sum()}", 
                      fontsize=11, fontweight='bold')
        ax1.axis('off')
        
        # Method B: Per instance
        ax2 = fig.add_subplot(gs[0, 2])
        ax2.imshow(edge_b, cmap='hot', vmin=0, vmax=1)
        ax2.set_title(f"Method B (Per Instance)\nEdge per mask â†’ Merge\nPixels: {edge_b.sum()}", 
                      fontsize=11, fontweight='bold')
        ax2.axis('off')
        
        # Method C: Instance map
        ax3 = fig.add_subplot(gs[0, 3])
        ax3.imshow(edge_c, cmap='hot', vmin=0, vmax=1)
        ax3.set_title(f"Method C (Instance Map)\nInstance map â†’ Morphology\nEdge Pixels: {edge_c.sum()}", 
                      fontsize=11, fontweight='bold')
        ax3.axis('off')
        
        # Method C Optimized: è´¨é‡ä¼˜åŒ–ç‰ˆæœ¬
        ax4 = fig.add_subplot(gs[0, 4])
        ax4.imshow(edge_c_opt, cmap='hot', vmin=0, vmax=1)
        ax4.set_title(f"Method C (Optimized)\nHandle overlap regions\nEdge Pixels: {edge_c_opt.sum()}", 
                      fontsize=11, fontweight='bold', color='green')
        ax4.axis('off')
        
        plt.suptitle(f'Edge Extraction Comparison - {Path(output_path).stem}', 
                    fontsize=14, fontweight='bold', y=0.98)
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
    
    def visualize_comparison_method_b_only(self, image, edge_a, edge_b_original, edge_b_optimized, output_path):
        """
        Visualize comparison: 4 subplots (Original, Method A, Method B Original, Method B Optimized)
        ç”¨äºå¯¹æ¯”Bæ–¹æ³•ä¼˜åŒ–å‰åçš„æ•ˆæœ
        """
        fig = plt.figure(figsize=(16, 4))
        gs = GridSpec(1, 4, figure=fig, hspace=0.3, wspace=0.3)
        
        # Original image
        ax0 = fig.add_subplot(gs[0, 0])
        ax0.imshow(image)
        ax0.set_title("Original Image", fontsize=12, fontweight='bold')
        ax0.axis('off')
        
        # Method A: Baseline
        ax1 = fig.add_subplot(gs[0, 1])
        ax1.imshow(edge_a, cmap='hot', vmin=0, vmax=1)
        ax1.set_title(f"Method A (Baseline)\nUnion mask â†’ Edge\nPixels: {edge_a.sum()}", 
                      fontsize=11, fontweight='bold')
        ax1.axis('off')
        
        # Method B Original: åŸå§‹ç‰ˆæœ¬ï¼ˆlogical_or + æ¯æ¬¡è½¬æ¢ï¼‰
        ax2 = fig.add_subplot(gs[0, 2])
        ax2.imshow(edge_b_original, cmap='hot', vmin=0, vmax=1)
        ax2.set_title(f"Method B (Original)\nlogical_or + astype\nPixels: {edge_b_original.sum()}", 
                      fontsize=11, fontweight='bold')
        ax2.axis('off')
        
        # Method B Optimized: ä¼˜åŒ–åçš„ç‰ˆæœ¬ï¼ˆbitwise_or + äºŒå€¼åŒ–ï¼‰
        ax3 = fig.add_subplot(gs[0, 3])
        ax3.imshow(edge_b_optimized, cmap='hot', vmin=0, vmax=1)
        ax3.set_title(f"Method B (Optimized)\nbitwise_or + binary\nPixels: {edge_b_optimized.sum()}", 
                      fontsize=11, fontweight='bold', color='green')
        ax3.axis('off')
        
        plt.suptitle(f'Edge Extraction Comparison (Method B) - {Path(output_path).stem}', 
                    fontsize=14, fontweight='bold', y=0.98)
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
    
    def batch_speed_test(self, data_dir, max_images=100, methods=['a', 'b', 'c']):
        """
        çº¯é€Ÿåº¦æµ‹è¯•ï¼šåªç»Ÿè®¡è¾¹ç¼˜æå–æ—¶é—´
        æ ¹æ®methodså‚æ•°é€‰æ‹©è¦æµ‹è¯•çš„æ–¹æ³•
        
        Args:
            methods: è¦æµ‹è¯•çš„æ–¹æ³•åˆ—è¡¨ï¼Œå¦‚ ['b'] åªæµ‹è¯•Method B
        """
        data_path = Path(data_dir)
        
        # è·å–JSONæ–‡ä»¶åˆ—è¡¨
        json_files = sorted([f for f in data_path.glob("*.json")])[:max_images]
        
        print(f"ğŸ“ Total JSON files: {len(json_files)}")
        print(f"â±ï¸  Running speed test (edge extraction only)...")
        print(f"ğŸ“‹ Testing methods: {', '.join([f'Method {m.upper()}' for m in methods])}")
        
        success_count = 0
        error_count = 0
        
        # æ ¹æ®methodsåŠ¨æ€åˆ›å»ºç»Ÿè®¡å­—å…¸
        total_timings = {}
        edge_pixel_stats = {}
        
        if 'a' in methods:
            total_timings['method_a'] = 0.0
            edge_pixel_stats['method_a'] = []
        if 'b' in methods:
            total_timings['method_b'] = 0.0
            edge_pixel_stats['method_b'] = []
        if 'c' in methods:
            total_timings['method_c'] = 0.0
            total_timings['method_c_optimized'] = 0.0
            edge_pixel_stats['method_c'] = []
            edge_pixel_stats['method_c_optimized'] = []
        
        for json_file in tqdm(json_files, desc="Speed test"):
            try:
                result = self.process_single_image_speed_test(json_file, methods=methods)
                
                success_count += 1
                
                # ç´¯åŠ æ—¶é—´ï¼ˆåªç»Ÿè®¡è¾¹ç¼˜æå–æ—¶é—´ï¼‰
                for method in result['timings']:
                    if method in total_timings:
                        total_timings[method] += result['timings'][method]
                
                # ç´¯åŠ è¾¹ç¼˜åƒç´ ç»Ÿè®¡
                for method in result['edge_pixels']:
                    if method in edge_pixel_stats:
                        edge_pixel_stats[method].append(result['edge_pixels'][method])
                
                # æ¯10å¼ æ‰“å°ä¸€æ¬¡è¿›åº¦
                if success_count % 10 == 0:
                    timing_str = ", ".join([f"{k}: {result['timings'][k]:.4f}s" 
                                           for k in result['timings']])
                    print(f"\nâœ… {Path(json_file).stem}: {timing_str}")
            except Exception as e:
                error_count += 1
                print(f"âŒ {Path(json_file).stem}: {e}")
        
        # æ‰“å°ç»Ÿè®¡
        print(f"\nğŸ‰ Speed Test Complete!")
        print(f"âœ… Success: {success_count} images")
        print(f"âŒ Failed: {error_count} images")
        
        print(f"\nâ±ï¸  Edge Extraction Timing (per image):")
        for method, total_time in total_timings.items():
            avg_time = total_time / success_count if success_count > 0 else 0
            print(f"  {method}: {avg_time:.4f}s (total: {total_time:.2f}s)")
        
        print(f"\nğŸ“Š Edge Pixel Statistics (256Ã—256):")
        for method, pixel_list in edge_pixel_stats.items():
            if pixel_list:
                avg_pixels = np.mean(pixel_list)
                std_pixels = np.std(pixel_list)
                print(f"  {method}: mean={avg_pixels:.1f}, std={std_pixels:.1f}, "
                      f"min={np.min(pixel_list):.0f}, max={np.max(pixel_list):.0f}")
        
        # ä¼°ç®—100ä¸ªepochçš„æ—¶é—´ï¼ˆå‡è®¾æ¯å¼ å›¾éƒ½è¦å¤„ç†ï¼‰
        if success_count > 0:
            images_per_epoch = success_count
            print(f"\nğŸ“ˆ Estimated Time for 100 Epochs:")
            for method, total_time in total_timings.items():
                avg_time = total_time / success_count
                time_per_epoch = avg_time * images_per_epoch
                time_100_epochs = time_per_epoch * 100
                print(f"  {method}: {avg_time:.4f}s/img â†’ "
                      f"{time_per_epoch:.2f}s/epoch ({time_per_epoch/60:.2f} min) â†’ "
                      f"{time_100_epochs/3600:.2f} hours for 100 epochs")
        
        # é€Ÿåº¦å¯¹æ¯”åˆ†æ
        print(f"\nğŸ“Š Speed Comparison:")
        if success_count > 0:
            if 'method_a' in total_timings and 'method_b' in total_timings:
                avg_a = total_timings['method_a'] / success_count
                avg_b = total_timings['method_b'] / success_count
                print(f"  Method A (Baseline):      {avg_a:.4f}s (baseline)")
                print(f"  Method B (Per Instance):  {avg_b:.4f}s ({avg_b/avg_a:.2f}x slower)")
            
            if 'method_b' in total_timings and 'method_a' not in total_timings:
                # åªæµ‹è¯•Bæ–¹æ³•æ—¶
                avg_b = total_timings['method_b'] / success_count
                print(f"  Method B (Optimized):      {avg_b:.4f}s per image")
            
            if 'method_c' in total_timings:
                avg_c = total_timings['method_c'] / success_count
                avg_c_opt = total_timings['method_c_optimized'] / success_count
                if 'method_a' in total_timings:
                    avg_a = total_timings['method_a'] / success_count
                    print(f"  Method C (Instance Map):  {avg_c:.4f}s ({avg_c/avg_a:.2f}x slower)")
                    print(f"  Method C (Optimized):      {avg_c_opt:.4f}s ({avg_c_opt/avg_a:.2f}x slower)")
                else:
                    print(f"  Method C (Instance Map):  {avg_c:.4f}s")
                    print(f"  Method C (Optimized):      {avg_c_opt:.4f}s ({avg_c_opt/avg_c:.2f}x slower)")
    
    def batch_visualization(self, data_dir, output_dir, max_images=20, update_existing=False, show_method_b_only=False):
        """
        å¯è§†åŒ–ï¼šå‰Nå¼ å›¾ç”Ÿæˆå¯¹æ¯”å›¾
        ä¸è®¡æ—¶ï¼Œåªç”¨äºè´¨é‡å¯¹æ¯”
        å¦‚æœupdate_existing=Trueï¼Œä¼šæ›´æ–°å·²å­˜åœ¨çš„å¯è§†åŒ–å›¾ï¼ˆæ‹¼æ¥ä¼˜åŒ–Cç»“æœï¼‰
        """
        data_path = Path(data_dir)
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
        image_files = sorted(list(data_path.glob("*.jpg")))[:max_images]
        
        print(f"\nğŸ“ Generating visualizations for {len(image_files)} images...")
        print(f"ğŸ“ Output directory: {output_path}")
        print(f"ğŸ“ Update existing: {update_existing}")
        
        success_count = 0
        error_count = 0
        
        for image_file in tqdm(image_files, desc="Visualization"):
            json_file = data_path / f"{image_file.stem}.json"
            
            if not json_file.exists():
                print(f"âš ï¸  Skip {image_file.stem}: JSON file not found")
                error_count += 1
                continue
            
            # å¦‚æœupdate_existingä¸”æ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåŠ è½½åŸå›¾å†æ‹¼æ¥
            output_file = output_path / f"{image_file.stem}_comparison.png"
            if update_existing and output_file.exists():
                # åŠ è½½å·²å­˜åœ¨çš„å¯è§†åŒ–å›¾
                existing_img = plt.imread(str(output_file))
                
                # è¿è¡Œä¼˜åŒ–åçš„Method C
                edge_maps_c_opt, _, _ = self.method_c_instance_mask_optimized(json_path=json_file)
                
                # æ‹¼æ¥ï¼šåœ¨æœ€å³è¾¹æ·»åŠ ä¼˜åŒ–Cçš„ç»“æœ
                self.append_optimized_c_to_visualization(
                    output_file,
                    edge_maps_c_opt[256]
                )
                success_count += 1
            else:
                # ç”Ÿæˆæ–°çš„å¯è§†åŒ–å›¾
                result = self.process_single_image_visualization(
                    image_file, json_file, output_path,
                    show_method_b_only=show_method_b_only
                )
                
                if result['success']:
                    success_count += 1
                else:
                    error_count += 1
                    print(f"âŒ {result['image_id']}: {result['error']}")
        
        print(f"\nğŸ‰ Visualization Complete!")
        print(f"âœ… Success: {success_count} images")
        print(f"âŒ Failed: {error_count} images")
        print(f"ğŸ“ Output directory: {output_path}")
    
    def append_optimized_c_to_visualization(self, existing_img_path, edge_c_opt):
        """
        åœ¨å·²å­˜åœ¨çš„å¯è§†åŒ–å›¾çš„æœ€å³è¾¹æ‹¼æ¥ä¼˜åŒ–åçš„Method Cç»“æœ
        å¦‚æœåŸå›¾æ˜¯4åˆ—ï¼Œæ‰©å±•ä¸º5åˆ—ï¼›å¦‚æœå·²ç»æ˜¯5åˆ—ï¼Œæ›¿æ¢æœ€åä¸€åˆ—
        """
        # åŠ è½½å·²å­˜åœ¨çš„å›¾
        existing_img = plt.imread(str(existing_img_path))
        existing_height, existing_width = existing_img.shape[:2]
        
        # å¦‚æœæ˜¯RGBAï¼Œè½¬ä¸ºRGB
        if existing_img.shape[2] == 4:
            existing_img = existing_img[:, :, :3]
        
        # åˆ¤æ–­æ˜¯4åˆ—è¿˜æ˜¯5åˆ—ï¼ˆå‡è®¾æ¯åˆ—å®½åº¦ç›¸ç­‰ï¼‰
        # å…ˆå°è¯•4åˆ—
        col_width_4 = existing_width // 4
        col_width_5 = existing_width // 5
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯4åˆ—ï¼ˆä½™æ•°è¾ƒå°ï¼‰
        remainder_4 = existing_width % 4
        remainder_5 = existing_width % 5
        
        if remainder_4 < remainder_5:
            # åŸå›¾æ˜¯4åˆ—ï¼Œéœ€è¦æ‰©å±•ä¸º5åˆ—
            is_4cols = True
            col_width = col_width_4
            new_width = col_width * 5
            new_img = np.zeros((existing_height, new_width, 3))
            # å¤åˆ¶åŸæœ‰çš„4åˆ—
            new_img[:, :existing_width] = existing_img
            # åœ¨ç¬¬5åˆ—ä½ç½®æ·»åŠ ä¼˜åŒ–C
            insert_pos = existing_width
        else:
            # åŸå›¾å·²ç»æ˜¯5åˆ—ï¼Œæ›¿æ¢æœ€åä¸€åˆ—
            is_4cols = False
            col_width = col_width_5
            new_width = existing_width
            new_img = existing_img.copy()
            # æ›¿æ¢ç¬¬5åˆ—
            insert_pos = col_width * 4
        
        # å‡†å¤‡ä¼˜åŒ–Cçš„è¾¹ç¼˜å›¾ï¼ˆresizeåˆ°åˆ—å®½xé«˜åº¦ï¼‰
        # edge_c_optæ˜¯256x256çš„
        target_width = insert_pos + col_width - insert_pos  # å®é™…éœ€è¦æ’å…¥çš„å®½åº¦
        edge_c_opt_resized = cv2.resize(
            edge_c_opt.astype(np.float32),
            (target_width, existing_height),
            interpolation=cv2.INTER_AREA
        )
        
        # è½¬æ¢ä¸ºRGBï¼ˆä½¿ç”¨hot colormapï¼‰
        # å½’ä¸€åŒ–åˆ°0-1
        edge_normalized = edge_c_opt_resized.astype(np.float32)
        if edge_normalized.max() > 1:
            edge_normalized = edge_normalized / 255.0
        
        # ä½¿ç”¨hot colormapè½¬æ¢ä¸ºRGB
        edge_c_opt_rgb = plt.cm.hot(edge_normalized)[:, :, :3]
        # ç¡®ä¿å€¼åœ¨[0, 1]èŒƒå›´
        edge_c_opt_rgb = np.clip(edge_c_opt_rgb, 0, 1)
        
        # ç¡®ä¿å°ºå¯¸åŒ¹é…ï¼ˆå¯èƒ½å› ä¸ºé™¤æ³•å¯¼è‡´çš„å°è¯¯å·®ï¼‰
        actual_width = new_img.shape[1] - insert_pos
        if edge_c_opt_rgb.shape[1] != actual_width:
            edge_c_opt_rgb = cv2.resize(
                edge_c_opt_rgb.astype(np.float32),
                (actual_width, existing_height),
                interpolation=cv2.INTER_LINEAR
            )
        
        # åœ¨æŒ‡å®šä½ç½®æ’å…¥/æ›¿æ¢ä¼˜åŒ–Cçš„ç»“æœ
        new_img[:, insert_pos:insert_pos+edge_c_opt_rgb.shape[1]] = edge_c_opt_rgb
        
        # ä¿å­˜ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼‰
        plt.imsave(existing_img_path, new_img, dpi=150)
    
    def batch_test_method_c_only(self, data_dir, max_images=100):
        """
        åªæµ‹è¯•Method Cï¼ˆåŸå§‹å’Œä¼˜åŒ–ç‰ˆæœ¬ï¼‰çš„é€Ÿåº¦å’Œè´¨é‡
        """
        data_path = Path(data_dir)
        json_files = sorted([f for f in data_path.glob("*.json")])[:max_images]
        
        print(f"ğŸ“ Testing Method C only on {len(json_files)} images...")
        
        success_count = 0
        error_count = 0
        
        total_timings = {
            'method_c': 0.0,
            'method_c_optimized': 0.0,
        }
        
        edge_pixel_stats = {
            'method_c': [],
            'method_c_optimized': [],
        }
        
        for json_file in tqdm(json_files, desc="Method C test"):
            try:
                # Method CåŸå§‹ç‰ˆæœ¬
                t0 = time.time()
                edge_maps_c, _, _ = self.method_c_instance_mask(json_file)
                time_c = time.time() - t0
                
                # Method Cä¼˜åŒ–ç‰ˆæœ¬
                t0 = time.time()
                edge_maps_c_opt, _, _ = self.method_c_instance_mask_optimized(json_file)
                time_c_opt = time.time() - t0
                
                success_count += 1
                total_timings['method_c'] += time_c
                total_timings['method_c_optimized'] += time_c_opt
                edge_pixel_stats['method_c'].append(edge_maps_c[256].sum())
                edge_pixel_stats['method_c_optimized'].append(edge_maps_c_opt[256].sum())
                
                if success_count % 10 == 0:
                    print(f"\nâœ… {Path(json_file).stem}: "
                          f"Method C: {time_c:.4f}s, "
                          f"Method C Opt: {time_c_opt:.4f}s")
            except Exception as e:
                error_count += 1
                print(f"âŒ {Path(json_file).stem}: {e}")
        
        # æ‰“å°ç»Ÿè®¡
        print(f"\nğŸ‰ Method C Test Complete!")
        print(f"âœ… Success: {success_count} images")
        print(f"âŒ Failed: {error_count} images")
        
        print(f"\nâ±ï¸  Timing (per image):")
        for method, total_time in total_timings.items():
            avg_time = total_time / success_count if success_count > 0 else 0
            print(f"  {method}: {avg_time:.4f}s (total: {total_time:.2f}s)")
        
        print(f"\nğŸ“Š Edge Pixel Statistics (256Ã—256):")
        for method, pixel_list in edge_pixel_stats.items():
            if pixel_list:
                avg_pixels = np.mean(pixel_list)
                std_pixels = np.std(pixel_list)
                print(f"  {method}: mean={avg_pixels:.1f}, std={std_pixels:.1f}, "
                      f"min={np.min(pixel_list):.0f}, max={np.max(pixel_list):.0f}")
        
        if success_count > 0:
            avg_c = total_timings['method_c'] / success_count
            avg_c_opt = total_timings['method_c_optimized'] / success_count
            print(f"\nğŸ“Š Speed Comparison:")
            print(f"  Method C:           {avg_c:.4f}s")
            print(f"  Method C Optimized: {avg_c_opt:.4f}s ({avg_c_opt/avg_c:.2f}x slower)")
            
            avg_pixels_c = np.mean(edge_pixel_stats['method_c'])
            avg_pixels_c_opt = np.mean(edge_pixel_stats['method_c_optimized'])
            print(f"\nğŸ“Š Quality Comparison:")
            print(f"  Method C pixels:           {avg_pixels_c:.1f}")
            print(f"  Method C Optimized pixels: {avg_pixels_c_opt:.1f} ({avg_pixels_c_opt/avg_pixels_c:.2f}x more)")


def main():
    """Main function"""
    parser = argparse.ArgumentParser(description="Edge extraction method comparison experiment")
    parser.add_argument("--data-dir", type=str, required=True, help="SA-1B data directory")
    parser.add_argument("--output-dir", type=str, required=True, help="Output directory for visualizations")
    parser.add_argument("--max-images", type=int, default=100, help="Maximum number of images for speed test")
    parser.add_argument("--kernel-size", type=int, default=3, help="Edge extraction kernel size")
    parser.add_argument("--device", type=str, default="cuda:5", help="GPU device (e.g., cuda:0, cuda:5)")
    parser.add_argument("--visualization-only", action='store_true', help="Only generate visualizations, skip speed test")
    parser.add_argument("--speed-test-only", action='store_true', help="Only run speed test, skip visualizations")
    parser.add_argument("--update-visualizations", action='store_true', help="Update existing visualizations by appending optimized Method C")
    parser.add_argument("--test-method-c-only", action='store_true', help="Only test Method C (original and optimized) on 100 images")
    parser.add_argument("--test-method-b-only", action='store_true', help="Only test Method B (optimized) on 100 images")
    parser.add_argument("--show-method-b-only", action='store_true', help="Visualization: show only Method A and B comparison (4 columns)")
    parser.add_argument("--test-bbox", action='store_true', help="Test bbox extraction from SA-1B JSON files")
    parser.add_argument("--num-bbox-test", type=int, default=50, help="Number of JSON files for bbox extraction speed test")
    parser.add_argument("--num-bbox-vis", type=int, default=5, help="Number of files to visualize bboxes")
    parser.add_argument("--bbox-start-index", type=int, default=1000, help="Start index for bbox visualization (skip first N files)")
    parser.add_argument("--cuda-device-id", type=int, default=0, help="CUDA device ID for bbox extraction (è¶…å‚æ•°)")
    parser.add_argument("--nms-iou-threshold", type=float, default=0.5, help="NMS IoU threshold for removing overlapping boxes (å»ºè®®0.3-0.7)")
    
    args = parser.parse_args()
    
    # Set CUDA device FIRST (before any other operations)
    print("=== Setting CUDA Device ===")
    device = set_cuda_device(args.device)
    
    config = {
        'kernel_size': args.kernel_size,
        'device': str(device)
    }
    
    print("\n=== Edge Extraction Method Comparison ===")
    print(f"Data directory: {args.data_dir}")
    print(f"Output directory: {args.output_dir}")
    print(f"Device: {args.device}")
    print(f"Kernel size: {args.kernel_size}")
    print(f"Max images (speed test): {args.max_images}")
    
    # æ ¹æ®å‚æ•°é€‰æ‹©æ‰§è¡Œæ¨¡å¼
    if args.test_bbox:
        # Bbox æå–æµ‹è¯•å’Œå¯è§†åŒ–
        print("\n" + "="*60)
        print("Bbox Extraction Test")
        print("="*60)
        
        bbox_extractor = SA1BInstanceBoxExtractor(
            min_area_threshold=1000,
            min_iou_threshold=0.90,
            nms_iou_threshold=args.nms_iou_threshold,
            use_cuda=True,
            device=device,
            cuda_device_id=args.cuda_device_id,
        )
        
        # é€Ÿåº¦æµ‹è¯•
        print(f"\né˜¶æ®µ1: é€Ÿåº¦æµ‹è¯• ({args.num_bbox_test} ä¸ªæ–‡ä»¶)")
        print("-"*60)
        bbox_extractor.batch_extract_test(args.data_dir, num_files=args.num_bbox_test)
        
        # å¯è§†åŒ–
        print(f"\né˜¶æ®µ2: å¯è§†åŒ– ({args.num_bbox_vis} ä¸ªæ–‡ä»¶)")
        print("-"*60)
        vis_output_dir = Path(args.output_dir) / "bbox_visualizations"
        bbox_extractor.batch_visualize(
            args.data_dir,
            vis_output_dir,
            num_visualize=args.num_bbox_vis,
            start_index=args.bbox_start_index
        )
        print(f"\nâœ… å¯è§†åŒ–ç»“æœä¿å­˜åˆ°: {vis_output_dir}")
        
    elif args.test_method_c_only:
        # åªæµ‹è¯•Method Cï¼ˆåŸå§‹å’Œä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        extractor = EdgeExtractionComparison(config)
        print("\n" + "="*60)
        print("Testing Method C Only (100 images)")
        print("="*60)
        extractor.batch_test_method_c_only(args.data_dir, args.max_images)
        if not args.speed_test_only:
            print("\n" + "="*60)
            print("Phase 2: Visualization")
            print("="*60)
            vis_output_dir = Path(args.output_dir) / "visualizations"
            extractor.batch_visualization(
                args.data_dir, 
                vis_output_dir, 
                max_images=20,
                update_existing=args.update_visualizations,
                show_method_b_only=args.show_method_b_only
            )
    elif args.test_method_b_only:
        # åªæµ‹è¯•Method Bï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        extractor = EdgeExtractionComparison(config)
        print("\n" + "="*60)
        print("Testing Method B Only (100 images)")
        print("="*60)
        extractor.batch_speed_test(args.data_dir, args.max_images, methods=['b'])
    else:
        # åˆ›å»ºè¾¹ç¼˜æå–å¯¹æ¯”å™¨
        extractor = EdgeExtractionComparison(config)
        
        if not args.visualization_only:
            print("\n" + "="*60)
            print("Phase 1: Speed Test")
            print("="*60)
            extractor.batch_speed_test(args.data_dir, args.max_images)
        
        if not args.speed_test_only:
            print("\n" + "="*60)
            print("Phase 2: Visualization")
            print("="*60)
            vis_output_dir = Path(args.output_dir) / "visualizations"
            extractor.batch_visualization(
                args.data_dir, 
                vis_output_dir, 
                max_images=20,
                update_existing=args.update_visualizations,
            show_method_b_only=args.show_method_b_only
        )


if __name__ == "__main__":
    main()
