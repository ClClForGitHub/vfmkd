# Mamba backbone configuration
name: "MambaBackbone"
model_size: "base"  # tiny, small, base, large
pretrained: true
freeze_backbone: false
freeze_at: -1

# Architecture settings
d_model: 512
n_layer: 8
d_state: 16
d_conv: 4
expand: 2

# Feature extraction settings
feature_scales: [16, 16, 16]  # All features at 16x downsampling
feature_dims: [512, 512, 512]  # All features have same dimension

# Training settings
learning_rate: 0.0001
weight_decay: 0.01
dropout: 0.1