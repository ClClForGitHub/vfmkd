#!/usr/bin/env python3
"""
éªŒè¯NPZä¿å­˜çš„ç‰¹å¾ä¸SAM2åœ¨çº¿ç”Ÿæˆç‰¹å¾çš„ä¸€è‡´æ€§
å¯¹æ¯”P4 (64x64) å’Œ P5 (32x32) ç‰¹å¾
"""
import sys
from pathlib import Path
import torch
import numpy as np
from PIL import Image
import glob

_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(_ROOT))
sys.path.insert(0, str(_ROOT / 'vfmkd' / 'sam2'))

from sam2.build_sam import build_sam2
from hydra import initialize_config_dir
from hydra.core.global_hydra import GlobalHydra

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def load_sam2_model():
    """åŠ è½½SAM2æ¨¡å‹"""
    sam2_config_dir = _ROOT / "vfmkd" / "sam2" / "sam2" / "configs"
    if GlobalHydra.instance().is_initialized():
        GlobalHydra.instance().clear()

    with initialize_config_dir(config_dir=str(sam2_config_dir), version_base=None):
        sam2_model = build_sam2(
            config_file='sam2.1/sam2.1_hiera_b+.yaml',
            ckpt_path='weights/sam2.1_hiera_base_plus.pt',
            device=str(device)
        )
    
    sam2_model.eval()
    return sam2_model

def extract_online_features(sam2_model, image_path):
    """åœ¨çº¿æå–SAM2ç‰¹å¾"""
    # åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
    image_pil = Image.open(image_path).convert('RGB').resize((1024, 1024))
    image_np = np.array(image_pil)
    
    with torch.no_grad():
        # é¢„å¤„ç†
        image_tensor = torch.from_numpy(image_np).permute(2, 0, 1).float() / 255.0
        image_tensor = image_tensor.unsqueeze(0).to(device)
        
        # ä½¿ç”¨image_encoderæå–ç‰¹å¾
        backbone_out = sam2_model.image_encoder(image_tensor)
        fpn_features = backbone_out['backbone_fpn']
        vision_features = backbone_out['vision_features']
        
        # æŒ‰ç´¢å¼•æå–ç‰¹å¾ï¼ˆä¸sam2_teacher.pyä¿æŒä¸€è‡´ï¼‰
        features = {}
        
        # IMAGE_EMB_S16: backbone_fpn[2] (64x64)
        if len(fpn_features) >= 3:
            features['IMAGE_EMB_S16'] = fpn_features[2]
        
        # P4_S16: backbone_fpn[2] (64x64) - åº”è¯¥ä¸IMAGE_EMB_S16ç›¸åŒ
        if len(fpn_features) >= 3:
            features['P4_S16'] = fpn_features[2]
        
        # P5_S32: backbone_fpn[3] (32x32)
        if len(fpn_features) >= 4:
            features['P5_S32'] = fpn_features[3]
        
        # vision_features (åº”è¯¥ç­‰äºfpn_features[-1])
        features['vision_features'] = vision_features
        
        return features

def load_npz_features(npz_path):
    """åŠ è½½NPZæ–‡ä»¶ä¸­çš„ç‰¹å¾"""
    data = np.load(npz_path)
    features = {}
    
    for key in data.files:
        if key.endswith(('_S16', '_S32', 'IMAGE_EMB_S16')):
            features[key] = torch.from_numpy(data[key]).to(device)
    
    return features

def compare_features(online_feat, npz_feat, feat_name):
    """å¯¹æ¯”ä¸¤ä¸ªç‰¹å¾çš„ä¸€è‡´æ€§"""
    print(f"\n[{feat_name}] ç‰¹å¾å¯¹æ¯”:")
    print(f"  åœ¨çº¿ç‰¹å¾: shape={online_feat.shape}, device={online_feat.device}")
    print(f"  NPZç‰¹å¾:  shape={npz_feat.shape}, device={npz_feat.device}")
    
    # ç¡®ä¿ç»´åº¦ä¸€è‡´
    if online_feat.shape != npz_feat.shape:
        print(f"  âŒ å½¢çŠ¶ä¸åŒ¹é…!")
        return False
    
    # è®¡ç®—å·®å¼‚
    diff = torch.abs(online_feat - npz_feat)
    max_diff = diff.max().item()
    mean_diff = diff.mean().item()
    
    # è®¡ç®—ç›¸å¯¹è¯¯å·®
    rel_error = (diff / (torch.abs(online_feat) + 1e-8)).mean().item()
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    online_flat = online_feat.flatten()
    npz_flat = npz_feat.flatten()
    cos_sim = torch.nn.functional.cosine_similarity(
        online_flat.unsqueeze(0), 
        npz_flat.unsqueeze(0)
    ).item()
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"  åœ¨çº¿ç»Ÿè®¡: mean={online_feat.mean():.6f}, std={online_feat.std():.6f}")
    print(f"  NPZç»Ÿè®¡:  mean={npz_feat.mean():.6f}, std={npz_feat.std():.6f}")
    print(f"  å·®å¼‚ç»Ÿè®¡: max_diff={max_diff:.8f}, mean_diff={mean_diff:.8f}")
    print(f"  ç›¸å¯¹è¯¯å·®: {rel_error:.8f}")
    print(f"  ä½™å¼¦ç›¸ä¼¼åº¦: {cos_sim:.8f}")
    
    # åˆ¤æ–­æ˜¯å¦ä¸€è‡´ - è°ƒæ•´é˜ˆå€¼ä»¥é€‚åº”æµ®ç‚¹æ•°ç²¾åº¦
    is_identical = max_diff < 1e-6
    is_very_close = max_diff < 1e-3 and cos_sim > 0.9999  # æ”¾å®½max_diffé˜ˆå€¼
    is_acceptable = max_diff < 0.2 and cos_sim > 0.9999   # å¯æ¥å—çš„å·®å¼‚
    
    if is_identical:
        print(f"  âœ… å®Œå…¨ä¸€è‡´ (max_diff < 1e-6)")
        return True
    elif is_very_close:
        print(f"  âœ… éå¸¸æ¥è¿‘ (max_diff < 1e-3, cos_sim > 0.9999)")
        return True
    elif is_acceptable:
        print(f"  âœ… å¯æ¥å—å·®å¼‚ (max_diff < 0.2, cos_sim > 0.9999) - å¯èƒ½æ˜¯æ•°å€¼ç²¾åº¦é—®é¢˜")
        return True
    else:
        print(f"  âŒ å­˜åœ¨æ˜¾è‘—å·®å¼‚")
        return False

def main():
    print("="*80)
    print("NPZç‰¹å¾éªŒè¯è„šæœ¬")
    print("="*80)
    
    # åŠ è½½SAM2æ¨¡å‹
    print("[INFO] åŠ è½½SAM2æ¨¡å‹...")
    sam2_model = load_sam2_model()
    print("[OK] SAM2æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # æŸ¥æ‰¾NPZæ–‡ä»¶
    npz_dir = Path("datasets/coco128/SAM_Cache")
    npz_files = list(npz_dir.glob("*_sam2_features.npz"))[:5]  # åªæµ‹è¯•å‰5ä¸ª
    
    if not npz_files:
        print("[ERROR] æœªæ‰¾åˆ°NPZæ–‡ä»¶")
        return
    
    print(f"[INFO] æ‰¾åˆ° {len(npz_files)} ä¸ªNPZæ–‡ä»¶")
    
    # éªŒè¯æ¯ä¸ªNPZæ–‡ä»¶
    all_results = []
    
    for i, npz_path in enumerate(npz_files, 1):
        print(f"\n{'='*80}")
        print(f"[{i}/{len(npz_files)}] éªŒè¯: {npz_path.name}")
        print(f"{'='*80}")
        
        # æå–å›¾åƒID
        image_id = npz_path.stem.replace('_sam2_features', '')
        image_path = Path(f"datasets/coco128/images/train2017/{image_id}.jpg")
        
        if not image_path.exists():
            print(f"[ERROR] å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            continue
        
        try:
            # åœ¨çº¿æå–ç‰¹å¾
            print("[INFO] åœ¨çº¿æå–ç‰¹å¾...")
            online_features = extract_online_features(sam2_model, image_path)
            
            # åŠ è½½NPZç‰¹å¾
            print("[INFO] åŠ è½½NPZç‰¹å¾...")
            npz_features = load_npz_features(npz_path)
            
            # å¯¹æ¯”å…³é”®ç‰¹å¾
            results = {}
            
            # 1. å¯¹æ¯” IMAGE_EMB_S16 (64x64)
            if 'IMAGE_EMB_S16' in online_features and 'IMAGE_EMB_S16' in npz_features:
                results['IMAGE_EMB_S16'] = compare_features(
                    online_features['IMAGE_EMB_S16'], 
                    npz_features['IMAGE_EMB_S16'], 
                    'IMAGE_EMB_S16'
                )
            
            # 2. å¯¹æ¯” P4_S16 (64x64)
            if 'P4_S16' in online_features and 'P4_S16' in npz_features:
                results['P4_S16'] = compare_features(
                    online_features['P4_S16'], 
                    npz_features['P4_S16'], 
                    'P4_S16'
                )
            
            # 3. å¯¹æ¯” P5_S32 (32x32)
            if 'P5_S32' in online_features and 'P5_S32' in npz_features:
                results['P5_S32'] = compare_features(
                    online_features['P5_S32'], 
                    npz_features['P5_S32'], 
                    'P5_S32'
                )
            
            # 4. éªŒè¯ IMAGE_EMB_S16 ä¸ P4_S16 æ˜¯å¦ç›¸åŒ
            if 'IMAGE_EMB_S16' in npz_features and 'P4_S16' in npz_features:
                print(f"\n[å†…éƒ¨ä¸€è‡´æ€§] IMAGE_EMB_S16 vs P4_S16:")
                diff = torch.abs(npz_features['IMAGE_EMB_S16'] - npz_features['P4_S16'])
                max_diff = diff.max().item()
                print(f"  æœ€å¤§å·®å¼‚: {max_diff:.10f}")
                if max_diff < 1e-10:
                    print(f"  âœ… IMAGE_EMB_S16 ä¸ P4_S16 å®Œå…¨ç›¸åŒ")
                    results['internal_consistency'] = True
                else:
                    print(f"  âŒ IMAGE_EMB_S16 ä¸ P4_S16 ä¸åŒ")
                    results['internal_consistency'] = False
            
            # 5. éªŒè¯ vision_features ä¸ P5_S32 çš„å…³ç³»
            if 'vision_features' in online_features and 'P5_S32' in online_features:
                print(f"\n[vision_features vs P5_S32]:")
                diff = torch.abs(online_features['vision_features'] - online_features['P5_S32'])
                max_diff = diff.max().item()
                print(f"  æœ€å¤§å·®å¼‚: {max_diff:.10f}")
                if max_diff < 1e-10:
                    print(f"  âœ… vision_features ä¸ P5_S32 å®Œå…¨ç›¸åŒ")
                else:
                    print(f"  âŒ vision_features ä¸ P5_S32 ä¸åŒ")
            
            all_results.append({
                'file': npz_path.name,
                'results': results
            })
            
        except Exception as e:
            print(f"[ERROR] å¤„ç† {npz_path.name} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
    
    # æ€»ç»“æŠ¥å‘Š
    print(f"\n{'='*80}")
    print("éªŒè¯æ€»ç»“")
    print(f"{'='*80}")
    
    for item in all_results:
        print(f"\n[{item['file']}]")
        for feat_name, is_ok in item['results'].items():
            status = "âœ… é€šè¿‡" if is_ok else "âŒ å¤±è´¥"
            print(f"  {feat_name}: {status}")
    
    # ç»Ÿè®¡é€šè¿‡ç‡
    total_tests = sum(len(item['results']) for item in all_results)
    passed_tests = sum(sum(item['results'].values()) for item in all_results)
    
    print(f"\næ€»ä½“é€šè¿‡ç‡: {passed_tests}/{total_tests} ({passed_tests/total_tests*100:.1f}%)")
    
    if passed_tests == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼NPZç‰¹å¾ä¿å­˜æ­£ç¡®ï¼")
    else:
        print("âš ï¸  å­˜åœ¨ä¸ä¸€è‡´çš„ç‰¹å¾ï¼Œéœ€è¦æ£€æŸ¥ï¼")

if __name__ == "__main__":
    main()
